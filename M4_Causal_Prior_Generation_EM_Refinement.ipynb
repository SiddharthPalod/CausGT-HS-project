{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09f62a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste this in a single notebook cell and run it.\n",
    "import sys, os\n",
    "print(\"Using python:\", sys.executable)\n",
    "\n",
    "# Use the notebook's interpreter to uninstall then reinstall cleanly.\n",
    "# This cell uninstalls transformers/token libs then reinstalls a clean set.\n",
    "# It may take a few minutes depending on network.\n",
    "\n",
    "print(\"\\n==> Upgrading pip / build tools\")\n",
    "!{sys.executable} -m pip install -U pip setuptools wheel\n",
    "\n",
    "print(\"\\n==> Uninstalling possible conflicting packages (if present)\")\n",
    "!{sys.executable} -m pip uninstall -y transformers tokenizers tiktoken sentencepiece huggingface-hub accelerate safetensors datasets || true\n",
    "\n",
    "print(\"\\n==> Reinstalling compatible package set\")\n",
    "!{sys.executable} -m pip install -U \"transformers[torch]\" tokenizers tiktoken sentencepiece huggingface-hub datasets accelerate safetensors tqdm scikit-learn\n",
    "\n",
    "print(\"\\n==> Clearing HuggingFace cache (so corrupted tokenizer files are removed).\")\n",
    "# Be conservative: only clear transformers/hub caches if they exist.\n",
    "home = os.path.expanduser(\"~\")\n",
    "hf_transformers_cache = os.path.join(home, \".cache\", \"huggingface\", \"transformers\")\n",
    "hf_hub_cache = os.path.join(home, \".cache\", \"huggingface\", \"hub\")\n",
    "for p in (hf_transformers_cache, hf_hub_cache):\n",
    "    if os.path.exists(p):\n",
    "        print(\"Removing cache:\", p)\n",
    "        !rm -rf \"{p}\"\n",
    "    else:\n",
    "        print(\"No cache found at:\", p)\n",
    "\n",
    "print(\"\\n==> DONE. Please restart the kernel (Kernel -> Restart) if your environment supports it.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e7562e",
   "metadata": {},
   "source": [
    "# EM-Refinement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b946e3",
   "metadata": {},
   "source": [
    "EM = Expectation Maximization\n",
    "\n",
    "This phase is a \"One-time\", offline, self-supervised training loop that learns all the specialised neural components used by the online CoCaD pipeline. It proceeds in 3 main steps:\n",
    "- Synthetic \"gold data\" generation\n",
    "- bootstrap pre-training of all modules\n",
    "- EM-style refinement loop on real-documentss"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    },
    "image-3.png": {
     "image/png": "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"
    },
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAssAAAHoCAYAAAC/2KLeAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAJlWSURBVHhe7P1/bJv3fe9/P3u7AAv7xmXk3KDQnppwI3FdEtadrW7LGPgs8vGJpJMzy/M5GteAUTswTArXao4yoa4OjxsdeYYOq0KLltrV3YYh2ti8s3JaPUv7ZhJ9/LWcBeHcLrI2h3GaUjw16N4rRJwFuXA7CIEYvf+4SPHiJVI/LMmxk9cDIBJdv3/JevHD9+fDj919992/RkREREREFvl/OCeIiIiIiIhFYVlEREREpA6FZRERERGROhSWRURERETqUFgWEREREalDYVlEREREpA6FZRERERGROhSWRURERETqUFgWEREREalDYVlEREREpA6FZRERERGROjY2LIcSzOZmSYScM2T1wiRey5H7+QVGdjvnfbiFX5gll8txYdjvnLU6u6OkruTIzSY45Jy3jvyDKa7kcswmNnIvd75wwrqvqSHnnI2z4nszlCKXyzGbCDvnbIxQgtlbfC3WbChFLpci6px+k6Jnc+TOrtfWRETWz02H5ejZHLlcvdcGB+TSH7JFr9kEt+hP2wei+D7wfpH3nDNuBfs1/9sBPM75ANsHmPj5BtyL94tAkWLROeMmFYus16aWUly3A16B7REmruS4cjZKCyv4HSmFs1wuR+5inIBzewAEiF8sr1sKRZ1xLpZCZM1n4A5xS++NiIjc0W46LPc91Ehjo/UaTJtgphks/dzYuJNg3LnGBng7T/atrO2VZ965zAfqEKMvz3Ll4mqDY631YoTub6Tx3lb6Xqla+Na7r4XeGq3b/j9twbfJOXXtYqH7aWy8l9ZI2jlrdV7po/XeRhrvDxFzzrspHUT/+iKzV6pb19KRVu5tbOT+0PrsZXkeIie68H08y5mBPqbts1byO+L2E/iacyLwtQB+t2PaWIjhcwUM/+MMdDrm3QFq3ZuOwTEuzl75YFt140F2NjbSetg5Q0REPmg3HZZvB+abJ2ltb628An2MOxf6QHlo2mbgcjmnL+dm19t4pmkCHnZ90VkS0cHjv+cB08R0zPnwasDT5Mb4oO9T5wD773NR+PvYojdSy/6OmCYmLnwtvfapAETamnFhYjpuaPLYJJkbblr+pM4nDHeYhu1e3B/4TRQRkdvVLQrLUVK2j4IX1wFWz1/TR/ilj6NzuYvEyy1f5WlXUkT32usRD3EofoEr5dKB11KMBKv//Pu+PELqtSuVY385QWRv1RJ0DaeYvVI5/ivnR+kYSpHLBfACGH4itvPyPzHKxKtWvWYulyN3ZZbUcJcVPOquFyYxa/s4vLz3L48s3lY8Yn0UD5VrO5sg0pfgwuul5V6/QPyJm4g6mRkyN8DzO49Xf3Tf+Yf43FCYmVnUcrnk+ZY+1s/9fIKB7aUVytNeSxDeXqO2deH+RRg4U9nuxWSElu1djExWps2eGah5LcK2mtnFr9I13h1m9MxFZsvPx8+vMDs5Qtf2chlDBL8B4CVgX69GvatnX4T42dnKs/bzWS6eKW0LrJr00v0dCY6Qeq2y3ER/5Qxq6Wjz4aZA5qWkc9byCjPMFMD1+ZbK9ccqqfH/JvDGDBnbZACu9jP9z0W4z88h+zoOS973Onxfi3NhtnLuqeMDNZ57H13DE1wsL5fLceW1FPE++3Uq3+sJ4uVn5GzUcW+sax6xbiLeTmtb1S3MDUQSlX8jrrwcJ7xwzrbfrf6JynNycYzIXo/178LCvy0TDFT9u+GwqH9H+Xkov5YobRtK1fg30zo2+7k4S+eqztNellO+Vg7V6y9Tq7zofMq/F9XTwonZRfuq/r1cvB/n7+3i85glEar/N8daf/F2RUTquQVh2cB/pJmZconGWBbD3237BzNKKheAsUpZR7LgJ7LoH/8VujrIVxMZirhp+UoUPxAeDOBzQf6lQfrOVRZ1/VY33T6T9PgU6TkT7vLSceS7REp/DD1PJEj0d+DdlGf69Djj01nY5ic8VD42P9HJMQYOeDGKeWamxxmfzmBuctHwkynGT89QAHg3a60/cZ4M4HuwGc/7pWkvzVDAwHsgwjNfA5ZYz6l8fD43ZNNTjL+UJls08LaEGXHWlG5ppuvRbRSmp0hfNWGzh5Ynn7mJjm6vMnmpuOij+0MBP27ypOPOqLzM+ZY+1meTj/2DYeuafqUFNybp7/URu+rcWoXR3MV+1wzj01nMG+D+7TAjP+6lbXOWqZdmKBTB2NHFwF84W8EtmQtnGD89vvCa+ZU1Pf/SIH0An91D8/b3yP79OOOnp5gpgPHZDiLfPgRvnefM6Wmy7wIUmDldWqZ6F5a9UZ4fCtPS5MJ8Y5rx09Nk/tWFe0cHkVipxniBh7b/1gL/NM705QLFTQa+Lw8s0anTz3/8TTeYWV4dc85biXme+4c8bPLR8qeV62SV1BSZmXq1aumy4Z/lAS++LueciiXvey2dceJPteAxihQuTzP+93m27u0qvSEp8xBOJBg44MNNlvRL40ylsxQNLy1PjJBwvgE0fPg3T9Ozp5HGh/qq55Hh/MQ403NW/XLhkvUcTP2ksoTR3EWX1yQ9lSZvgmtbC73fdvzWbGmm64CLmfFpsibgbiY8NEHvwy6yU1PM/KoId/noOjJC7SdxsejZCP5C0lbqtvj3ajXCiVkCblup3Fi2MjOUYPaIj8yx8r/Bg6TdgaoQGz2bq17/WIH2Tm9lG07x82RMA9/eyr/i0V1ewD4tzB6fgTlvO5amAN0crxyH6SVgO45wYpaIL2M7jjQNnc43OMv9zRERWZ1bEJYhO9ZqhQ+Aw0nStn9Ew4l2vHPJqlq9vhfTmIaPPcv842b4I1UtDOXWg/yxQc68VYSm/fT2j9LlN+DqOP29VdWcuK6n6b9/H6HegwQf2sfJNwCXD38XgJ/eR/wYNzKc3N9KqLeHnlArJy8V4a5m2p8CvtbL/s+64O00g/sfpDPUQ09oH/f/fojY2DA9vVneAXi/wKu9PfR8M0YamIp0svP3O61tdnfScy4PuPB8vgOWWK9a6fgoMvPdfbQGD9LTHaR1/0kyN8DwB6pb/TbNM/1fH6Sz+yDBPcdJm8BmD184YFtmhU4k0xRw0dxW+hh++wDtu1zwxjTDNeqplzxfIPn4c6TfBsPfxWh/L/ubwEwfp+/7eeemqr09TU97iJ5QKwenrGUNV5bjv9/Jwe5OOiesP8Kepj2OFS3p7/fT09tDT28Pf3PjPnyfhOJckv7u0nNyro/OnaX72nuQzsPT5AHX9i/Q8UqM/t5XKbwP8A7Z3h56eoep1bZ76Cv78bog/9JB7t8foqc3xL77+5kugKupnccdz3nm+X20hnoI7e/kzBxWWU7dxmUfhgEU8jXrsOv9jtil/3za+rTg98qfFgSskppCmuR3nEuXZAuYQMN26x7Wstx9d+p9xI8byJ8uXafQPu7vnqLqKdjda/0+vzvDif2tBLt7OBhsZd+pjBWS/uiQo+U6z/RAD+M133SliX2zh1fnrbD8zpz1LAzb33SYpX8juoM8+GwaE3A1PUDVe4RNJtO9rYR6Q7SWj/cuF9nvWr9vnY+cIQuwrYnaT6JTGI+bqhAZC7auqR+It8GofkYOty78mxt9xA/p47btxwimstDUbLW+hhK0N5mknw1W1o8H2WkP3IvEOJ8xMRrKgTpKc5NJds4+zYvbMMmcsz25ZprjwfLPjuMgSsDPouOYnAPvrup24qX+5sSCO2lstM0XEVnGLQjLJoU3ndMqvA0GNAWq/qDnjvipakyqx9l56Wq59SVN37enyN9w0fzlNjw38owf66nu+ASY2Vdt4SZP7GfWn2XPZ7uA/dy3Hdjko+t85dgO7XIBLoxPQcfnPbiAfPr4ki2gi3w+wGgyxYXXrnDlSo7Ew9afd9fmBueSSygdnznD5DO2OHG1n8wvsOpp7R/7mtd4baFVPUa+AODCdZfz49XFr0Udn8aeI3210tGv0grZXx1sypY93xh930tj4qHty824zDTHI7Ha27Ix//drC/c0/a4VeIo/S3OiNC3/phXocC3zNO0dYeCAF9e7M8TC9g5yuwiMjpF6eZYrr18h90KbFcRcLlZ+p7p4oMkF5Ln0bfsTmOTVrAkYuO+xTSZPduF+5snOWwXD9U/Bi7vuvKV+R2yu9ld/WlDq2Jf/h+dqhn8A4lZHwSWf2WXvu10Hvm2l6/Ss7Tqde41r9prph+/DA5j/NMmw7XcuP5CxAqnbQ5ttccxrvFbjDdxKVf0bUTpnNkFVhbOZrfxuvfKONdLKuxnS5TcaV7MUTGCTa2X/rpVCovVGZ33KBfpeTGM2BRaVQZSDufNNVc7eanyPG8PMcH6VYT32y3lb4PbQYGZIvpjBLE8basbr3G6dN31Q2gYG/iPV/z4FmpwLLv03R0RktW5BWF6emR5c+Lix8lp+RA1n56XOiK3rUvE9a6g1SsOtrWCkqF3GJwB4x7S1mJgzxEqtj/bX4Elo2Fz6k1m8Vll+ObujPD90iLYdWzH/aYqpvxym56XlYuHGmklVShFqvewfS1vSDE9nSh39wku3Qq7wfPPlewVwA1jNmw+b4nvvOCctbXuYxFAHnk0m6WefsgUwP9HvfYtDbT62vj3D1FSS4V5HK+cdYMnfEZvypwW+lggDbc24bmSY/vPFn2es2Arve0VDqUNrkfdu8t7fVt4vWp8O3azDraXyi4bqevibVRpto3FsvhQ2q0Nz1lYGV3mtsfX18AxZvDQPQXivDzLnicXPkzGtadFdXszM+frhuKYsyUXHWavERkRk/XzgYTk7b2L49txcfXJdLUT79+N1maRfmqHo8rL/iFW/bGd4vmCrF22xaj8pUvhZGniVawXA8OJzX1oUIKcvQ+xKqSX6d+wd6pbR0YzXBebMc+wL9dAzcIKGu7Y6l1qB8vH52GOv09wewfcp4EaerK0+eynJby9+M2B/VX0sXZIfmGTmXfDs7V26FXIl57s9TOKQH+NGlqnpPNzlp/uF9X0iavMQHuzGfxcUzg0SrCr72E/zZ11gzvDc/hA9vf2cuMtg9XfqJJl/wXpj8aT9KWnhC3cbQIFri96MrEYB813ntJtQ+rTA9fkuAvdB8dIk/UuF1pDHal2/Uedd6Erue5Wp0qcdXnz9lefZ88QefPbm2J9ew3rs99g62oGnz2e1+l/LMmVb/E5nlQwkF0JnXYbb6hRcVr4/TodbS7XA5bIE61MmZxnDIjXK4sKfrrkHmz5m5qDh01H2+CiVW1jlGQ2fjuJxO0owlhPPM7/cdRAR2QAfeFiOnctgGn66q2opo6Rq9MZ2Mu7pIjWZsr1GOQS0DEXY3+SieOkkfd1PcfKNIq7P7mdg0BGXt7Uxcj7B6HCciYujtG0Drk1z/DsA4zx3LksRA//XJ0glRhkZHiGevMDs35aO7dhJpgvWduKzKRLHRxhNpLj4crwU/ktBxmjm8eQoieQoYdMKF0ZzF4nhEUaTF+hudg5bVWM9xxIwTv9Epvr4jidInQnj2wyF/3Vy6bCzZidI/qQALhcu8lz6qzqtkMuebyWw5qcGORg6wXQBjN0b3yGnZeh5ev0GmFky5gOMDI+UXr0EMCnesO5B1wsjjBwf48Kh5uqP38mUhlXz0j4ZZ/RMombr3+APpijcAM+BUS6eiTNSft4+CcXLZ+iv8WZk5V6l8K9W+cHiZ6T+78hipU8LNrlwUSTz9+Viljq8bgwg/9ZJ5xzLsvfdKc+JCxmKgO/LE1xIjDKaSDHx9WZc9jcDp/s5c7lojRRzpvI7N/GYD9eNAlM/qFMKtITM21YbsLc1Rfz4BIlB5xK3WpjE2VV0cC614LYv/BsaJvFkdSlb9Gz9lum+S1loCiwaVSJV3l6p5tf/pO2YQgm6q3te1tR3KYvhD+CnUm4R++W8Nc2YJ7/Mp4fVrPDt7aw+l3Aitap/KzQahois1gcelokH2XksDVU1c+0UXlzBx2p3efB+1mt7NeEp15/eyHLmmWHy5Bl8Zpo8LrwHBojaRhUw0yeZLvpoO9CCz+3CfGuc/kMHK3Wwkcf4RmKGwnUDr7+NjgMdtOzYyvxcuUwjSSjQz/jlAuYWL/6HO2j7XQ+uQrY0esUwx/8qg3nDhfu32/B/EuaPDRP7xwLFj3vwH+ig5ZNzHF/08XSN9RxLAOSP7ePg96fJmi7r+B7246VA5nQ/nQdrtvOuq2Q8bQWTOh37AFjmfD1PRK0/umaak93TQJL+v5yx3gQcWkVgWLUIvQe8Vvg1vLQc6KBj4dVGM4MMPz9DoejCs7uDjhY3c99zlmGkGTw1Tf5dMD7bQluTq/YY02MH6fwf42R+VcS9o4WOAy34jCLZ6RgH9w+uOtxVS/Na3gTDywO1OmvW+h1xLlNS/rSgbkmNTe9veoA8c86OAGXL3Pda8se+yuDpLOYNA4+/jbbfcpF5/iQz9hId8gzuP0hsOovpKv3O+b1QyDD+Pzo5eBNvPNLfPsn0taL1HLR5cdW8ibeYuzRsZC5HrjRaUP0vLOmjdaxc45wjl+uGZ5NWDfeC8vCGOXK5CL7MIDvLHekOt9I4ll0YOi+Xy5E74mbG3tFu5yBpbMf0JBxfsoNfyeEZslBdblGaxtzMqss8+h5qJDlnP5cckYaZZUv2RETW4mN33333r50TP/SGUuQ6vZhp2x8MkTtVZ5yLQy0w3cf9oY1/k8T2ASb+Vxe+n53kwT9YfUvu6lhDS3rNNIM7baMgiIiI3CIffMuyiKzNWD9n3iji/nfhqk9ONkrgSDu+TSbpH290UIaW436rFvdDVossIiJ3DoVlkTtensHoGbLve9nf7/ySk3XWGad3r9saB3u9P/oOxbn42gUmEqOMDMcZe3mW+MMe4NYEcxERkVpUhqEyDJHbw4EoE0f247ur1BHwRhGzkGX6e330/LDWd1iKiIhsvI9mWBYRERERWQGVYYiIiIiI1KGwLCIiIiJSh8KyiIiIiEgdCssiIiIiInUoLIuIiIiI1KGwLCIiIiJSh8KyiIiIiEgdCssiIiIiInUoLIuIiIiI1KGwLCIiIiJSh8KyiIiIiEgdCssiIiIiInUoLIuIiIiI1KGwLCIiIiJSh8KyiIiIiEgdCsuyJN/X4lyYzZHL5chNRvEPpriSyzGbOORc9DYUJjGbI5dLEXXOqitKKpcjN5sg7JwlIiIiHzl3bFiOnq0faKJnc+TOrjweSR27ozzzZAsewyQ7PcXM/zYXZhWLxapFRURERD6M7tiw3PdiGtPwExhyzAglaG/KknyozzHjDjeUWlELaTgxW/dNxKrd56FhExQvnaQ1dJDOg4OkI63c29jI/aHYwmIdg2NcnL1Cynkv5M7ztVEuvHaFiy+syxMkIiJyx7tjwzLxIMfTJt5WezAMk3jSD+kkH7Ko/MHwujGA4nvvOOdUadjuxW24nJPlTuRpwnOXC9cm5wwREZGPpg0Ny0ePHuXy5ctcvnyZo0ePOmevWSw4SdbeujwUwG9kmQyWWz3LNauVV3XrZ5RUbpZEyD5tmTKOGi284cTsomnRszlmE6UYH0owazsGZ8tveX/WdsrLVbYXPZsj1+kFvAQc8yqsc434DTD8RBbtp1SLu/BafN52lX2C4Y9Urt1QilyufG62fQLezlrXuKxSPzzyRJwLr5eO4/UUo0EPLX0J27QLxJ/w2Nb10TU8wUXbvbzyWop4X4ttGfB9bZTUa6Vlfj5L6rh9GxW+L4+Qeu3KwrZmX04Q2etcqr7yfUoNdzBwpnLPrji2E+hPVO0nN3uBhO2Yy9u5kChfD+ue+J8YZeJV27NwZZbUcBcLZ7NwDyJV+7+YjNCyvYuRycq02TMD2K+SZ1+ExMu2Y34txUjQ2nKte77wDG/vIJK4wOzPax9TvXNhb4T42Vmu2NZLfK18NCIiIre/DQvLR48e5dFHH2XLli1s2bKFRx99dAMCcx/JhdblMIlWL+ZCq3KUVC6Cv5CksbHReh1L09BpCwA34/AMWbw0LwTCMHt8BlRNi9LcBPO/tEJ79BE3k+VjaBwkjZ+IM4w3BejmeGUZ00ugtEzfQ400jmWBLMnGRhobW2u0nMcI7mxkMG2CmWawsZHGnUFilMN6gIb0YOVajM3jP1Iv2MJMapzxSwUAinPTjJ8eZ+onzqUynJ8YZ3rOql8uXBqvs5ydh7av+ihMTzFzrQibvbR9fYKRx3wUfzLO9FsmbPbQ8uQzWF0IPYQTCQYO+HCTJf3SOFPpLEXDS8sTIyTKobozTvypNrx3FSlcnmb87/Ns3dtFKcdX9v5EgkR/B95NeaZPjzM+nYVtfsJDqy9d8bQdZb+RYer0NJlCEdc2P+HBOIHS/GZ/M1sLM0yV9mMaHvxPDDCy27EdfzPXvrePxsadBOPge7AZz/tZ6/hemqGAgfdAhGccIdNo7mK/a8ba9g1w/3aYkR/30rY5y9RLMxSKYOzoYuAv/NYKe6M8PxTG736HmZesbZubvXQceZ7o7tr3/MyFDNBCNPYtwv4G3rk0xfjpKWbeduE9EOH5wdK2S6rPJUB8MExLE8z/xFov/Stw134PIyIiclvasLB84MAB56Sa09ZqoXX5bAA/aY6XWpXDiXa8ZppBe+1yqXTD8O1ZdTCq6GNmDho+XW413oPPyJKtmuahgSwzh0trPGQPtzHOZ0xwe6qPwawcO8QIprLQ1FyjBXn1oo/4MeaS7FzYPnC4leQceHfV3kPy2z30zFnlF8X5V+np7WF4zLlUmtg3e3h13grL78z11FmuWvYvO+nsPkjn78eYeRcwDN556SCtoR5C7cdJm8BmD184AOzupctvwLsznNjfSrC7h4PBVvadygAG/j86hAfofcSPG8i/dJD794foCe3j/u4p8lV79tP7iB/jRoaT+1sJ9fbQE2rl5KUi3NVM+1NVCy/L9Ysz7NsT5GBviH339zNdANw+2kuP+YmvtHJ/e5CD9v3goam6QZzipZMEv5NZ+Hkq0snO3++0jq+7k55zecCF5/MdVevx9jQ97SF6Qq0cnLLO1HBlOf77nRzs7qRzIguAp2kPAIe+sh+vq8D0Nx+ks9u2bZcX/xf9Ne95//fT8LVu9je5KEz382DgID29B+k8PE0eF97dX8Iel6vPpZltbuDdPFNRa73gnn08dsK2goiIyG1uw8LyrVNqXW7ykk2VWlIBb4OBmTm/8HNZ7FwG03Bjfdh8c7LztsB9jxtjbobWS9mFaeG9Poy5marW3+jZSglBuWyhSiG/6FjXRxiPG7KXFrdF913KLg7tGy5PJlqOsO9QfN+a9sZfpUvTYuQLAC5cdwEP34cHMP9pkuGrCxshP5AhC+D20EYXzZ9xAXkufXu6stC517hWGcAD2M9924FNPrrOV+7HoV0uwIXxKfuyy8u+0W8L40lezZqAm22/Y00xWg6ROJPi4uwVrlwp7wdcjtufnxuunvD5AKPJFBdes9ZLPGw1xbo2N1QtZv7v1yifbfpd6w1L8Wdpylk0/2YBk/IOu3igyQW4aRmqnHt521vv8pXWWqzrd7y4AHdLdGG93AttVgmGYWBfs/pcTjD1jyZs9hH+8RVmzyaIftkgb7uPIiIit7sNC8unT592Tqo5bT3EzmUwMSm86ZyzMazA7WNPCKK7vFYQPTxD1vCxJ2SVZSyE01K9coBKOchguirBCUXeecU5bTVcsAmgyHsrCWLmDLFeqxXc/ho86VxwdRq2GkARs2Dd90R/AP92F9lXpjgT7yd2aQX3fXeU54cO0bZjK+Y/TTH1l8P0vFTdPr6U+p0xy9coz1SNc//G8SnnCgvKnf3yLy1erydynPpr5hkO7CMYTZL+RRGjyU+gf4zUkKNpXURE5Da2YWH56aef5tSpU1y/fp3r169z6tQpnn76aediG6aq9dcmvNeHYRasVkkADNz3VC2Bx23/uYb4eTKmgfueKM1N5XKLPmbmDNz3eHEblRIMa3+OcpBbymqprVVuEd3l3cAW7XXy02sUwLqX2yuTPX0+q2XzWpYpYuR/BeDF128riO18AG9VK+6rXCsAhhef+xLjp60a6/Jr+rJ92eV5mnorne6299L8GYB5rv20dN+BbOpBgt099H17GsOo8YmCU0czXheYM8+xL9RDz8AJGu7a6lzqJsTIXAPwcN9uc9G5T6XrB/LYFWuex/fvMR3rjb+UdpS62Pnw7ciT/n4fwYd28uA30xRw4X3wSzgKSkRERG5bGxaWKQXmHTt2sGPHjlsalLHVMld1pAsl6PYbtnINq/7YPvxcONG9qFPYYlbdsbczgNdWbpGdL02zhfHYL+fBXvZROoZVe7OASQOeJUawoNb+ymNSNwWqOzYOpQg0maRfXHuIz7xttWZ6W1PEj0+QGHQusQan+zlzuWiN8HEmReL4CKOJFBOP+XDdKDD1A6sU4sQrGYqA78sTXEiMMhKf4OKf+THetW9snOfOZSli4P/6BKnEKCPDI8STF5j928VvJpbj2hVm7EyckeMJUmcO0bwZipfGGX4F5ktlEd4HJxgdHiE+OcH+bc4t1GBa6xnNXSSGRxhNXqC7eX2G5Rv8cRoT8BwY5eKZOCPD1rW8+HK88qbyX0yKgNH8OGPHE4yNhuHYGdJvWyNijF6cID48Yp3zqxeIL/k8dvFM8iIT8RFGhkcY6PLhBoq/yjLuXFREROQ2taFh+YPVR2tjkmxToFJnecRH5lgjraVWX4C+h5JWqC4t081xknP27dRmlX5U1wKXp1XVSh9uJTlXHvItR+5JmLyZMox4kMk5A/+RXJ2h40oOJ62RNHK2oePiQXYeS0NpOLBcLkeuE5Kl0RfWKv3tk0xfK4LhpaXNi+smTq++PIP7DxKbzmK6vPgf7qDN74VChvH/0cnBUmfC/LGvMng6i3nDwONvo+N3DbI/PMnM+9VbS0ce4xuJGQrXDbz+NjoOdNCyYyvzc5XPGlYqO3WS7F1+Oh72491SJJ+O8Y0/HSYPjB87ztScCW4fbQc6aC6e4eTMCi7MsWFi/1ig+HEP/gMdtHxyjuOrKMNYUjxI8Jkpsm+De0cLHQc6aGtugF9lWehe+MxxkpdNcLlpftiP+8a81eH0T4at8/k3PloOdNDR1kwDBbJvVe+iWp5rb7vwtXRY17kJCpfHGXxyPd9NiYiIbKyP3X333b92ThSR+sKJWSJ+g+xY9RsvERER+fD5ELcsi4iIiIisjcKyiIiIiEgdCssiIiIiInWoZllEREREpA61LIuIiIiI1KGwLCIiIiJSh8KyiIiIiEgdCssiIiIiInUoLIuIiIiI1KGwLCIiIiJSh8KyiIiIiEgdCssiIiIiInUoLIuIiIiI1KGwLCIiIiJSh8KyiIiIiEgdCssfOmESszlmE2HnjI+06NkcudkEG3VVwolZcrkcqSHnnAr/YIoruRyziUPOWVVWsi2Ikspt7DndSuEXrHO+MOx3zlqV9drO+rN+L3O5FFHnrI+o1d+rFT7zQylyOf0bKCLr544Oy+VQUfU6qz9FcnsrFovOSXeQAPGLOXI/n2Bgu3PeGrxfBIqs+dKs13Zugqd/glwux8V4wDlLavkA75WIyGrc0WEZADPNYGMjjY2NNDYmyTYFbqJFwWqxWLol78MrnJhdvrXmtnFzLed9DzXSuDNIzDnjFkpHWrm3sZH7Qx/kUazR1wL43VC8NEn/VefMmxcL3U9j4720RtLOWauyXttZPT+9LT4gTzqedM68SR1E//ois1c2qDX6a6NceO0KF19Y3e/Sevng7pWIyOrc+WG5Sh/JtInR4HXOEJE18zDQ1oyLAunkCefMj7bOx/FvB96YZvgV58yb1YCnyY3hck5fJ54mPHe5cG1yzhAREbsNDctHjx7l8uXLXL58maNHjzpnbwhvg1H1czgxu7g0I5RgNjdLIlSubwvgBbydVilHrRbm6NlaJR6LWzkXlYY41ln2eCgfU4poqfZuyVbfUIJZ2/5mE4vfKDiPqXK81vFH/AYYfiKOfUXPVpe41LouTs59VZ1r+XzKL+d5LVyHUm2i83hDCWZzEazDjTjOpXodZ22o8/6Vf64+XkcLnuPaLjreWjZ1MTJZ2ebsmQFayvNq1VLuOMToWdvyZ0fxVOaWeOj4szEuvl46jisXGevb6lwI8NE1nGL2Smm5n89yIRGpsf8IkcQFrvzcWu7Ky3HCKymp2N1Ly33A1TTPjTlnWhbqrYfDxF++UjqOK6SOd+HZGyFhm3bhufDCuS6q097exciZi8yWjjH381lSwx3Lzlu0nZWe845DxF+uvg8Dzm0t4VDAj5siM1P95J0z6/A/McrEq7bn78osqeEu65rYnnXwEqh6Ptd+n6Nnc+Q6rX8rFv8ulXVYJTe5K4x9zTZ5e+l37fUxDi13HrZ7ciER58LrOXKlf+sW3SsCDCRs55XLMftygsjeyq7LXF8rb6t8/yv7q8WzL0LCdn+vvJZiJFhZo6UvTuq10rOZy3HltQRL9ywQkY+SDQvLR48e5dFHH2XLli1s2bKFRx99dOMD81CKQFOW5EN9zjn1HW61yjeA7JhVztF62LkQ9F3KQlOzI0ztwWeYZM5ZH6tHz+aI+OdJLpSFDJJ2B1YWshbxEtg1Y22nXvlAKMHsET/zpeNubGxksiFQ+gNbFiXQMLkwv/FYGvyR0h+oGMGdjQymzUo5S3lfoQTN84OV9cayeDttgb6GxedvXVfKfzA7G0gfqxxrsuAn4gyoGPiPNDNj26/h77b2Gw+ys3EQ63CtY9sZtK5MONFMwb7tOS+B5a57U4BujlfuleklsBCoo6Sqru0g6YJj/Ro8D0do2ZRhajpDoQjGji4G/qJeB6YA8VgvbU0GxUKG6dPT5I0WuqpvIJ4j3+VbwWbcLpNseoqpmXfwPtZG9dsiD+FEgoEDXrg6zfjpcabnwOMPM+L4mN1o7qLLU2B6Kk3eBNe2Fnq/vXw0CIT8eIDM9DDLfXDuebgb36+mmfrHPMVNLrwP9zIxFMb3bprx6SzmJheevb08Yw9hCzxETkTo2GFQfKN0Lm8U2frJhmXm1bf0OVv3oWXb0vehru0DtO9yQSFN8jvOmfX5HmzG836W6dPjjL80QwED74GIdU3eOs+Z09Nk3wUoMHN6nPHTU8ys032eSY0zfsl6oItz1nbOXMhUrQ/jPPcPecCF9/cq2/YcasYLFH6S5MRy52Hj8Tdz7Xv7aGzcSTBePc/SjL95K/MzU9Z5vWVibPMTPjJC1W/Qx5vp/qoP8yfjTKWzmKX9ffdInbi8N8rzQ2H87neYeck6RnOzl44jzxPdDXTG+dYTLXg3zZN+aZzxl9LMb3IvGb5F5KNlw8LygQMHnJNqTluzcotozmopMdNJVhGVV+5wkrTppdnWyhTe68OYm7T+4Q8laG8ySR9rte0/RvDZNKbhY88SIbM2k/SLS59J9BE/xlyyKtz3PWSFSdsUWu1vHuLnyZjQ8OklYyTEg7SWgigAh2fIYuC+x76QTc3zL+87SsBvkB2r/iPZ91CSLNXXFCA7ZtvG4SRp08C3d+njjQVbq7d9KQuG2xEoHcw0xxfOMUYwZXtDFPLQgEnhzfLCMYIP1XnTYuOaS7LvoSAHQ/vonLDeKnh+c79zMctTVv0v16Y4eP8+Qr0h9t1/kKlr9oX8RFp9uCgy8919tAYPcjDYyr7vzlDVL2p3rxXu3jjJvvYQPb09hNpPMvMuGM3t9NqXLUxz8Pc7Odgd5MFn05iAa/sXKLXb1nGIwO+6oTDNyYEVtJ2+laQzcJCDgQeJXSoCBoY5zsH2ED2hVo6nTcCF5/O19tqC71MuwGQm1m+dy/776YxMLTNvCUudc/k+XB1f4j7U5//TFnybIPNSP6upVp6KdLLz9zsJ9fbQ091JzzkrmHo+3wGvxOjvfZXC+wDvkO3toad3mOQ63efkt3vomXsHgOL8q/T09tD//cVvgdJ/dYk8YPj2lN54eji0ywsUyLxkne2S52FTvHSS4HecgdzuBI+1309r8GDVebGtiT32xTabpL95P/tCPdbvwqkM4ML3e132pRYc+sp+vK4C0998kM5u2zG6vPi/6IfmbbiB4tUpBrt76OkO8uD+x1ChkYiUbVhYvmWqOvg1MtkQucmW3OXEOJ8x8e4qtzyG2eMzyF4qxbp73BhmhvPOFpP4eTLmEiGzrnnyzm1VCeNxU9n/kuwlCuWPdlegqgzBKlWpq975Uw6eWWYWtdj3MTPnDO72gLo6VSUVpY+Yl1TI1w+/8SCTcwb+I4tLaZaSfaPyMXz+zQImQJ2a0K5dXlxA/qeDTC9Mnea1vP3dzn6atgHmDJPPVEJq/pls9cf9D99ntYTd18WFhXt2iObNwGYDt21RM/9aZX/xPPMALhdLtc16+ttp3gz5f3huRYEw/7PBheN75z0r1uczP1pokY79ch4A1+Zaez3JmVfyFHHT9hcXmH11gtGnOuBqfpl59S11zh33eaz7MDO8xH2oJ8Djv+eBd2eYXMmbCLvPBxhNprjw2hWuXMmReNhqy6x9TUo2+D4v8sow028AhpcHOoHth2hucpTirPA88nPDVT8vZtDylQQTZy8y+/oVrvy8dF6bXFT9k2VmedVWBpT/wZz1rH3Kx+K43MUDTS7ATctQpbyjfIxb7/LB96aYMcG1I8zElVlSiShdRn7F5TQi8uG3YWH59OnTzkk1p623vhdvtiV3ebFzGcyFlsc9+EiTXBQAby9WgAyAvZxgBRkgejZH7oiPzEJpQ6Wk4vZjvRmI+DKVN05jaz/avodK18sdsP7IriI0r0S5Y1Xxxjr8Wf649R/zUoye3h7Ha5CTzuVXpTTSw40M03++uPVxpYrvrnzd5H99kM7DJ5i6XMDl9tH2tREmElaN81LzbkbDZqsH3U3dh9LoIOWShBXbHeX5oUO07diK+U9TTP3lMD0vrWD/G3qfa8kT+2kGcON7OLBQgrFQinOz51FD+IUEA1/04/l4lvTUGWLHYsys4N8qmg0+AXDdrPFvlKv0ZjXP1KLr1cM3jk/B1WE69wcZ/Ms02XcNvP4AA8kU0Rq10iLy0bRhYfnpp5/m1KlTXL9+nevXr3Pq1Cmefvpp52K3httT3dJ8j7u6pWKl4kEm56yygfBeH2TOV1om3yzUDumluuaq1tL1Oh6wtXQvTMG9sDGr9dtMD9asw64vSnMTi8omllTv/Cm3ai0utyjvZ/6Xddt3V2aoGS9ZkvVqu9fEqutuHKtRs75GsatW66r3vgFb0AvwgNf+NGQovG1r2Svx9PuqW/rT1ygARpOPhplxxk/bX9Ms9eH3skojPaz3cHH1efDt8JAZG+bg/vu59z+fJHsDjN/dT9eS827OVKmVu+o+bLd+d5ZWHh3kJoaL62jG6wJz5jn2hXroGThBw121Om06bOR9riM/MM3Mu+D2tTOwyws3Msz8oBSIb/Y8Fgmz5/MGkGVyT5CDvX0MTxsYtW6BsY0v2IJsy94mq4ziV6/XqKWPkbkG4OG+3abjeo0zlc7DDh++q2likSCtX3iQ/lcK4PKy54u1SoRE5KNow8IypcC8Y8cOduzYccuCcvQRf1U5QOxcBtPwE1gIalFSiz6iz1JYSR1vqRbWuyvBHh8LHfvA/rG9vcNamMST/kpd84qPZyXKNbaBqt760bP2cokY+QJVQ+mFE92LyjBiv5x31Pcuvh7V262h5vlHSZ2NLgzp5+wgGD0bwGuutnV+8TnxZgGTBjwL277Za2oTSpBaNDrAOvveNJmi9ZH6xPkEo8NxJi4O4N9ir0Y+yZmZgvUx8p9dZCI+wmjiAhMHvNU1y6ef4/xbRauG/0yKxPERRobjjL08y8SgfcHVs0Z6uJXDxbURiU2QSowyMjzC6Dfb8WwCCtd4fcl5Nyd/wnEfjidInYnQ/PFlvi2jPDrIzQwXZ1rbNpq7SAyPMJq8QHezc4y4DKYJ4KV9Ms7omQTR9bzP/2JSBIzmxxk7nmBstN7zPsz5N4rg9uP/lONN04rOYyXmS19O4mXPmVFGhuOkfrwfzw3ncgAe2o5bvwvxMxcZfdgD5Jn+Xu3nc/DHVr2258AoF8/ErecmkeLiy3Gr0aLrGcYuThAfHmFkeICuz7uBIvNz485NichH1IaG5VvC3sEvlyNAsnr0iHiQ42lzYVi4XK6ZmWPWP54VVvAsD6G05FBRh2fINvnxFyoBuKzvodIoDLb6YF9mkMaqDnYrOZ4VOtxaGqWicv7Nl6rLLPoesr6opTy/m8nFZRilzouBXHl4NKtjIqXrYW13+TKMxecfgFJNdSy4k8E0Vg1wvXu1Qn0vpjFL5zSbCJeuqX3bzcysQxlGg+38c52QbLR3XlwHVwf56rFxsm+Dsd1PW4cfI3uSk/9UHdKSj3+DWDpP8eNufC0dtN1TZPrbU46ayjR9X/kGJ/+xgLnFi//hDjoOtODbMs/cWi5FeaSHJYaLW3/z5Avg+d02Og500LbLoDg3TeybBxlfct5Nct6HtmZcmdii++BkjQ6yuuHiFhwbJvaPBYof9+A/0EHLJ+c4vqh8Ic3gqWny74Lx2RbamlyY63mfnzlO8rIJLjfND/tx37Ba2Gs5MTmDiQvXZpOZSVsoXdF5rMQ4/c9OkTXBvaONjo5miuMnmbnuXM7qp3LypXfw/LsOWna4cb2dZeqZr3LwnHPBkniQ4DNTZN8G944W67lpboBfZa2W+Pw1TJePlgPWtfRSIHN6kK+u58dIInJH+9jdd9/9a+dEWUqUVKkGeHWlDSJ3Hv9fXCCxz0Pmhw+yb7Ud2O5w0ckcgc+apI/VKkc6xNjrvTRfn6bv/tCKOj2KiMid6c5vWb7VSvWxi0d2EPmwWcNID3e6vaP4PwvcyJOt0WK52tFBRETkzqWW5VUJk5i1SivKX4YhIne6MPFXu2kqZHgjW8Dl2UXzLg/GJjBfGWTnl/S7LiLyUaaW5RWyhmCL4C8kFZRFPlTmmf9XaLjPT9uBDlp+24PreoHM6X6CCsoiIh95alkWEREREalDLcsiIiIiInUoLIuIiIiI1KGwLCIiIiJSh8KyiIiIiEgdCssiIiIiInUoLIuIiIiI1KGwLCIiIiJSh8KyiIiIiEgdCssiIiIiInUoLIuIiIiI1KGwLCIiIiJSh8LyMqJnc+TORp2TlxZKMJubJRFyzlgj53aHUuQW/ZxilUdbsdHbXw/OY1wkTGL2Ju4ZVNa9pecYJZXLkZtNEHbOumOFSbyWI/fzC4zsds5bnfALs+RyOS4M+52zNlQ4Ye03NWT97B9McSWXYzZxyLnoLeE8HhERuXU+NGE5evZWhxwRqaf4PvB+kfecM1br/SJQpFh0zvhgFG+XAxERkVvmwxGWQwnam0xM00vzLW95sVoGP5AWn8OtNDbuJBh3zlgnG739DREjuLORxof6nDPuYB1E//ois1duxzeDhxh9eZYrF+0t4zFC9zfSeG8rfa9ULbxqsdD9NDbeS2sk7Zx1S6Ujrdzb2Mj9oZhz1jq7ne+1iMhH04ciLIf3+jDmJjmeMfG2fpg+zhYBaMDT5MZwOaffDjw0bTNw3ZbHdie6ne+1iMhH04aG5aNHj3L58mUuX77M0aNHnbPXSZg9PoPspT5iwUmyho89znrWcq1tKMFsLkeu9FrcGlyqHy2/lqt7HUqRywXwAt7OWtus3t5sYnGMt8pHyq+lanFrWK6GuHy+tnrYcu1j/WtgU2/7q72Odc7LeSy1rnf1MrMk7nEu4WTVHVdd66HUsvtx+kRwhNRrpeV/PstEf0tl5u4wo2cuMvvz8vwrzE6O0LW9NL+0v9kzcSZK27CukYeOPxvj4uul9a5cZKxva2W7tYQSzOYi+A0AL4FcznZPfHQNT3BxtnJuV15LEe+zHWtNK1ivfA6JQxyKX+BK+VxfSzES9NiWsZ5/DD+RXPlZW1z7vVBzOxwm/vKVheuWOt6FZ2+EhG3ahefClPbgqNUtb7fGa7K8Jx9dwylmr1Tu3YVEhCWvyI5DjJ6tPGezZ0cX9r9g4XqUn6tyrfkE8TOldUvPlWdfhMTLle1dsV8zawk6jiS4MFs651yOK7NjRJa81zZfG+NKLkfu5VHsldz+v7hALpfjYjxgmyoiImu1YWH56NGjPProo2zZsoUtW7bw6KOPbkxgHgrgN7LMHAboY2bOwP/Ioj8v1h+fJ+F4YyONjY0Mpk28nfY/RFFSuQAN6UEay8vMtxNoqtpItcOtNDYmyQLZMWud1sPlmQb+I83MlLbVOJbF8HdXhcbo2RwBkgv7axybx3+kdrBcvSipI35ID9K4M0isFDwivgyD5f0dS9PQWSvsLmWZ6xhKMOu4jtZ5Ve8nejZHxD9PsrxM4yBpd2BRsK9eZhJ3px+jspnlhRLMdjaQPlbehnW/luah7b+1wJtTTF8uUNxk4PvyQKWz2mf30Lz9PbJ/P8746SlmCmB8toPIt6s7fxk7/Lime3iw9Fx4jnyXbwWbcbtMsukppmbewftYmxU263nrPGdOT5N9F6DAzOnSPvEQTiQYOODDTZb0S+NMpbMUDS8tT4yQeGJR3CtZ3Xqu3+qm22eSHp8iPWfCXV46jnyXyHbgJ1OMn56hAPBulunT44xPnCdTtYVqnoe78f1qmql/zFPc5ML7cC8TQ2F876YZn85ibnLh2dvLM19zrgmQ4fzEOOOnS6+JGQo3APJMfbvPdm5euDrN+OlxpufA4w8z8sLiN6qWAPFYL21NBsVChunT0+SNFrqsxLo8w4d/8zQ9e0qlP3ujPD8Uxu9+h5mXxhl/aQZzs5eOI88TLT0/4fgYIyE/ntJzMP5SmvwNF0bde+3wnfNk3gW23ceXFjpQ+vnjz3uAPOl4snp5ERFZkw0LywcOHHBOqjltraK7vDA3Q7lCte9SFpqaF7fGYJJ+1gqNgNUKTaXGOZxox2umOR6s1CTGgjtJzi38uGrZsdaF4+JwkrRp4Ntb+qMdStDelCVpr611LnPTrODvnUuyc+F8ogT8VF0D4kEm58C7a/HVqm/p6xh9xI9RtV/rTUXSvp9SjXn6mO36ECP4bBpz4ZOBKAG/UX0N6aP1WBpz4ecVuMeNwTz5hbrrPlqXrWd2kf2rfbQGDxLa38mZOQAP9z1cmn2uj86dD9IZ6qGn9yCdh6fJA67tX6DDvplr0/T3jpMHwE+k1YeLIjPftbZ9MNjKvu/OsGSXsVdi9Pe+SuF9gHfI9vbQ0ztMcnevFejeneHE/laC3T3W9k5lrDdqf3RocesowCrXc11P03//PkK9Bwk+tI+TbwAuH/4uYGyYnt4s7wC8X+DV3h56vhljyerit5J0Bg5yMPAgsUtFwMAwxznYHqIn1MrxtAm48Hy+6kqWpIl9s4ee3h56ev+G9+7z4d5UJDvWz8FztnN74yT72kP09PYQaj/JzLtgNLfT69wcwFMB/G7g2hQH799HqDfEvvsPMnXNuWA9eaYHehi/av106Cv78boKTH/zQTq7e+jp7qTnXB5cXvxf9MPuEbpa3FDMkuy+n9bgQXq6g7R+YR999e61Y49wguRPCtYz+cVS2/LuL7FrO/DGNMNrrBMXEZFqGxaWb40ozU2QvWQPnDNV4a3CHpgW8zYYmJnzlSC5ZiaFN53TbO5xYyx81Fp+lT+CXYsG2metoFzVyS3koQED/5Hqj6+XbDmvaanrGMbjdtyPkr5LWXB7rFbje9wYZobzzu3Ez5MxDdz3lI+3/InBGhxOkjat61yrDKa2LJkBK+JCnux8KZ5/vDx/F4HRMVIvz3Ll9SvkXmizAqbLRUN5EcDMv2YLjvtp2gaYM0w+U9425J/JlsL0Kj18Hx7A/KdJhktBDSA/kLFazt0e2myLL1jlemb2VVtYyxP7mXW0ns922ZZaufzPBhfO9533rLcJ+cyPFq5T7JfzALg226/kYi3DAwSaXBQvxXjs8LQ1sXRu3NfFhYVn/BDNm4HNBm7HNgC6dnlxAfmfDlLaCjDNa/kVviUzr/HaQjjt4oEmF+CmZajyO5Z42Hr7sfUuH7Q04QGKb0zRd86+odVJxtPkAc/nv4Qf8H/ROvfMT2M39zyJiEhdGxaWT58+7ZxUc9pahBPtVfXC1qtUQ3wndPQz05WSCNurqlX2ZpWDaZWsraTB9lq2pfVOVhodozHJvD9CblWhuRY/0e99i0NtPra+PcPUVJLh3qmPTEDZZXwCgHfM5YtZVqr47pJt0Yt4nkgwcsADb6cZ/tPhyrUvvZkxL8VKrc/21yAnbdsoc22y/lu8sR530AWbsMpCFu2/h28cn6Lcc6/43jvOlVfnlWGm3yiXYvj50uc98O4Mkwtv8kREZL1sWFh++umnOXXqFNevX+f69eucOnWKp59+2rnYGlgd+0x7bWz5NZaFWh39lmH49jgCptVSuiHeLNhKDtbTPJM7B0njJ2L/oot4nvmaLe7rKUa+ULusI7rLC4W81XJf79xDe/AZ9hb5Gsd7j3t1NcsL+mgt1Vgvvs+rsZ/mz7rAnOG5/SF6evs5cZfBMt30gAyFtwHDywOdlameft/SNcv1/PQahfIzW+5YCHj6fFbr6rUsU7bFF6xyPcPzBVvnuBb+42+6gSKFn60u4K6b7WGiX/VjUGD6fwaJ2VrHSZfOrclHw4yttvn0OOOnp2vWUseuWi3Z3vsGbOUnAR7w3sxTFiNzDas8Yrfp2P84U+l85Rh/q51e2/VfvTz9/5Cx9vVEN83boPCTJCeci4mIyJptWFimFJh37NjBjh071jkoV4JV5lyNVtibqP3tezGNafjptrU6hhPdKyiLyFIwoeHTK98XVEoO/E9Wt4BHz9bo/b5qMYKLAnMfM3M4OjVCOJFapw6Flr4X05hNgUWjUQSaTNIvllqw40Em5wz8R+zHEibxpB9jbtIa17lcT+3shNm5ymg5lFplB8blmBRvAEYzXS+MMHJ8jAuHmll+pK+TnJkpWB/R/9lFJuIjjCYuMHHAu3TNMgAZTBPAS/tknNEzCaKn+zlzuWiNQnEmReL4CKOJFBOP+XDdKDD1g/7ard2rXW9bGyPnE4wOx5m4OErbNqsW+/h3ygsUMN+1rsfjyVESydE1vBFZTgvRWC9+A8y3Mpj+EUaGS6+vB+D0c5x/q/rcRobjjL08y8Sgc1sl35smU7RKNyYWznMA/5bl70otgz+2auo9B0a5eCbOyLB1fS++HLeuy+l+zrxRhM3NHJq0noOR+BgXXpsoPec17rVjHwuOTTLzLnh2+3FTIPPS4upmERFZuw0Nyxsp+oi/dt0rADHOZ0wMf6D+HxqneJCdx9JQ+qg+l8vRzfEVdPCLEUxlMUrrrTyY2QKtrYa4fT5p69C2FjGCO5NkDT+R0tBtfQ81kpyrrpOONMys75eO1LiOuU5IOr7cZPGxRPBlBqtKQhYv08zMajv4Ocp0Ir4Mg6XRQW7OIMPPz1AouvDs7qCjxc3c91ZWhpF8/BvE0nmKH3fja+mg7Z4i099eybppBk9Nk38XjM+20NbkwiTP4P6DxKazmC4v/oc7aPN7oZBh/H90cnDMuY2y1a1npk8yXfTRdqAFn9uF+dY4/YcO2up7hzn+VxnMGy7cv92G/5NgtdVugCO9BJqstyXGZ1voONBRebU2A2n6vvINTv5jAXOLdW4dB1rwbZlnrl7VyNVBvnpsnOzbYGz309bhx8ie5OQ/3VxYJh4k+MwU2bfBvcM6xrbmBvhVttSynWfwD0rXH+s56Ph3PrZev1YapaXWva6n3NEPuJrmubr3XERE1uJjd99996+dE0XkI24oRa7Ti5keXJ8aetkQgfhFoi1uMj98kH2qVxYR2RB3bMuyiMhHW5j9zW4oZkj/QEFZRGSjKCyLiNxRIowmE0xctOq38y8NM2jv6CgiIutKYVlE5I5i0PTbfnz/BvLnBnm0t1JBLiIi6081yyIiIiIidahlWURERESkDoVlEREREZE6FJZFREREROpQWBYRERERqUNhWURERESkDoVlEREREZE6FJZFREREROpQWBYRERERqUNhWURERESkDoVlEREREZE6FJZFREREROpQWBYRERERqUNhWURERESkDoVlEREREZE6FJZFREREROpQWBYRERERqUNhWURERESkDoVlEREREZE6FJZFREREROr4yIfl6NkcubNR5+TVCSWYzc2SCDlnCIRJzOaYTYSdM0RERERue2sOy+HELLlczvZah9AYSjBbtU3rtRC4yvNnEywVwaJn1+l4REREROQjaU1hOXo2R8SXYbCxkcbSazA971zsJpmkj1W229jYyM5grGq+iY89dYNwlOYm5zQRERERkZVbQ1iO0txkkn42iD3CxoKtBOO2CRvKwP9I7RKKcKId71yWrHOGiIiIiMgKrSEsAxj49i5VCMFCzaq9nCI15Fzm5mRSacymZhbH5TB7fAbZSzPOGXVVl5OkFm/TWRqyVJ3zQg2z49yd6wylqktNnPNLatdVL64FXlQSU7WOtbzz2ocTsyssZ6l3/6Kk7PtcquylXm33UKr6mi9xra1zrHF/RERERDbAGsJyH61jWQx/pEaQK4uSykXwF5KVcopjaRo616nD15tBJue8tDu3NRTAT5rk4erJdTUF6OZ46RgHSZteAvZzCiWYPeIjs1AWMkjaHVjivLFavY90w7PldZJkm2zrhBLMdjbYSk2SdVvB+y5lwfmmILQHn2GSOWe160fP5oj450kulK2UjnGZILyccGKWgDtdKbUZsx1lKMFsLkBDerByf8fm8R9xBuqS+HkypvMNVphEqxcznaSPm73WIiIiIhtjDWEZONxaCYGLWjJLpRBmmsGH+ioT40GOp00M355lQpyB/8jyLZZ9l7KLthXd5SWbqi4PWZKZ5vhCPXSMYKo6nEYf8UP6uK28ZPEytWTHdtrWsd5cLKxzjxuDefL2+fbrZHc4Sdr00mwLoOG9Poy5SWv7oQTtTSbpY61W4ATrGJ9NYxpL1XUvz9tgQCFfuZaHW2ktvQmJPuLHmEtW15IfbiU5B95dta5MjPMZx713hv5lrnUsuJPGRvt5ioiIiGyctYVlsEKeveXU9hG5t8HAzJxfFFpj5zKYhhuvY3o1Zwc/e/C0OZwkjZ9AOUiGErQ3ZZlZaasyVIfBRcJ43Fgt6PbSgM6ljx5MCm86Jr1ZwKQBT6gSgAP2UT7qskJmJYCWy0xKkfEeN4aZ4bzz+pRact33OKavQt+LacymQI03K9Z1WTgGm75LWXB7ar4ZigUnydoCfFXov+lrLSIiIrIx1iEsl/XRWiphWFQWsaGslsdykAzv9UH5I/11lB2zB/fyay0tnDGCO603GfOlcLhUaI6dy1Tqs0N78K2mzGQt4kF22sorFofm1epjZq5ciuEI/SXrf61FREREbs46hmWAGPkCGA1WS2B2vna5RXivD8Ms1K3RXbXDSdLudhKhKAH/PJNVQ8ytlXVOtcsKVsc6b2cLsNUyP7hcaUrcqs9uHiq9IbC32L9ZqF1uUSpxsLdwN3y6eg/eBqPq57oOt5bquctBt/51ie7yLtlav1A6E9qDz7B/ClB/myIiIiIfhDWE5SgpZ6erUIL2pspH89ZH7n4ijs5y3X5jdTXFy4pxPgO+J9tp2IBWZauDXaC601ooQWqJlmCr5rp6hIduv60sZShVuxPcEvouZfHuSrDHx0KNL5SDtGN/hEk86beVOJTqhf2ByjJDKQLLjEUdPVt/5IlyiUZVi/hQikCTSfrFJe7C4SRpfAQeWfwpwHLXWqNhiIiIyK20hrBsjSJRVVtaGsWg3AHMajW1dQCsuUw9zg5+S39jXyw4ybzhCJHr5XArjWNZvJ32c3Uzs2QLtkl6rED7wvJ+SA9WdYazby/iyzC4c5k3EIdnyDb58RfKAbii76FGknNWDbS1zQi+zCCNtk6DseDxhTrpXC5HbtcMg2mzajuLLd7mwjnEg+w8lgZ7jXEnJOvVly+w3tx4m2rcr5u61iIiIiIb42N33333r50TZY0Whj9bLjSuVpRULgBjK3mzISIiIiJrtbaWZbm1hprxssqRPkRERETkpiks3zEcX94hIiIiIhtOYfkOYHVqs74JseoLQERERERkQ6lmWURERESkDrUsi4iIiIjUobAsIiIiIlKHwrKIiIiISB0KyyIiIiIidSgsi4iIiIjUobAsIiIiIlKHwrKIiIiISB0KyyIiIiIidSgsi4iIiIjUobAsIiIiIlKHwrKIiIiISB0KyyIiIiIidSgsi4iIiIjUobAsIiIiIlKHwrKIiIiISB0KyyIiIiIidSgsi4iIiIjUobAsIiIiIlKHwrKIiIiISB0KyyIiIiIidSgsi4iIiIjUobAsIne4FgaGB2hxThZZie1+2vb6nFM3iAf/Xj8e5+Sb4qPl4fXalogsRWFZRG5/OwL0Do4w8IQ9HPho2esDHqC5rZkHAN/eFm5V7JHlefxtdNzOgW57mPjJKF9qMp1zNkgb3X3dtDknL6fm82/iDY4w9kL49r2+Ih8SCssiclvzfS3BxRd78RvgfTTOxAtha8auAL1/McbFhAcK4EleZGy4m/27nFuQW+7LcS7+PMeFxCgjgzcRDm8JP9Hv9eL72QmC3887Z0L/GFd+niOXs71+foHRAwAB4hcd814fI+Lcxjqo+/yTJxb8BjOf6eX5IX2uIrKRFJZF5LbleSJB4ikf2Wc76ezuIZjKYuwOEN0OXOpn3+c6eeHd+/Bu93LfOy/QubOTwUvOrcgt98MQ9/9GiKlfOWfcPjxHIuzfluGFx5POWZaBTu79jUaCE6Ug/Xaa/t94kIOnAZKEAjEy7xbJTw0S3NNI4+c6GXRsYq2WfP4BmObgs2m2HogQ3V29roisH4VlEbk9bQ8T/aof440z9JVb/uZNTBrwtAG7IozNjvGlrW+QvZrlja1fYmw2wSHnduQDMs07153TbhcBBvb5MH+S5IRzlkP6z6fJ3ADu8rKnszy1hWgsgOulgzx4MEb6avU662K5579s7DnS17zsf1JPvshGUVgWkdtSy9e78BtFZqb6WfiQ3OvGwMDtBS6d4XhvJ/cH8uCGfOB+OnufY7p6MyKLhfbT7C6QmajTqmx3tZ/JS0XAjT9wyArKZ0fY84vjPHZ44562ZZ//BWl+lMnjum8PvfbJIrJuFJZF5DZ0iO4WD7yb4fx3KlPDn24ATApZgAzT5zJAlsxPMmSBzLlpMrat3Coef5iB4VESZ8aIDw8Q9ju6XO1ooeNAB4f6Rxj5eqC0fJTezuruiB6/1ZFrpLQNz75eRpMpJuKRRaN9ePxtdBzoWuj4xXY/ga9HGanargf/EwOMDI8wcLB250dfZy/R4ThjZxKMDvYS2GGf68H/cAcdByqvlh3lfVdPW5XtfsL9I8STY8QX7bPMR8tB69ijXw/gw0fXYIKJyTFGgrW6tHnoeCrKSH8Y/3brZ+vcF9+PDr8Xw8zy6umqyXWdSKYpAK5d+0kkvsWe+eN0Ph6rhNh1t5LnvyL902uYm700P1E9XUTWh8KyiNx+vrYH32Yo/ixt+5jcw+f+rQEUKRbsCyfpC/WxgjbCjdEZZywRIfCZeX70gxd4DT/dL6RI2TtdtXyJ/97/LXq/3EHHgTDPf2s/vt8JcGgoTrz00X5L/wQTL0Ro+yTg8vF4/AIX/qyF+f/jwtfSQntlawDs2tfN0cEBDn2xg/3/qZvUiwO0f/IT4PYTHhojNRwh/vIYA7+3FVzbaP/TOGOTUfy2bXiOTDA2dAj/5ld54QeTzG8PMPDjiySeKIfLXex/7L9zdHCEkeERRoa+Rfd/gl3BiPXz8Ajf6v/vfMmZ5JfgCY5y4f+K07U9z/kXX+A1Woj8+CJjfbaNbA8Tf3WM0S4fLqBhb4SJn4/R7c5T/GQzLQ8v7jLoOfJd/vverbj3RkicHCPx8hgDDzaAq5nuFyZs5wQPfMYNhTyxqi0sYew5Zq4Bm7z4/22abwQ3Miiv9vkHfphnHoNtv1nrTYSIrJXCsojcdrp+x4sLcN0X5srrV0qvFB3bgXfzZFbYIrhYL2Ovlbe3stdscpkPtz9lYACuLS7GT49zovcxzvzMhbczUumI9Z0Q9+8cJm0Cn9zK3MA+JrMFiuY8878Ctg/Q+6gP1z+fpDXUQ093J8/NmGA00JD6KqHHn6LPsdvxyD52to+TB4z7DNKPtBLq7aHnSyeZMV14D3RhnO5c2F7yn4u4PtvMfts2trkNXMDWLUXGT5+kPzhM+l/d+L8axRpzYZy+/3I/O+8NMX4VeD9P9qcwfvoNCsUs4//1Qe7deT8hW+vnkrZH+O6RNhp+FuPR0DAnT49zIrKPnqn3aH7iWwtvHAL9j9PyyXmmD3dysLeH0FemyW9yYTSYPHUwxMGIM+Z2MPCwQTp6kIwJbPPCX4VoDR6kp/urTF8z8D82QAcAYTxuKJrOxLmUNK9mK8PLFavmrb/VP/9ZCiZs/eTiNxEisnYKyyJy2/F9ygAKTEfu5d7PlV7PZ6yQ8osZhp0rrNgwnV+wbXMFr52BZfb2nacIdR8k+JVynM2Tf8cEGvDsdSwLYGZ57RzEQvdz78599L0C7PXi2QTF995xLOym6XfK5SY1XH3PuiY/S9Pv7GRmzjD5TKX98533Fke89H/9KqHeEMEvnSxNSTJvAoabqrJYpuk5liSLl/19o8T7/WSfeYye8kgRK9RxZD8+F2QvDVe1zE7PXMPEjf8R641Js8cNFHnnldICpfN0bfPRkp6u0aHuC7jNS/zolTC+bUBhhh99p3zNtuHaBLi38YBtjcXXur6WvjG6fUUKN6wSkscXOvptjJt9/l2f2OqcJCLrQGFZRG4zVsufswXtkN+HiyIzU+s9QNda5bm26Qs8/r2LzL5+hdlXU3TdYzgXWtq5DPkiGA1exxdM5HnjpaoJNZnvzDsnrVCGgvGHDLw8a7Wiv5xiz6ecy5Sc6+OxRAaa2mh51zZCwyo84HEDJub/1znH4vpMM13AzC8K1puNUGnG9k/gAopzr1KO9dX62dfeQ3r3F9hmgJl9lfGFeXvY9inALOAo9V0RzxMJvnWgyAvh+3mhqqPfRrn559+1xe2cJCLrQGFZRG5PhWu2OuRD7LnPBdemOb7Sj/xrWtxhbdnXMl+F7D8ywcRfhGl+f5Kn/9O97HyglZNvLvGNcLVqZa8OkvxpAT6zn1PJUUYTF+j+Xcj8sJ+ecuvqBgiPXmSsvw1P9jk6P3cvO3+/lfP/4lzK5noRs1iEz+4naqsBXinzfQAXrnoNoNdNskDy2CTZokHzkyniw3Emkm00/Gqa4a8vM9Dbw014KJL9R9sVfqoZ7ybgWmbxdV/O3ijPf9XN+UiQE5ftHf3aGVgY63iD3MTzb/6fm3k7ICLLUVgWkdtMBtME3n9v4aN6T387zZtN0j84uMah4Zpo3v3v+fereTUvFZY7eHyfD+NGhjOH+q263ipdxM/E6XJOXiRM++ffIfkbnfS/+Hf83dgwPf95J/sG1na2S4uw/z+4cRXSDIdO1BhFZICJMwOVH/dGef7LBucPD5N+28D/5DP0rjIwnp/LAy7c2xxBe6sLF1DInicNcMhPw8wgrQeH+ZtX/obnBkK0PhAituj6Vuv9TQ+QJ/vjyjSrRdYk/eNyi6z1fBn/r+pCk0X2RkkN7+Hadx+j71xp2thzVgnIJh8tf2rvKrmebub534rr48CNxaU2IrJ2CssicptJcz5bANdWa+SGHQN894tesmM9BOPOZVdrmhORHnp6V/H69grG2dhkhT1LgAe85TKMBoy77POAf+OpEZ6LcMNL+5lu/rAU0v/wT6L0frn2cG8LSuUJK7eVhgOOSS4XC0Uj2yNWzS/A7gaMzdbWPfsijA0FcJ17jL6JGMH/OU1hczPhWHTRkHZLSf/Xk6TfBs/v2IfC89C724ermOHMQOlavw9GcxfRzv9ovWHZ+8f09h+izTkkX5UwzU0uwMUnyovtHSXw2y4Krxynb+HZSZM3gbsaSh3+nDz4nxghNRyAiU5CVeUm1pjGAJ5dX1rVua/cTTz/2z24N0P+rdpFKiKyNh+7++67f+2cKCLygdoeJvHjXrz/muc9twdeGeTR7pMbO1zXTfI8EefUUy14inmyvyriMlzMjafZ9uUAXooU0sPc/8v9XOn04Son22KR4ltJ7t3fX94K4fgYkZYaNafFLMnu1krrZknXcxeItHiszmsAxQwnxyDg2E9mLAkHAvhKwZcbRfLTgzz4+Ela+icYedSH61+z5N+GrYbJ5LhJ+2MtuN83yZy+CH/0EL7yPt5O0/+FILwwy8DuUsS+UaT4hv1cgC/HudDXgqfqOO5l3zeBHV2MfLuXtk++Q/5XRbjLg6c4w8mBIIPlc/QPkIp34a3xTqDwyiCdX6oxdNvuUS680EZDoUDx4+8xX4CG7VuZf2mYx3qrnx3PUIoLB4rEfmNf1VdUR/56lvAuW735DZP0n+8kOGr9OHDmCl07bAd1o0jxF1P0PNTDVGXqEsIkzu7h/EPBpUtCVvv8PzXGla8ZnNnTSt8yre8isnoKyyJym/LRcmAbxZmpGqMf3G48+B/ehdtlMne6/MUoPnw7MmQuO5ddzD+YIn4Apg7bR5jw4H+il4EnO/D+IkbjH9Tv2LU2PloONGEUC1x6KW0Fsu0+fGTIbOR139FCh9eg+KtLTKXtMTBM4rUIvjeHCQZt5SE7Agz09dLlh+ne+wk5hk/zDKW40OklE29k35kWOrzY7oXD7hEuvNBG4Tv30vmMc+ZGWmFYhlU9/4eSV+h1TxHc02OVsYjIulJYFhH5gEUncwQ2JWl8yDmaMoQTs0TuydD/hWCdkSA+ZL6cYLbfR+bYzsVlB9tHuHC+g+JfNtIaqZ7V+9dXOLQrT3JFraseev86xSFXkgf/wPZ10htuNWF5hbb3MvZ/heH5VjptQwWKyPpRzbKIyAfsxI/TmJ9pZ2IwYKtR9tBxJMHjzS6y5577aARlgB8+x+Sci+ZwnF57jfKOLka+14Ln7TTJ79lX8NFyYICW33SBaWI2t5W+7nopeYafOUO2qZ2BDR4zeaO1fL0D37+c4biCssiGUcuyiMhtwLOvl0g4gH97uSbWBYUZJk8N0vfDmsUEa7e9g4Fvd+M3XJA/yWOP16gF/kD46BqM0NXWTEP5+/I2FcmnkzwXHa4edeRAlLGvNFc6KVJg+liQwRUMued5IsHYY/BcILjsSBvrY51blveOcuEvmkj/18U17SKyfhSWRUQ+klqInh2h+VIPrYe9JGa7MLsf5OAKQuaHSUvfGJEdaVqD9b4Xbz11MJr4j/xd8KDtS1NuVpj42Xby0U76FZRFNpTCsojIR1DL8AXiu+fouz9EkjCJ2QjulxbXAouIfNSpZllE5CPnEN1tHvI/fa70LXFe3Kv8hm4RkY8KhWURkY+ap/bg22xybc5tfaX31700YFLQtyWLiCyisCwi8hHTtcuL6915itusbwv8j3u9GDfyZJxDtYmIiMKyiMhHje9TBlybIdTbQ0/vj2CzAT9LV32bnYiIWBSWRUQ+gsz/U6q52P3H3PepAtM/UFQWEalFYVlE5COmYBYpvjsPeAgfbGHrT56jf8y5lIiIoKHjREQ+gjpHufD1bbzxMxfNW9N8Y38/085lREQEFJZFRD6idrTQ9v+cYyp9e3xnn4jI7UphWURERESkDtUsi4iIiIjUobAsIiIiIlKHwrKIiIiISB0KyyIiIiIidSgsi4iIiIjUobAsIiIiIlKHwrKIiIiISB0KyyIiIiIidSgsi4iIiIjUobAsIiIiIlKHwrKIiIiISB0KyyIiIiIidSgsi4iIiIjUobAsIiIiIlKHwrKIiIiISB0KyyIiIiIidSgsi4iIiIjUobAsIiIiIlKHwrKIiIiISB0KyyIiIiIidSgsi4iIiIjUobAsIiIiIlKHwrKIiIiISB0KyyIiIiIiddy6sBxKMJubJRFyzhARERERuT3durAsIiIiInKHUVgWEREREalDYVlEREREpI6bDsvRszlyZ6O2KWESs85pUVKL6pSjpHI5cqXXbCJsn7lofm42gX2J8n6jZ53rL7WeNW/xvkRERERE6rvpsNx3KQtNzSxE49AefAbV04aa8TJPPl6eYOA/0sxMYyONjY00jmUx/N22MB0llQvAWGl+YyPJgp+IIzDTFKD5kjV/ZzC28vVERERERFbhpsMyh2fI0oCnFHTDe30Yc9nqaZ9ugLkZ+myrZcdaKz8fTpI2DXx7rUgbTrTjnUvSeriyfN+LaUzDxx5767SZJmlbZvn1+mhdCNYiIiIiIitz82GZLAVb0PU2GGQvtTIzV54WZo/PIHvJHpVNCm/afnTwNhjQFKiUUuRy5I74MZwLFvLYY++K1xMRERERWYU1hOUY5zMmhm8PYaI0N2WZOWyVZxi+PYRDe/AZ1rTVMNODC6UUlddOggulHLXd7HoiIiIiIvWsISxD7FwG03DjHWrGWy63ODxD1nDjvceN4SjBWE52vhy+V+dm1xMRERERWcqawjLx82RML4FOr63cIkuhNM2czzpWWJoVvv10V41aESVVNcLGYsuvp9EwRERERGT11haWS6UYYC+3KE8zyZxbZYe6eJCdx9Lgj9jqj9spvLhM+/TNriciIiIisoSP3X333b92ThQRERERkTW3LIuIiIiIfHgpLIuIiIiI1KGwLCIiIiJSh8KyiIiIiEgdCssiIiIiInUoLIuIiIiI1KGwLCIiIiJSh8KyiIiIiEgdCssiIiIiInUoLIuIiIiI1KGwLCIiIiJSh8KyiIiIiEgdCssiIiIiInUoLIuIiIiI1KGwLCIiIiJSh8KyiIiIiEgdCssiIiIiInUoLIuIiIiI1PHhCMtfHOXClRy5nO318yuM9VmzB/7WOe8CowecGxERERERqfbhCMt/eZAH722k8ZkZigA3spz8D/fSGbVm9/9BD1O/gsI/nqRvfyONv/EgB087tnFLhUnM5phNhJ0z7kxDKXK5FKXLvWLRszlyZ1e7loiIiMit8+EIy2XfSZIuAJu8NP+JpzTRQzjx32n+34N0BvpJXnasIyIiIiJSx4crLJPkuX/IA+Br6cWPh3BijO6tk3wjGMOaI3euKKlcjtSQc7qIiIjIxviQhWVI//k0mRvAdj+98efpbjhPzx/0M+1cUERERERkGRsalo8ePcrly5e5fPkyR48edc7eGFf7mf7nIuCmubnA8XDfBxCUrRbQSqfCWRIh5zKWcGLWtpyj7jeUYNa+ndkE9irn6Nkl9lGuIx5KldY9z/9ds07a2VrrOHbHPlm035XWKju2W7NW2XndbNseSpHLBfAC3k5rfvmYq69hrXMUERERuTkbFpaPHj3Ko48+ypYtW9iyZQuPPvroLQvMyTdKBRcfd+G66py7As6QWvWqH3yhvG6AhvQgjY2N1mtsHv+RxeUDhj9CN8cXlkvOeQksBMQoqSN+5sdK22gctOqxS6JncwRIOvbhPDYvgV0z1vyde/j/ZEwM356q8BtOtOM10yQPUwqrAVjYZyPJgp+ILTBHz+YIuNMMlvd7rEB7p9e2xVqs7dqvyeB8O4Gm6qXCiWYKx2z7nvMSKO/7cCuNjUmyQLZ0fK2lYw40TFauw7E0+COLrrWIiIjIzdiwsHzgwOKx2WpNW2+e4Cin9m2lYAKbm2nvL3f0W4V4kJ3l8LXotZNg3LlCRfQRP8Zckp3BWGXi4VaSc+Dd5WhNdSzX91CSLF6ah4CQhwZMCm+W58YIPhQkhhXI25uyJB8qjY0HcDhJ2jTw7bVHYZP0i5VlYucymIaPPQuBOswen4GZOU+sHJznkqUQaul7MV1ZJ5Sgvckk/WzpOChdq7FsZYUayoH8uO1cY8GdJOeqFiMWbK26tn2XsmC4WTqK99Fqvw7x82RMaPi0WpdFRERk7TYsLH8g9kZ5/utNXPpmJz0X7B39bpUwHjdkL9nCW0nfpSy4PVWtuua8M2RmKZSDXjzI5JyB/0iNkoV73Bh4CVS1eEfwG9WLwTx5e7AvbXMhUIf24DOyTJZCrLfBgKZAdUv6ET8Lm73HjWFmOL/Em4VavA2VQL6cqpKKZVusy+zlG7Wug4iIiMjN2bCwfPr04oGMa01bN9vDJAb3UPjuY/RM5Ks6+j3e6Vx4GWspw1hHfQ+Vyi/cpQBrD82mrRTC9qpq0a6h71J2oRQjvNeHMTeDPdqb9vKRFbamrw8r8EZ8mcp5LdNizUK4tpeODJI2nUuJiIiI3JwNC8tPP/00p06d4vr161y/fp1Tp07x9NNPOxdbH9vDJJLdGC99g+D3S/XKV/uZvGR19PMHDjnXWNpNl2HEyBdqlFsA0V1eKOSXbl0N7cFnmGTO2ZeKEdxZCo5NzVY985sFRznFKhyeIWv42BOySjDsreDZ+cU1zYvU2G/40w3VE2pYvF2rFX7BUDNesiR32ko8llUqI0kPVpWOiIiIiKyXDQvLlALzjh072LFjx4YFZV/nAIkXe/H9bJh9A9XjXpxIZygCrvv20Lu9ataG6XsxjdkUqB6RYShFoKm6fphSB79KR7QwiSf9lTKHUIJUvVEd4ufJmAb+J52jY6xkZIo+kmnwPRLAR7ljn8WqafbTXbXfKKlyi3apLrpqv6EE3cvUPVh1z9XbDSe6q8sl3ixg0oBnIYhHSS0qw7CVqcDCmxOjobLcou2KiIiIrMGGhuWN1HH8Ald+nmNiqAv/J10YuwdIDTUvzO967iK5rzXjwurod+h8jiuvjdFr38hGiAfZWRqRoVJ7C8kaLdJmOkmh1VZrS5pBW8tqw6JttJZKJmIEdw6Sxk/EViLSPp+sKqmoJ3YuA01ecNYR1zr2XDuFhZBfY79PwvHlyiVqbLeb49Ud/OJBjqexarRzOXK5ZmYWbTdGMJXFKG0nNVTqFGmrs+5mUmUYIiIism4+dvfdd//aOVFERERERO7glmURERERkY2msCwiIiIiUofCsoiIiIhIHQrLIiIiIiJ1KCyLiIiIiNShsCwiIiIiUofCsoiIiIhIHQrLIiIiIiJ1KCyLiIiIiNShsCwiIiIiUofCsoiIiIhIHQrLIiIiIiJ1KCyLiIiIiNShsCwiIiIiUsfH7r777l87J96J/H9xgcQ+T9W04rtFAFybXdaEt07S2N5ftYyIiIiISD0fkpZlD/vv80CxQPqHfexrbKSxsZF7P3cvrc/OYAK8nWbwKxsUlIdS5HIpos7pdqEEs7kcqSHnDLswidkcs4mwc0a1lexv3azwmD70rOuQO7vSq77C63ZL76WIiIis1ocjLG8/RPNnCkx/836CA0kypcme4CinnvJjFLMkDweJXXWsJ3WFE7OrCIYiIiIiH04fjrDc5aPh0guExmzT9kZ5/kgbno8XSD/zGH3nbPM+CPEgOxsbaT3snHE7ihLwQ/rFPueMFQknZsnNJlimTfUmrLC1dkPECO5spPGhm7smIiIicmf6UITljs0m05MnKhO2h0kMBfC6TNLf7iT4/bx9cVnOUDNeM8P5uHOGiIiIyEfLhoblo0ePcvnyZS5fvszRo0eds9fNeCRITznYbe9gJNaL/64i2bGeWxuUS3XJudKrqj45lGA2N0si5JxWWX424bXNrIierSxTr741nJi1LVNv31FSVfur1UIbJtHqJZsKEnPOKnMcd6UV2Wr5jfgNMPxEqubVWM9e5rHcMYYSzOYiWJuO1D/+WtcZZ21w9T4WXdPyskMp2/nVaNV2nk+d1vTqe1P7/tkteS8XPQ+L54uIiMj62bCwfPToUR599FG2bNnCli1bePTRRzc0MFtaiMa+RUeTCzM9zGOHp50L1OcMPlWvGuFrES+BJ+F4qXPhYNrE27lEMAolmD3iZ37MWr6xsZHJhgB+o3qx6NkcAXeawdIyjccKtHdWh+pwYpaIL2NbJk1DpzNEGfiPNDNTXmYsi+HvXnxeoT34jCwzS5SLRB9xM1neTuMgafxEzkYXShUG0yaYpWPeWQrdoQSzR3xkjtnWcwccddFLHGM8yM7GQaxND9LY2MjOYI04Hz9PxjTw7bXHVusNgJlO0geEE80UFo6jkeScl8CioOslsGvGWqZ8Dg71r0OF4Y/QzfHqfS0RmJe7l+HEbPXzMJZ1bkJERETW0YaF5QMHDjgn1Zy2fjyEEyMEmlyY6UH2BWNYbcp+wn2HaHEu7lSqKS6HmurXToLLliSYpJ+thKpYcJIsXprrtPpFH/FjzCWrapj7HrLC4IJQgvam6u0SD7KzKiCV6osdy0zOgXdXdSTLjrWyUHF7OEl6Uai0jotSqKyn7yHbdohxPmOC21OzVbXM2u5x23WMEUxloam5Kjiu5BiXZh2P4dtja9Heg88wyZyzrlAs2Fp1P/suZcFwU/0WxFy2ZntF12EuWRXq+x5KLvFcLH8vvQ0GFPKV+Ydb75A6eBERkTvThoXlW8tDx/Dz9PoNinNJehaCMrD7S3Q9/DmsEZc30jz5ZQN1WRiPG7KXlg5j3OPGWK52OOShAQP/kerW8ECTc0GTwpvOaU5RmpsqoXIp9lKAiLM5fBHrfMvlEwsvRwv5yo5xebHgJFnDx55Sq3l4rw9jbrIqIFeVOiw6DlZ8P5e7Dua8s+U3S8GEhk/XeAOwgnvZ92Iasymwwk87REREZK02LCyfPn3aOanmtPXQMvQ83zrgxfV2muFwH/bii0ComU/87O9I26bVtOYyjA9SluSi1vDVj9wQTrTjdYTKRUrXKUByYT+DVc3h9WVtJSeVl711dr30MTNXbpEOs8dn2N6YWPXKVaUON1PKsIbrsLRl7mX5E5Cx+VKovt2fTRERkTvbhoXlp59+mlOnTnH9+nWuX7/OqVOnePrpp52LrZnniQQjnV5cb88Qc46lvDdK2A+ZqXHbxDrWXIaxes4yCfDidjZO2lpIy8Kfbqj8EM8zX/dj/dVwhsrawnt9GGaawVUF8Rj5Qq3z3Th9l7JWKYazBnuoGS9ZknXqkFfq5q7D4pKQKqu5l4dbrTrpVZepiIiIyGpsWFimFJh37NjBjh07NiQoszfK8wtfOtLJYHks5e1+Al+Pc+F4AK+ZYdI+/vJtoVyvG6jqhBc9G6iumy3V7PqfrB5Rorvq4/4+ZuZY1JkwnEitrsVxKICfNMll6l9jv5yvru9ddDw1linXBTvOl1CCVK0RLeqyQrfRUKtswuFwkjQ+Ao/4qmuw3yxg0oBn4dpESdUsw1jaonOscR0odfCrnHOYxJP+JUprlr+X0bP1OweKiIjI+tvQsLyxuogPBvC6AJeXwHO2sonzCaIHW/C4oJCZJOlc9XZwuJXGsSzezspxN19ydPAjRnBnaZSF8rk9CccdZQN9D5VHWahsK9Iws6rW8OguL2bm/PKtrYdbq/f1JEw6yw8OJ0mbpWXKo0zUON/cETcztUa0WEKlZrfO0HELYpzPgLeJ6lbceJDjaWx1wc3M3EwZxkquA2CmkxRay/uK4CfN4BKt2svfS/u8CL7MYO1RQURERGRdfOzuu+/+tXOifMSEEswecTO5IfXDIiIiIneuO7hlWdaLNYzdjIKyiIiIiINalkVERERE6lDLsoiIiIhIHQrLIiIiIiJ1KCyLiIiIiNShsCwiIiIiUofCsoiIiIhIHQrLIiIiIiJ1KCyLiIiIiNShsCwiIiIiUofCsoiIiIhIHQrLIiIiIiJ1KCyLiIiIiNTxIQrLHvxPDDAy2Etgh3OeiIiIiMjqfTjC8vYORiZTjP5nDxgtRJIporudC4mIiIiIrM6HICy3EI19iw7XFD3tIXq6n2PG9NJ+MOxc8I4VPZsjdzbqnFzfUIpcLsUq1hARERGRGu74sNwyPECgyWT6RA/TAFzCfBeMf/s5PM6FRURERERW4c4Oy9t76W7zwNU0z42VJ7bhvgu4y01b9dLyYacWdREREVlnd3RY9v9pB82bIf/PPyK9MNWL2wDeLjBVtbSIiIiIyOpsaFg+evQoly9f5vLlyxw9etQ5e438/PHnPUCeN/6qEpV5wkMDwPV58ral10259XIoRS6Xs16zCcJAODG7aNridUvz6y1DlJR9mTq1ylX7yuVIDTmXWEIowWxulkQoTGJ2qX05jsXRaluupY6etebPJkpnE0owW/c8rX3OJqJV+7aOv3p/i8/JcTy27UbP5sh1egEvAeexOo+n6jwXH4+1X8e1yc2SCNlWExERkY+EDQvLR48e5dFHH2XLli1s2bKFRx99dJ0D837u2w7caKDl/32FK6+XXl/3YwD5X5x3rlDhDE9Vr5WEIi+BXTM0NjbS2Jgka/iJ5HJEGiarpnWXw2M53HY2kD7WWFqmkWTBT6QqgEZJ5QI0pAcXlhmcbyfQtLAAlLYV8WUYLC3TeCxNQ2etcLkUA/+Rbni2fDxJsk2BqiAZTjRTsB/vnJeAM+A3BWi+ZM3fGYwBEH3EzWT52BoHSeMn4gjihr99Yd+DaRNvZ45crn1hf9a0xdeGMcf1Kx1P30ONNI5lgSzJxkYaG1vpo3Svj/jILJzHIGl39XniOJ7WwxA9G8FfSFbuQ3q+ankRERH5aNiwsHzgwAHnpJrTblqo1IL8s5Pc+7l7S68Q0/8CUGDunK212SkeZOdCmHO+dhKMO1dwypJ8qK/0/30k02bNaYZvTylYRgn4DbJj1dvueyhJFi/NpZAbTrTjNdMcL4VOgFhwJ8m5yjrWtiD9bJCFpeJBJufAu8vZMry06uPpo3UsC03NCwE1FmytPt5LWTDceCuTwEyTPGyfAH0PlYIqADHOZ0xwe6pCtpk+vrDtWHCSbM1pjmszl6TVtq++F9OYho89S7y5iT7iB9t2IUYwVX2eAMxN2pYJ43GDOZ9dmO28FiIiIvLRsGFhecPd417cgrz7j7lvG1aHv9P2hW8Bs0AlWjmEPDSQZcYRKqGPmTlo+LQVI70NBmbmfCUE1xLy0ICB/0h1i7iz9Xl5JoU3HZPeLGDSgMcWPqvKPTqrYrKlkK95vOXSjFwuR8RvOGfXNP/LWluyeBsMaApUfwpwxPoUoT4r9Br+SPV6Nc7DHozLgdpaTx0GRUREPso2LCyfPr04rdaatjYm1/650oLs/6NdeCgyMz5s6/BXw5rLMD5o5VIDx2uhZXs9WPXBVeUeY3XfDlSUrm0AewmD6Vzqppi28pTVfBKQtZVuVF721u8aDreWjr1hcQ20iIiIfGRsWFh++umnOXXqFNevX+f69eucOnWKp59+2rnYzfsXkyLA++UJAR7/PQ/Ft84w/MwyXfvWXIaxSvE887aSgooozU3VLaqV0o0yq3V0Qd1trV14rw/DzHA+Dgw14yVLcqet3GMFrG2kGVzX4A7ZeXtZy0rFyBdWX55iFwvutOq5N+iai4iIyO1tw8IypcC8Y8cOduzYsb5BGeDHGbI3XLi2AnjoivfS8vE0w1/pW7pV+QNh1TB7O6tbraNnA3htNb9WDa6zY2A31VUMVulGdec3CCdSq2wRN/AfqR4xottvKwNZVJIRJVWjfMEp9sv56rrm0nbXKnYus+jaQJSUvaPeomMu1Vk3Bao7P4YSpKq24xQmcbbWSCUiIiLyUbOhYXlDXe1n+HQe35cvkDo7RsSXJ3Y4SOyqc8HbQyy4k8E0VbXGAZI02ltu40F2HkuDrca2m+OODn7WyA/JufIQaaW64IaZVbaIm6THCrTb6n9JDy6MaEE8yPGq421mZiVlGIdbq4/tSZhcjzKMGtcml2un8KKtBTseZHKuXM9deiNwuJXGsWxptI3yubqZsXWirMltjXBirWONwmHvXCgiIiIfDR+7++67f+2ceCfx+NvYtfka4+cyzllSz8JwahtQciIiIiLyIXLntiyX5NNTCsoiIiIisiHu+LAsIiIiIrJRFJZFREREROq442uWRUREREQ2ilqWRURERETqUFgWEREREalDYVlEREREpA6FZRERERGROhSWRURERETqUFgWEREREalDYVlEREREpA6FZRERERGROhSWRURERETqUFgWEREREalDYVlEREREpA6FZRERERGROhSWRURERETqUFgWEREREalDYVlEREREpA6FZRERERGROhSWRURERETqUFgWEREREalDYVlEREREpA6F5dtBKMFsLkdqyDlDRERERD5IawrL4cQsuVyu+nU26lxMREREROSOtKawDICZZrCxkcbGRhobk2SbAswmws6llhEl9VFpWR1KkculqHpLEQ+ys7GR1sP2iSIiIiLyQVt7WK7SRzJtYjR4nTNERERERO446xyWwdtgVP0cTswuLs0IJZjNzZIIlVtaA3gBb6dVyrFkC/NQqrrsYzZBpR07TGK2uiykelvW/NlEtGo5axmrdbvmegvH69h+1XlZ85zHHk7MLhxj9GyOXKcX8BLI5SotzPbrga31uVTLXPOYYNEx585GrX2Uj0u10CIiIiJrsr5heShFoClL8qE+55z6Drda5RtAdswq56hXjhBOzJLrbCB9rFz2MUi6UJ4bJZWL4C8kS/MaaTyWpqEzt6gsxPC3w7PWMoNpsxTS2ymUtmtNc5RKYOA/0r2wXrnkZNEbgSX0PdRI41gWyJJsbKSxsZX6V8pL4Ek4XjqXxccUJZUL0JAeXDjfwfl2Ak1VGxERERGRNVh7WDb8RMotm51ezHRyiQC4FlECfoPs2E6C8fK0GMGHgsSAcKIdr5lm0B7U40GOp00M3x5b6zOY6eML24gFJ8nWnOal2dEiW73vPlrHstDU7AjV68Uk/ax1btQ4pvL5Hg+Wl4BYcCfJuYUfVQstIiIiskZrD8tVHfwamWyIOEoj1knIQwNZZuoEP2+DgZk5vxAuy2LnMpiGm+WqqOd/6VzTyaTwpmPSmwVMGvCUyyfW1Tz5hWC+WL3zFREREZH1s/aw7ND3YhrT8LFnQwKkiIiIiMits+5huSa3p7ql+R431d0AVyCeZ75GaURZdn5xuQVAeK8PwyyQdUxfD9a2M5y3tQA3fLr6CJwdHtfT4vMN43FXTRARERGRNVj3sBx9xF8VIK0yCD+BhZAbJdXpLIrIUjAXB81q1rB03k7bqBGESZy1Sj5iwUmyhp+IvcNdKEG33yCbqtT+3jwD/xFbB7vStiulEDHOZ0wMf6CyzFBqcYe7dSrdsFrw/XTbOi+GE9347dlco2GIiIiIrMnaw7K9g18uR4AkjTtt4bTUya48LFwu18zMsTRm1UZiBFNZDH+kzhBpllhwJ4Np8B8pbyuCb74cVvtoLY9QUT6eIz4yx9arg5tJeqxA+8K2/ZAeZGdVB7vjpM3ysHA5crtmGExXnynxIJNzRukcnCNurEI8yM5jaShds1wuRzfHqzv4iYiIiMiafOzuu+/+tXOiOIQSzB7xkTlmHw3j9hQ9W3rDsprh+0RERESkprW3LMttJEpzE2QvKSiLiIiIrAeF5TtVKMHsom8QDOA10yTXpexERERERBSW71TxPPP2+uxcBD9pBu314iIiIiKyJqpZFhERERGpQy3LIiIiIiJ1KCyLiIiIiNShsCwiIiIiUofCsoiIiIhIHQrLIiIiIiJ1KCyLiIiIiNShsCwiIiIiUofCsoiIiIhIHQrLIiIiIiJ1KCyLiIiIiNShsCwiIiIiUofCsoiIiIhIHQrLIiIiIiJ1KCyLiIiIiNShsCwiIiIiUofCsoiIiIhIHQrLIiIiIiJ1KCyLiIiIiNShsCwiIiIiUofCsoiIiIhIHQrLIiIiIiJ1fOzuu+/+tXOiiIjI+ouSygXw2qYU3y3aflrCJhcul3NitcwPH2TfQN45WURkTRSWRUTklmkZvkD8gKf0U5GZ77TS+cwqA+6OFjqav8ADD/rx/1YznrtK06+OE9zTQ9qxuIjIWigsi4jILdRC9OwogaZSM3ExS7K7lb5zzuVWzvflEZ55qgOvUWD68P2ExpxLiIjcPNUsi8gdzEfLw37K7ZQbzbe3BZ9z4k3y7W3Dv9059aNgmr5wjJl3Sz+6vOzvi9LiWGo1Mj/soXV/D+NzBi1/MrDuz4PH30bLDufUO9B2Py3+9bo6t/Z3T+SDpLAsIrXtaKHjwPqFw/XXwsDfxom0uFjlh/g3rasvQpdz4rJ8BL4eZaQ/XBWOzaYvMZJMEP7AA7OPlgMdtzYMXh3mqWfTmKUfXU0BvvVcwLHQKl0dpyc8TNrdQu9u58yb53kizqlvfQlv+WDvZHu7iXS3Oacuy+MPMzAcpbfT/q+BiTc4wtgLYQVm+dBTWBYRhwEmfp4jdybOyPDNhMNbI/zCCAHO8Njhaecs+OIoF67kyOVsr59fYazPmj3wt855Fxg94NzIOthxiMTFMXp/Zyt8tov4jxOES7Py3w/yjZ9uoze2tlbVtbCuwwTx4REit/hG578f5PgrlQTq3hsh8cQaY9fVGH09g/zNO84ZN2l3lOef8jH3bJDYVedMGPjrK9XPUS5H7uVROgC+GOeiY96Vv444N7FChxh73bGfK1e48voVriw85xeJf9m53lp56BhOkRoN4GErLUfGSA36S/PyxILfYOYzvTw/9EE9wSK3hsKyiDj0s+83HiR2eYWjFHwQOuM87n+Hqehg7VblvzzIg/c20vjMDEWAG1lO/od76Yxas/v/oIepX0HhH0/St7+Rxt94kIOnHdtYq+1hEj/oxZcdpjNwkJ7gFFnDT2CoEginu0+QNgJEhsoB5Nbq/4NGHvx+xrpGH4DYl3oYXwihBv6vRtfc0p5PTzF92Tn1ZniI9O3Hc/mFujXQ/f/lXhobgwvnYL7ST+PvH2Qc4C9DdMYzFIt5pqJBHmxs5N7/MujYwgqFHsC7Gcy3xhkMPkhjYyON997LvZ87yJlrRaBIduwbhH7oXHFtWoae51sdLqZ6Wwn1HuS5n5p4H+5eeMMH0xx8Ns3WAxGi69iaL3K7UVgWkRryzP//PqgItRwPA3/Sgvtn0wy/4pzn8J0k6QKwyUvzn5RDqodw4r/T/L8H6Qz0k1yXYOXkITzYjd/IcCYSKwX6eczr0PBp+8fgSZ77hzzeh3s5ZJt6K+XnzQ8sLMM0PceSZMsHYPjp/V6UD+atg0PnAPvvM0knTzjnOKQZns4AYPzmHhaKSfZGeb7TxZnuBzn4/XTtN3UrFN7rw/VGjH3tPcTS5S21EPnrEQJNLsz0cO1PWNZi7wgDB7yYf3+CnlLny0vme2Bs43P2NzRjz5G+5mX/kx/UEyyy8RSWReTOsv0Q/vsg8w/9KwggVhgF8LX04sdDODFG99ZJvhEsh9gNsDdCl9+geGmS/oWWUy9uA4wG+yjDkP6rN8hv9rHnqarJHx3n+ngsUWnddn12PwO3wcf64QPNuAsZ/qZOq7JdfmDS6rDo9hP4mhWUU8N7uPbdx9Y0yoelgwfudn6K4iGcGCG8y6D4VpKedX+WPfR+tQ3PpjzpeHJhatsntwJbce+1L5vmR5k8rvv20GufLPIhorAsIqtkdVgbTYyROD5AuGbveg/+L/YSHR4pdWzz0PHUKGOTE8T7agchz75eosOV7VmdikYYeMLR477Lh5c8cyftE+tL//k0mRvWSAC98efpbjhPzx/0s87tcFUOfaUFD0Uyf29rlQx5aADM+ax9UXjlVa697cL725UPt28PK7nP4PEH6B0cYaR07zz7ehlNppiIR1Zci50/9lWG0wvd/fB2DjBaFcjWi4+u/hGiXw+UOq6WOl8O9hKo6uDYwQNeAzP7qlVSsawTJH9SAFw0/6cEicE9FL7bSej76xFhPRSzU/zI9ilKy9Dz9PoNinNJDrb3rf+zvLuXjl0uuHqpar/eBgN4h4LjDUD6p9cwN3tpfqJ6usiHhcKyiKzc3ghjF8fo3Q2vj73A5FUPXfEUF4532QJtCwN/O0Gir40GwOV7nPj/usDRlnkKLh8te9urNgnA9gjf/W8tbP1kC5HEKcYSFxg7uocGXDR/JcFEotLjPnyvB8xrvF6jw1VNV/uZ/uci4Ka5ucDx8AaEiyqH2HOfC97NkP5OZarHtw0DKL47b18YOEn+X8H4t5+7fUYVWNF9hpb+CSZeiND2ScDl4/H4BS78WQvz/8eFr6WFGne6jjyxyHHSb5d/9tA2tP4jhQSe+y7hz7rwBaOM/W2CiVfjdN37CdjWwUAyRXQhoD/ANjfM/zJWvYElJOMzVuvuZ/1se+UbBNclKAOc4OCXBhe+aMX3tQQjnV5cb6cZ3qBn2f9Hu/AA+cyPbF/wEsbjBm6YzDt/936YZx6Dbb952zzBIutKYVlEVihAfDBMc3Gab+zv48TpcU5+O8Sj38/Q8HCE7x4ptQj399J1n4uZH7YS6u3hYOA5Zq6D4W7g754MEfrT0pAUNh1H9mP8dJCDV0zAg5ckoYeCHOw9yFen8xj+xxkojVbhbTDANLGqRFcm+UYpuHzchcv5h369fdnqjIXLR/j10ogFr18h1eEBiuTfWNxWmZ034S43yw3q1ZucXdjeil6vjd3ER+Mru89sH6D3UR+ufz5Ja6iHnu5OnpsxwWigIfVVQo8/xeI7vYSrMYKHpyrlBHf56R5cz2HJInQ1F0gG/45CEVxNbub+Zyf7Qj30fOkkM0UvgadKo1WEPDRQxPwX5zaW8MqrzJXD/sc3pgrc80SCxFN+jGKW5OHaI3Ssh/2l0NvQEq88S1ci+A3gX65x3rkCWQombP3kck+wyJ1JYVlEVuZIFy1uKPzs76pas/LPZMnjwtcawQ+0fdYKhUXn8F2fbOKBy9M1Ryr4QsM7XPqrtNVqTIGZsRMLYXibC8DNtt+xrVB8Z8VfaewJjnJq31YKJrC5mfb+9YtfNfncGEBh+hvc+7l7S68YmaI1KsfMM84VSj7uYqtzmsNwYKdtmyt4faGTYedGlrPC+8xeL55NUHzPeaPdNP1Ohulzq3k7U3LuIP1j2YX6ZcPfyzNPrdP9+rIX15vnObHdajVmbpqeiXI034rr48CnfLahEms8w3W1EPnrbnzFAgCe33u80tFvveyN8nw5KNu/8bCzl0hwna4RWC3InwRuZDhpe5ZC56xrVfjZ39X93XN9YrknWOTOpLAsIivS9VnrD/I7by9uGQVgWxP7gakreYoYuO9x/AG/+gZnqqcs6N/fSs8rfr7gMcDM8qptGLc9n/EAJoVf2NdYob1Rnv96E5e+2UnPBXtHv40T/nTD4hbkr/nxbYbipUnqDh622cDtnPYBWOl95lyGfNHqsFh9p/O88VLVhFWZPtzPmbcWuvvh2xum2bHMTflhiNbgCfjP1vFm37AVvR/w4dkMmIWbKGvwEE58i/3vvUDogReqO/qtlx2HSAwF8LpM0s9UdxrsfSRAc8N6lXyw0BG1ugXZzx/7PECe9A/rPBeAa8vt8ASLrD+FZRFZkXeKVoBxba4TNd81KQD5Y0lmCuB9+BRjx0dJnO/GT4aTx3rqtkhZ9tO0DYpzM1QqRXtp/gxwI0/m+1ULL297uNTR6jF6JvJVHf0e73QuvN7mufbjyk+H/p0PF3mmv7fEMGRmAUfXv0U8/jY6DnSs4rX6b2Bc6X3m6iDJnxbgM/s5lRxlNHGB7t+FzA/76VluSL8lpen7ykkyRawObH/Qz4xzkTXo2uXFRZ658UrA9O9twg0Usv/3qkeVaBmyOo1+I3iCjL2jX9s6fe12abxu/11FsmM91bXQ2wdo+c35+p9WrIGZf63y+7r7j9m1HYqXxpccrtH8P8s9wSJ3JoVlEVmR8X/OUwS23uWIX7u34gL4RYYkQKgdn5mk8ZF+Xjj3d/zo2R727dxH/3JDaD1ltfjl5ypDVZVbZM30mYUW2YJZhH/jWfqbBbeHSSS7MV6ydbS62s/kJaujnz+wcWPCZt5+ByjyXrmedPsA7btcmK+c5GCda7D1Ey64wbLjHTf99h7+/e5/v4rXF1Ydlld8nwnT/vl3SP5GJ/0v/h1/NzZMz3/eyb6B1bfNVvMQHgzge3cjOrD5eeAzBpjXeG0h9JVaTYtZzpdbTd8yeQcDd/Uof4u0DKUY2X2tqtNoMl4aU/m+5b52eyVfM95CNGYF5fxLg46xlD2EB/fj/cUMKxwYZoUKmO9WTwmE/HiKWc48M1znzUSpjOXGck+wyJ1JYVlEVuY7w5x5q4jxW+302kYpaPnifXgoMP2D0rjHN4Cmdia+8oelwPaHPD7YS9fepWNb+Le9uACXa1tpSgujf9SMq5Dm+Dcrbc0//1cTDKNuq52vc4DEi734fja8KLidSFvj+bru21N1DuspPT1HARdbdwP4GDgRwPuLJD1fqjeyggfPv3HBv2SWDT3T3+mjp7dnFa/hUrBdhZXeZ4pww0v7mW7+sBTO//BPovR+efWt2XYtQ8/T2zy/MR3YtlufXvBxlxX8Ac9TvbRtL5KdGKSvHKBfyWPegK3uDtvKNtv9hIdTjByAM4+Eqo/zlR/xxjUAD7u+WH/wvI7ROPHhEeLPjtQpC7LGUi5/6cij3ScXgqpv7yGiZ8aI+A2yP13vMZaTZH5RqT/2BOP0/juXVf5Rr1V5uwf3Zsi/tdwTLHJn+tjdd9/9a+dEEfkoG2Di9QC+zaU4caNIfnqQBx8/Cds7iAz20vVbnyB/7R3Y3IDHmGfq24/Rkyj9yd4eJp6M0FKjfLH4Vr1xYf2Mvpyg7d8UKLzv4r1fzcMnPWz91RTDX+nhpD2MhBLMHvEy03s/IVttc8fxC3yrzYNrU2VadqyT1sPWh/hdz11kYG/1QRXfniG2ik5w0bMpeKh1mVEePIQTE/R658kXG/DcSP//27v/2Lbv+87jz4MHcEgBBhlAYcVMqJV4XmpedjZ7bY6Fb6arRdKCWJp7gtCAUFooTAJPSqZMqCMQDgRthsA6UK21coQ0tLBWJW6nafFE4XwmfYblLAjnbqF1WGR1KUVUoO8uEIEZ+QIXlECCuz++lPTlV/xKlCU5dvZ6AESS78/P94fjFz98fz9fhr97svIYKvQz/X4P7ktHaT61u7FnK0Mzi3QedK2ds9LtOYZ/v5vJWq4zXiIT00SrXmjbQ2g1Cg3OMvrtOrLndmuMYpuXp1l8MUCpWAQ+YsV4GO8Xf032Z4OEY5W9trEr1+ksxWl4ylplHmV6PkLAbZl0J8PIV8OYBTZDzC524V9N4gClErl0H81/krJMhOBwmolv+3CRY6qhyj3152ny4S26tj9dYPIPjltefLOF7gTppms0h52+uJU1xUiPteJaXuE39z9M4Wev0FFxfmxenmbxRTczx5oZqLUtIg8QhWUR2b76IC0BDy5jiWTFqAdBYpcnaN+X4pVIH8m1UoQgkZeG6D/hIzfRwPEzllUA6mOkr3XiuxWn4akZQicaIZesOnIG9DD9fj+euTBHezevgt5ttYVlk7+pjf0f3yS19npiBy9Os/iyh9QzR3dY67sHHK9zOeydgNQpsybc5CX4fD9DL7Xh+5U9aG7O+3yC2e/5WXjt+C6OUVwpkpgnGiwx1/84gx+2cPgRg5uXqr+KOvgX10k0FTn/72r/MrV9bUy828vKN2q7p3as1rDM6rV3cfvi3JbDNPZMLdLvSRE+ttVzCSIPJpVhiMj2LWdIXUxuCFDQTuCAi8JNS1DGXD7eP0XWAO+BKtXGFSMULDB30SkoA5xnbK6A92t7MDzXLlq4mtw6KOOlP+SHLR6c+sw4XmdoD/hw3c5agjLmaAk/7mPqfxq2Ydi20BTjwssBVi7aHmDbVZWjrRQyKZIOQRkg84MkWQKE9nKowSPfpLHkPErMZ2o5Q6qGoEx9P8cOQjY5oqAsn1sKyyKyi84zlTHwNc8S67BUrta3EU08R8CV4/JPKusa/U1tDIX8uDAw/uUwLQ6vVbaa650k8xtBulZfkPGgaorSdrDAzOtOD07dv86/lcH4Uiuzw6uvjgbw0nY6wXMBF7mrb25Zgw3lhzHPdlKXHbE9wHZ3Os8mGP2ObWJ9kJbvPMPB/cAdg5VaRglZHmEkmcP35NAefSnzMzQQwrj6YIfM0Pfa8P+fGcbOPWh3sEjtFJZFZBcViIeP0/eT2/j/NMH8e/PMz88z/9/+jBDXGO6017G20fVCL0FXgdwHK7hDvTzTtPqA32bihE/N4Oq4YHlF8YMmxPjpEKXZ4W3X9t4PCj8Oc/xPJ7nt7ycxX77O82n+7Chci3XQXEvwrY+QeCuK/1dx+sK78KBa0yg9T7r5yL7rtmfof7qR0gc5cqVGer/7Rw4P1VXKRJ9lJOen3/K69V1zpB3vr8b44zM7PurPTtM4Q6ESM7FqzyGIfH6oZllEHlje8DgXni4x8lQflY9P7Y1oIgHhsPOLRbYhMpGmdXmYjh0PtfagChG7Mk47M5x8Yudhy3t8iNf/vAvf0nm+8p93s8o4RHQqij/TTHgPxjO+p06Mk2j674R7nV8sUrsIE1daKcQ6th4WUuQBp7AsIiL3mDliSPTRBYa/tcMh4h7rZOjlCO3/yYd7X4nsua/Q8SP7QiIid09hWURE7iEvbSMX+H6bi8wPRvjbD+3zN+f9vW/yb90uPL5G9u/34n3EMk6bkWH4UNjyBkgRkZ1TWBYRkXsmdDbNeIf5AprdVpwb4PHubb+GRURkUwrLIiJyj3Qx+jddHPyCffpuMMi+0cGA5UU1IiK7QWFZRERERMSBho4TEREREXGgsCwiIiIi4kBhWURERETEgWqWRUTkPuSl/80LtFR7dd4nS8w8dZLz9ukiIntAPcsiInL/qY8QOuLF9b9TTP5wkGdbm3n2rSJ1B7xw678qKIvIPaOeZRERuf+cnuV6/SRHnyuPm9wUIz3WSV12mOPhOAX78iIie0Q9yyIict/pOWCQOWMPyiOEFZRF5B5Tz7KIiNy/6iMk3ooS+JcpTj4xwJx9vojIHlPPsoiI3KdCxOL9BMkwElFQFpHPhsKyiIjch0LErozT+VsLxE+FiS8DR0aZTfTYFxQR2VMKyyIicp/xEkmM0rm/wNSpDoavmlM7uw9T+keNgyEi95bCsoiI3FdCZy/QH4TMuWcZKAdl/3fG6fm6QfacfWkRkb2lB/xEROT+MTDN4vMBXEaB3IclcNfhdbtwPeSCW3Eanhq2ryEisqcUlkVEREREHKgMQ0RERETEgcKyiIiIiIgDhWUREREREQcKyyIiIiIiDhSWRUREREQcKCyLiIiIiDhQWBYRERERcaCwLCIiIiLiQGFZRERERMSBwrKIiIiIiAOFZRERERERBwrLIiIiIiIOFJZFRERERBwoLIuIiIiIOFBYFhERERFxoLAsIiIiIuJAYVlERERExIHCsoiIiIiIA4VlEREREREHCssiIiIiIg4UlkVEREREHCgsi4iIiIg4UFgWEREREXGgsCwiIiIi4kBhWURERETEwY7CcuxKnvx8goh9Rg1iV/Lkr8Tsk/fO2TT5fBrHPXYnmM/Pk+i2z5A13Qnm83ny+Tzps/aZTiIk5vPMJ+7mLpG7EyOdv/s/m58/ERLv5cn/8jqjR+zzHJxNk89vfd9GEvPb/PMgIiIPmh2FZfnXJEb6dJCV6QYaGhpoPmWfL3L/Kn0CfFLi1/YZ9zXzi2a+/AW12kchXURk7+0oLA880UDDoTBx+wz5/On2UodB8Rf2GVZmj6b+An8Q9TD+9jyLN/amN7pteJob84uf0b0Rp/vxBhq+0szAO/Z597MVCh/kyNk/xZI5+06GqfP2dUREZLftKCyLyOeFl8b9blwu+/TdUVfvw+Peo41/biUZ6GymudXyeWGKossFGGTeGCC+bF9HRER2247C8oa6Y0tNa77GmsnVmj/zY68pLtdeOs1frUMu1xda9xe7ssl6m7L99FmlrrqyzdV6Ujf+fLq2zKbnyFzPvr1IYr5yuU23YT/2WuqwN2nv6v5PB3HjJng6X/18nk2Tz3fiA3wdG7eBvV1V7o1ttbu+i9GZG8z/srz8L+dJj7SBUx3p6jlbu57rdb3Rwdn17dyYJtrkpWskvT7tvVmGmizbqsL/nVFm37XcF4vzpCeihACIMvvLPPm8rWZ2tU3XRgkC1LcRTVxf3+/iPOmRLrzlxVeP63piguvv13COLDoHE6TfW7Sc/+skBszWWa8d7iDRiuvjN8/F4vp5vp5YPS5rbW+UaOI6i+W2L749QaSetXsrGnTDJvcGtDFxI08+v8j0i5bJ9eXr9P40PVsdx9p9fJ3Em+W2zCeIrE233LdHIoxX3D+LzF8epat+fdcmFz0T68eVfy/NaHj1ilTnPR4l8fb6vbBoWyc0MFFxDIvvJeip2IITL9Hz/QTdULw6TPjHBfsCIiKyB3YUlitV1rQ2NAyTKdqXsWnspJex9eUNH52WcBpJBCieWd1eA1NLPjo3hCwfnYez5jLlkpDYlTydngzD5fUazhRp7fBVrFWdm+DpXvjh6j6nyDV2VgTmSGKeqH/Bsu0MdR3Wv/xjpPNRgsWptXY3TOfW1o897eHy6vSGYTIEiVYJ5M42P8+xK3k6se57heDpzUJVlfaWj2n14aZ4+BANZzIYGGTONNDQ0MyAfTOnms3zBeSq1DW7g1ECNy3n1R2k1/Lw1Pba7SV6PkrbY25Kt+ZIXkwyd6vEw79dZ19wa18I0HXCRTY5R84APAEiZ2fpf9JFLpUi+2EJHvHTdbocaKvwPp8gMdiG3wO5TIrkpQy5khtfKMJoIoKXYS7fLAFeDrath6ZIkx83sDA3QoYQsfj3iQTr+OhmiuTFFNk7LnwnolwYrtyzNxjg9hvHaWg4RHiiYpajQDDAw8UsqYtJknM5DLeX4PNDZnj/eYrkxSxFgI9zzF1Mkpy9xgJeIokEQyd8sFw+z0vgDUYY/Wnln0J3oIsub5G5VIaCAa79Ifpf6wEWuDabZG7JLB0o3kySvJgk9fOK1YEkb/59AXDh+4/r2/b2BPABxZ9PcX6r41hfi2DgNmPf2qRM7MAxAvW/Jvd3SfNcF8F9oI3oa5Wx1fXve+n1G2SSKTJLBjzio+3060Q3hOqyphgXzkYIej4ieylJ8lIW4yEfbacvEDsCdEzw/edD+PatkLmUJHkpw8o+z9oXos2Ezl6g66ALlpO88tyUfbaIiOyR3QvLG2pa44SfcPiLapWRYSy8ukSccDoHjYG13p94uLkiDAzczIHbY/aArTHI/BdLdOtO0NpokPmhZd8TYQ5ZAutmctPWADJA87S1TTE6g2zY9uUl8B02l4gkWvEZGYafsLTpVPNacBx4who041xbMMDj3dDL6miz89ydoLUxx1TFvqfIGG78TdX3ULW9E2HGMgZu/7Ha27WVpSlLeB5gyrr9bbc7hP+L5k/R2fggff19dLc/Tkc0ZV9wa/sM5vqb6e7vprk3RQHgERe514/S0XuSjqdnyAHsb+SYfV0AgvQ/HcRNiezrx2kOn6SvN0xz+yQLn4I72ElPPZz/uwVKgO9wTzkYRTjmd8OnC2T/sgAv9tLe6KI4N8jRzpP09Z+k49QcBVz4jjxTEdRLNycJ/2jBMmVr519o5vHWMCf7++jrbmayHN4bQ8D0CH39OT4C+KTIu/199L0aJ3Okn66gG25Ncry12zzPrZNkPwZ3oJV+6w6Kc5z8/Q5O9oY5+sMMBuCq/yptZIi/2se7K2ZY/mipj77+PkamrSubMn99kwJY7jsvPYd9QJGFS2Y43PQ41pTI/izM+X+yTrO5OkDHoaN0dPdZzvVqm9e5/m+GwceP091/kvATx5m8Bbj8BLssC1n0vNCOz1Vk7tWjdPT20dfbQd/VArh8BL8dhMB+PEBpOcVwbx99vWGOtj/LlqXHTTGix324SjmmzvQxZ58vIiJ7ZvfC8kSYy0vln+lr7SktFjYP0/aSh6q9wysUrL1rj3pwGwtcq7HHrVKVB9h+UcSgDm/3alBdLUVY/3Q2ri/uq3NjLFzb9Lis5QarP0/XbLPz/KgHNz46LW3L56Nstgun9savLmBs+GJy94yVTb6sbLvdk8y8U6CEh5a/uM78u7OMv9wGy3fxs7SR472r5X9/5yNKAB8vkPlRedpyjqIB7HNRvTntHKwHjCyXz1n2vzzIwq8A6vA2AT+aMn8B+JLfLE/oPobfDaWblxlchq6v+XABnlBs/Rz8tMUM1m43/vUtU1gasfxXbdyhHhIzaW7ML7K4mKfnsFk/7Kp+UKYnD5r7P9jF9bXr0kPgIeAhNx7LokbhvfUAN1FgBcDlYlt9/e+MMHcLcPv4RgdQ30OgEVjO8GY5XNd2HAVy56z/Xc1hOsenSb89z+L7i+vn2tZmI/cu6324BeL/bF5j74FqabmLbzS6AA+hs+v3cuJJ8+vRw4/44Y0UWQNcj0WYXZwnnYjR5S6YX9IchRgf7MTnKpG7OMjA6v0qIiL3xO6F5dXRMRqGyXg6zb8o7GFuW8xaxYqShxp7h/dWjqm1MgrLx9or6qRco2otNxjOGPaltrTpeTYs5SeWz6G1Hvz71DbbPfUnR+k4dZ7UPxVxefy0vDjKbCJS08/ZW/qkZPay7qopLi8UYZ+fwHe95RKMIpnycAaufeZShUtmz2vFJzrGXfSZr+tOkBjsJFjvIvdOipmJQeI3a7jvfsP8h3EzvrFN/cNM2pffsQLxf1gAPPif7FwrwTDLVHZwHBsEib3xfXpa/Dx8J0sqNcVIf/lXhS0cdv8mAB8Z1f5f5IJ9AAVSG85XH6+MpWB5hI72MMN/lSH3sRtfsJOhqTQxx5p4L5HEKC37oXRrkmejGfsCIiKyx3Y1LJvihA+Vg62lpGLbzgbwkWPKqeZwM24/x2y1rpHf2VYf15pIk3+9p3qiwAo+AhseTlqXW3EuXzC3ZSt5qKLud2xV2XXVuv+qnOdfFDGqHPtmnNprtrVoliDstW2324v/MS8L0yOcbH+cr3xrktyn4P56O11A6kMz6nob1wsFgo96HHqGd+pdbhfL99zzlqheH8X/ReDTArlyT+DURJYC4P/akFmCUVzgcrnHNL5Y7rH0fxPjolnXu/a5lKkpyDlZrY3OpY8S7u1j4LU53O4azkbmNkXA3einLmtr08U5tlcIUpvC0BzZj8Hjb2XosG+9TGUnx7FBO4EDLjCyvNneTV//IOcfcfOwfTHA7f3q+sOMhPjD3/UAJYr/XC20xlm4jVmbfsSwna8kqUwBHvPjX84Qj4Zp/upRBt8pgsvHsW9biz/WeZ+P0Rt0g5FhpGd4R/eBiIjcnd0Ly90J0lu87WpbrOUPYPY0Vy3DsCnXugZfqhw9otf5N30LN8HTlifmy+utlykMkF0CX0flaBCRRHrtQbR4+DI5t+2hvbNp0mch/r9WKmuuN7TLrGF2BzvXt382XVHmsel5nrjGgv3YgdiVKqNXlFVtb7ldufR2v6iYJQv2sL+lbbe7hWh8lnRinNGRUcZfbcW7Dyje5n2gkFmiCLgOd3E9Mc544jrjJ2q4d+5KksHZBUq4CX6v3KaxBOmZCP6HoPg/JhlcHd7rnZ9ycxn4UpCAGwp//+b6T/xnZsjcMUfEGL8xy8TIqLmdd68zUfOXiOpWPjbrhX1HZxkfGWXi8izt++1LFTE+BtwBnpsaJzE1TuTim1z7oGSOkDGTJjE2yujIBNNvzzM7bF9/cwt3zC8wvuY0E2OzJBzXH+HarRJ4ggS/uF6mQs3HUQuD0qfmsXb9dJTRsWmu9wSoOrDd/pby9Zhg9sY4LfuB23OMrZbp2Ay/ZdZre0+Mc2Nmwrw/E2luvD1h3ttd55hevb4jQ3T9nhm+V5aS9k1BfT/nXgriBkolD51vpElfrvyMv7haqub0Z0VERHZq98IyUBeMrtdbdsBUtVETajURZiyDpT44QLamMow44UPlUSZW2/ISjNW0rkFmukjr6nqng5AZrigFGHiiPCrHWg1nnmhdtvKhwNVRNCznInvKfNCvYt2X4LKtDCMeHjNHBVld5nB2Q6mG83mucuz5PK0rU5tchyrtPe1n4czdvKXPfEjTXW7fxuHBnGy33SsUiuD9egttJ9poOeymtDRH/NWTJAGmBxm7mMP41I032ELLoyXm/soMMXuhcOY4J388R85w4Qu20PZkEB9FFi4O0nHSOmpBhpF/yMFDLlzkyPzA2jsZJ/zdEVJLBvyWn9CJNtpaAtRRJPeBZbG7kDwzZm7X46flRBuB0gyTWfvZGGHsrxcwPnXh+Q8tBH8bVsgw8MIrTP5jEeMLPoJPttF2IoT/Cyss1fLHySLz2iRzt0vg9hFq8eGy797i/OUsBi5cDxlkL68/+lbbcdRimJELWYolF94jbbSFPCy9Ub0Mw8hMkrrjJXQihN/jwlhKMdJz0vkBu4kw4XMpcnfA81jIvD8DdfBhzuyJL9zGcJWv74lQ+T4Z5o+rJd2eFrM+HHB5fPgObPw07krdkYiIbObffPnLX/5/9okiIiIiIrLLPcsiIiIiIp8nCssiIiIiIg4UlkVEREREHCgsi4iIiIg4UFgWEREREXGgsCwiIiIi4kBhWURERETEgcKyiIiIiIgDhWUREREREQcKyyIiIiIiDhSWRUREREQcKCyLiIiIiDhQWBYRERERcaCwLCIiIiLiQGFZRERERMSBwrKIiIiIiAOFZRERERERBwrLIiIiIiIO/j+BB1F2hjavKQAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "id": "90aa300b",
   "metadata": {},
   "source": [
    "Expectation - Maximisation\n",
    "\n",
    "EM is an iterative algorithm used when your model depends on hidden / missing / unobserved variables.\n",
    "\n",
    "It solves problems where you cant maximize the likelihood directly, because some parts of the data or structure are unknown.\n",
    "\n",
    "EM alternates between two conceptual steps:\n",
    "\n",
    "1. E-Step (Expectation Step):\n",
    "\n",
    "Estimate the missing / hidden variables using the current model parameters. Here we initially assume your current parameters are correct. Using those parameters, you compute the expected values of hidden variables.\n",
    "This kinda gives a soft-guess of the hidden structure.\n",
    "\n",
    "2. M-Step (Maximisation Step):\n",
    "\n",
    "Update the model parameters to best fit the completed data (observed + estimated) from the E-step. Using the completed dataset from the E-step. Given these expected hidden values, what parameters maximize the likelihood?\n",
    "In the M-step, we choose the parameters that maximize the likelihood of the completed data.\n",
    "\n",
    "We repeat the $ E-Step \\rightarrow M-Step \\rightarrow E-Step$.. Each iteration increases the likelihood or keeps it the same. We stop when parameters stop changing (aka convergence)\n",
    "\n",
    "Popular example of EM model: GMM (Gaussian mixture model).\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "![image-2.png](attachment:image-2.png)\n",
    "\n",
    "![image-3.png](attachment:image-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1070e8",
   "metadata": {},
   "source": [
    "Motivation behind EM-Refinement:\n",
    "\n",
    "The full CoCaD pipeline uses LLMs heavily during construction:\n",
    "- To judge causal strength\n",
    "- To check confounders\n",
    "- To do CoT reasoning\n",
    "- To compute semantic coherence\n",
    "- To generate W_direct(i,j)\n",
    "\n",
    "But LLM calls are expensive, slow, rate-limited, and inconsistent. We cannot depend on a huge LLM during inference time. The whole pipeline must eventually run fast, locally, and consistently when deployed.\n",
    "\n",
    "So EM-refinement is all because at inference time you didnt want to use LLM for this cocad part..\n",
    "\n",
    "Goal of EM-Refinement: \n",
    "- Train fast surrogate models that imitate the LLM for our current context. \n",
    "- Distill (compress) LLM behaviour into small learnable models (All the signals LLM generated earlier line R_coh, mu etc) all get bundled into a single feature vector $v_{ij}$. Then EM-refinement trains a neural model $f_{fusion}$ such that $W_{direct}(i,j) = f_{fusion}(v_{ij})$. \\\n",
    "No this $f_{fusion}$ learns LLM-like decision boundaries, but becomes cheap, deterministic, fast, deployable with LLM.\n",
    "- Produce a relaible, stable $C_{prior}$ for training CausGT-HS: \\\n",
    "CausGT-HS (the final causal EBM) needs target labels. But raw LLM outputs as earlier are Noisy, contradiatory, Hard to trust. So EM-refinement uses Expectation-Maximization to refine teacher/student models. Produces a cleaned, calibrated, LLM-free $C_{prior}$ matrix. That us used as the answer key to train our final causal graph transformer.\n",
    "\n",
    "- Without EM-refinement every step requires dozens of LLM CoT queries. Its ofcourse slow, expensive,, not practical for real-time or batch-scale causal reasoning. \n",
    "\n",
    "Teacher = LLM\n",
    "\n",
    "Student = The small NN do whom we are distilling our LLM knowledge to (it operates on our $v_{ij}$)...\n",
    "\n",
    "So the EM phase distills the LLM + statistical reasoning into a cheap prediction model.\n",
    "\n",
    "Hence EM is an iterative process where:\n",
    "\n",
    "- Teacher computes pseudo-labels (E-step)\n",
    "\n",
    "- Student learns the mapping (M-step)\n",
    "\n",
    "This allows CoCaD to run fast, without LLMs, at inference.\n",
    "\n",
    "Teacher produces the gold standard causal edges using all expensive signals.\n",
    "\n",
    "Student learns to approximate those edges cheaply.\n",
    "\n",
    "- EM produces reliable, fast models (fusion, LPA, CPC, f_embed, f_student) and a stable C_prior (answer key) that the CausGT-HS energy-based model uses as supervision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2510658",
   "metadata": {},
   "source": [
    "## (a). Synthetic Corpus and Ground-Truth Dataset Generation:\n",
    "\n",
    "1. Generation of the Ground-Truth Causal Graph $G_{true}$\n",
    "2. Generation of the Synthetic Text Corpus $D_{corpus}$\n",
    "3. Generation of the Fully Labeled Dataset $D_{synth}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40f6963",
   "metadata": {},
   "source": [
    "### (1). Generation of the Ground-Truth Causal Graph $G_{true}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7672dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "from typing import Dict, Tuple, List, Any, Union, Set\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "# --------------------------\n",
    "# Seed & RNG utilities\n",
    "# --------------------------\n",
    "\n",
    "def _normalize_seed(seed: Union[int, random.Random, np.random.Generator, None]) -> int:\n",
    "    if seed is None:\n",
    "        return 0\n",
    "    if isinstance(seed, random.Random):\n",
    "        return seed.randint(0, 2**32 - 1)\n",
    "    try:\n",
    "        return int(seed) % (2**32)\n",
    "    except Exception:\n",
    "        return 0\n",
    "\n",
    "def _py_random_for_seed(seed: Union[int, random.Random, None]) -> random.Random:\n",
    "    if isinstance(seed, random.Random):\n",
    "        return seed\n",
    "    return random.Random(_normalize_seed(seed))\n",
    "\n",
    "def seeded_rng(seed: int):\n",
    "    base = _normalize_seed(seed)\n",
    "    return random.Random(base), np.random.default_rng(base)\n",
    "\n",
    "# --------------------------\n",
    "# Topology samplers\n",
    "# --------------------------\n",
    "\n",
    "def sample_scale_free_subgraph(n: int, avg_deg: int, rnd_seed: Union[int, random.Random]) -> nx.DiGraph:\n",
    "    m = max(1, int(max(1, round(avg_deg / 2.0))))\n",
    "    py_rng = _py_random_for_seed(rnd_seed)\n",
    "    G = nx.barabasi_albert_graph(n, m, seed=py_rng)\n",
    "    D = nx.DiGraph()\n",
    "    D.add_nodes_from(range(n))\n",
    "    base = _normalize_seed(rnd_seed)\n",
    "    for (u, v) in G.edges():\n",
    "        edge_seed = (base + (u + 1) * 1315423911 + (v + 1) * 2654435761) & 0xFFFFFFFF\n",
    "        if random.Random(edge_seed).random() < 0.5:\n",
    "            D.add_edge(u, v)\n",
    "        else:\n",
    "            D.add_edge(v, u)\n",
    "    return D\n",
    "\n",
    "def sample_small_world_subgraph(n: int, avg_deg: int, rnd_seed: Union[int, random.Random]) -> nx.DiGraph:\n",
    "    k = int(avg_deg if avg_deg % 2 == 0 else avg_deg + 1)\n",
    "    k = min(k, max(2, n - 1))\n",
    "    p = 0.1\n",
    "    py_rng = _py_random_for_seed(rnd_seed)\n",
    "    G = nx.watts_strogatz_graph(n, k, p, seed=py_rng)\n",
    "    D = nx.DiGraph()\n",
    "    D.add_nodes_from(range(n))\n",
    "    base = _normalize_seed(rnd_seed)\n",
    "    for (u, v) in G.edges():\n",
    "        edge_seed = (base + (u + 1) * 1140071481 + (v + 1) * 704602925) & 0xFFFFFFFF\n",
    "        if random.Random(edge_seed).random() < 0.5:\n",
    "            D.add_edge(u, v)\n",
    "        else:\n",
    "            D.add_edge(v, u)\n",
    "    return D\n",
    "\n",
    "def sample_sbm_subgraph(n: int, num_communities: int, avg_deg: int, rnd_seed: Union[int, random.Random]) -> nx.DiGraph:\n",
    "    base = _normalize_seed(rnd_seed)\n",
    "    base_size = n // num_communities\n",
    "    sizes = [base_size] * num_communities\n",
    "    remainder = n - base_size * num_communities\n",
    "    for i in range(remainder):\n",
    "        sizes[i] += 1\n",
    "    p_in = min(0.6, (avg_deg / max(1.0, (n / num_communities))) * 0.6)\n",
    "    p_out = max(0.01, (avg_deg / max(1.0, n)) * 0.6)\n",
    "    probs = [[p_in if i == j else p_out for j in range(num_communities)] for i in range(num_communities)]\n",
    "    py_rng = _py_random_for_seed(rnd_seed)\n",
    "    G = nx.stochastic_block_model(sizes, probs, seed=py_rng)\n",
    "    D = nx.DiGraph()\n",
    "    D.add_nodes_from(range(n))\n",
    "    for (u, v) in G.edges():\n",
    "        if u == v: continue\n",
    "        edge_seed = (base + (u + 1) * 73428767 + (v + 1) * 2654435761) & 0xFFFFFFFF\n",
    "        if random.Random(edge_seed).random() < 0.5:\n",
    "            D.add_edge(u, v)\n",
    "        else:\n",
    "            D.add_edge(v, u)\n",
    "    return D\n",
    "\n",
    "# --------------------------\n",
    "# Mechanism assignment\n",
    "# --------------------------\n",
    "\n",
    "def assign_mechanism_params(parents: List[int], mech_type: str, np_rng: np.random.Generator):\n",
    "    if mech_type == \"linear\":\n",
    "        coeffs = (np_rng.normal(loc=0.5, scale=0.5, size=(len(parents),))).tolist()\n",
    "        bias = float(np_rng.normal(scale=0.1))\n",
    "        return {\"type\": \"linear\", \"coeffs\": coeffs, \"bias\": bias}\n",
    "    elif mech_type == \"mlp\":\n",
    "        hidden_dim = max(4, min(32, 2 * len(parents) + 4))\n",
    "        return {\"type\": \"mlp\", \"hidden_dim\": hidden_dim}\n",
    "    else:  # saturating\n",
    "        coeffs = (np_rng.normal(loc=0.7, scale=0.3, size=(len(parents),))).tolist()\n",
    "        bias = float(np_rng.normal(scale=0.05))\n",
    "        return {\"type\": \"saturating\", \"coeffs\": coeffs, \"bias\": bias}\n",
    "\n",
    "# --------------------------\n",
    "# Plant motifs utilities - FIXED\n",
    "# --------------------------\n",
    "\n",
    "def plant_direct_edge(G: nx.DiGraph, u: int, v: int, motif_tags: Dict[Tuple[int,int], str]):\n",
    "    if u == v: return\n",
    "    G.add_edge(u, v)\n",
    "    motif_tags[(u, v)] = motif_tags.get((u, v), \"\") + \"direct;\"\n",
    "\n",
    "def plant_mediator_chain(\n",
    "    G: nx.DiGraph,\n",
    "    u: int,\n",
    "    v: int,\n",
    "    mediators: List[int],\n",
    "    motif_tags: Dict[Tuple[int,int], str],\n",
    "):\n",
    "    \"\"\"\n",
    "    Plant chain: u -> m1 -> m2 -> ... -> mk -> v\n",
    "    \"\"\"\n",
    "    prev = u\n",
    "    for m in mediators:\n",
    "        if prev == m: continue\n",
    "        G.add_edge(prev, m)\n",
    "        motif_tags[(prev, m)] = motif_tags.get((prev, m), \"\") + \"med_chain;\"\n",
    "        prev = m\n",
    "    \n",
    "    if prev != v:\n",
    "        G.add_edge(prev, v)\n",
    "        motif_tags[(prev, v)] = motif_tags.get((prev, v), \"\") + \"med_chain_end;\"\n",
    "\n",
    "    if not G.has_edge(u, v):\n",
    "        G.add_edge(u, v)\n",
    "\n",
    "    motif_tags[(u, v)] = motif_tags.get((u, v), \"\") + \"target_mediator_loop;\"\n",
    "\n",
    "def plant_confounder_chains(\n",
    "    G: nx.DiGraph,\n",
    "    conf: int,\n",
    "    u: int,\n",
    "    v: int,\n",
    "    path_to_u: List[int],\n",
    "    path_to_v: List[int],\n",
    "    motif_tags: Dict[Tuple[int,int], str],\n",
    "):\n",
    "    prev = conf\n",
    "    for n in path_to_u:\n",
    "        if prev == n: continue\n",
    "        G.add_edge(prev, n)\n",
    "        motif_tags[(prev, n)] = motif_tags.get((prev, n), \"\") + \"conf_chain_u;\"\n",
    "        prev = n\n",
    "    if prev != u:\n",
    "        G.add_edge(prev, u)\n",
    "        motif_tags[(prev, u)] = motif_tags.get((prev, u), \"\") + \"conf_chain_u_end;\"\n",
    "\n",
    "    prev = conf\n",
    "    for n in path_to_v:\n",
    "        if prev == n: continue\n",
    "        G.add_edge(prev, n)\n",
    "        motif_tags[(prev, n)] = motif_tags.get((prev, n), \"\") + \"conf_chain_v;\"\n",
    "        prev = n\n",
    "    if prev != v:\n",
    "        G.add_edge(prev, v)\n",
    "        motif_tags[(prev, v)] = motif_tags.get((prev, v), \"\") + \"conf_chain_v_end;\"\n",
    "\n",
    "def plant_collider_chains(\n",
    "    G: nx.DiGraph,\n",
    "    u: int,\n",
    "    center: int,\n",
    "    v: int,\n",
    "    path_u_to_center: List[int],\n",
    "    path_v_to_center: List[int],\n",
    "    motif_tags: Dict[Tuple[int,int], str],\n",
    "):\n",
    "    # Chain 1: u -> center\n",
    "    prev = u\n",
    "    for n in path_u_to_center:\n",
    "        if prev == n: continue\n",
    "        G.add_edge(prev, n)\n",
    "        motif_tags[(prev, n)] = motif_tags.get((prev, n), \"\") + \"coll_chain_u;\"\n",
    "        prev = n\n",
    "    if prev != center:\n",
    "        G.add_edge(prev, center)\n",
    "        motif_tags[(prev, center)] = motif_tags.get((prev, center), \"\") + \"coll_chain_u_end;\"\n",
    "\n",
    "    # Chain 2: v -> center\n",
    "    prev = v\n",
    "    for n in path_v_to_center:\n",
    "        if prev == n: continue\n",
    "        G.add_edge(prev, n)\n",
    "        motif_tags[(prev, n)] = motif_tags.get((prev, n), \"\") + \"coll_chain_v;\"\n",
    "        prev = n\n",
    "    if prev != center:\n",
    "        G.add_edge(prev, center)\n",
    "        motif_tags[(prev, center)] = motif_tags.get((prev, center), \"\") + \"coll_chain_v_end;\"\n",
    "\n",
    "def enforce_acyclic_by_ordering(G: nx.DiGraph, rng: random.Random) -> nx.DiGraph:\n",
    "    nodes = list(G.nodes())\n",
    "    rng.shuffle(nodes)\n",
    "    order = {n: i for i, n in enumerate(nodes)}\n",
    "    to_remove = []\n",
    "    for u, v in list(G.edges()):\n",
    "        if order[u] >= order[v]:\n",
    "            to_remove.append((u, v))\n",
    "    G.remove_edges_from(to_remove)\n",
    "    try:\n",
    "        if not nx.is_directed_acyclic_graph(G):\n",
    "            cycles = list(nx.simple_cycles(G))\n",
    "            for cyc in cycles:\n",
    "                if len(cyc) >= 2:\n",
    "                    if G.has_edge(cyc[0], cyc[1]):\n",
    "                        G.remove_edge(cyc[0], cyc[1])\n",
    "    except ImportError:\n",
    "        pass\n",
    "    return G\n",
    "\n",
    "# --------------------------\n",
    "# Main generator \n",
    "# --------------------------\n",
    "def generate_ground_truth_graph(\n",
    "    num_nodes: int = 1000,\n",
    "    mix_proportions: Dict[str, float] = None,\n",
    "    avg_deg: int = 4,\n",
    "    num_communities: int = 5,\n",
    "    motif_counts: Dict[str, int] = None,\n",
    "    noise_spec: Dict[str, Any] = None,\n",
    "    seed: int = 42,\n",
    "    max_motif_hops: int = 3,\n",
    ") -> Tuple[nx.DiGraph, Dict[int, Dict[str, Any]], Dict[int, float], Dict[Tuple[int,int], str]]:\n",
    "    \n",
    "    if mix_proportions is None:\n",
    "        mix_proportions = {\"scale_free\": 0.5, \"small_world\": 0.3, \"sbm\": 0.2}\n",
    "    if motif_counts is None:\n",
    "        motif_counts = {\"direct\": int(num_nodes * 0.1), \"mediator\": int(num_nodes * 0.05),\n",
    "                        \"confounder\": int(num_nodes * 0.05), \"collider\": int(num_nodes * 0.02)}\n",
    "    if noise_spec is None:\n",
    "        noise_spec = {\"type\": \"gaussian\", \"scale\": 1.0}\n",
    "\n",
    "    max_motif_hops = int(max(1, min(int(max_motif_hops), 5)))\n",
    "    base_seed = _normalize_seed(seed)\n",
    "    rnd = random.Random(base_seed)\n",
    "    np_rng = np.random.default_rng(base_seed)\n",
    "\n",
    "    # 1. Generate Background Topology\n",
    "    families = list(mix_proportions.keys())\n",
    "    props = np.array([mix_proportions[k] for k in families], dtype=float)\n",
    "    props = props / props.sum()\n",
    "    counts = (props * num_nodes).astype(int)\n",
    "    leftover = num_nodes - counts.sum()\n",
    "    for i in range(leftover):\n",
    "        counts[i % len(counts)] += 1\n",
    "\n",
    "    G_global = nx.DiGraph()\n",
    "    offset = 0\n",
    "    for family, cnt in zip(families, counts):\n",
    "        if cnt <= 0: continue\n",
    "        sampler_seed = base_seed + offset\n",
    "        if family == \"scale_free\":\n",
    "            sub = sample_scale_free_subgraph(cnt, avg_deg, rnd_seed=sampler_seed)\n",
    "        elif family == \"small_world\":\n",
    "            sub = sample_small_world_subgraph(cnt, avg_deg, rnd_seed=sampler_seed)\n",
    "        elif family == \"sbm\":\n",
    "            sub = sample_sbm_subgraph(cnt, num_communities, avg_deg, rnd_seed=sampler_seed)\n",
    "        else:\n",
    "            sub = sample_scale_free_subgraph(cnt, avg_deg, rnd_seed=sampler_seed)\n",
    "\n",
    "        mapping = {local: offset + local for local in sub.nodes()}\n",
    "        sub_relabeled = nx.relabel_nodes(sub, mapping, copy=True)\n",
    "        G_global = nx.compose(G_global, sub_relabeled)\n",
    "        offset += cnt\n",
    "\n",
    "    for u in range(0, num_nodes):\n",
    "        if u not in G_global: G_global.add_node(u)\n",
    "\n",
    "    G_global = enforce_acyclic_by_ordering(G_global, rnd)\n",
    "\n",
    "    G1 = nx.DiGraph()\n",
    "    for u in G_global.nodes(): G1.add_node(int(u) + 1)\n",
    "    for u, v in G_global.edges(): G1.add_edge(int(u) + 1, int(v) + 1)\n",
    "\n",
    "    motif_tags: Dict[Tuple[int,int], str] = {}\n",
    "    nodes_list = list(G1.nodes())\n",
    "    def sample_distinct_nodes(exclude: set, k: int):\n",
    "        pool = [n for n in nodes_list if n not in exclude]\n",
    "        return rnd.sample(pool, k) if len(pool) >= k else []\n",
    "\n",
    "    # 2. Plant Motifs\n",
    "    n_direct = motif_counts.get(\"direct\", 0)\n",
    "    for _ in range(n_direct):\n",
    "        u, v = rnd.sample(nodes_list, 2)\n",
    "        plant_direct_edge(G1, u, v, motif_tags)\n",
    "\n",
    "    n_med = motif_counts.get(\"mediator\", 0)\n",
    "    for _ in range(n_med):\n",
    "        u, v = rnd.sample(nodes_list, 2)\n",
    "        L = rnd.randint(1, max_motif_hops)\n",
    "        exclude = {u, v}\n",
    "        mediators = sample_distinct_nodes(exclude, L)\n",
    "        if len(mediators) < L:\n",
    "            mediators = [] if L == 0 else sample_distinct_nodes({u, v}, 1)\n",
    "        plant_mediator_chain(G1, u, v, mediators, motif_tags)\n",
    "\n",
    "    n_conf = motif_counts.get(\"confounder\", 0)\n",
    "    for _ in range(n_conf):\n",
    "        conf = rnd.choice(nodes_list)\n",
    "        u, v = rnd.sample([n for n in nodes_list if n != conf], 2)\n",
    "        len_u = rnd.randint(1, max_motif_hops)\n",
    "        len_v = rnd.randint(1, max_motif_hops)\n",
    "        exclude_uv = {conf, u, v}\n",
    "        path_u = sample_distinct_nodes(exclude_uv, len_u)\n",
    "        exclude_uv.update(path_u)\n",
    "        path_v = sample_distinct_nodes(exclude_uv, len_v)\n",
    "        plant_confounder_chains(G1, conf, u, v, path_u, path_v, motif_tags)\n",
    "\n",
    "    n_col = motif_counts.get(\"collider\", 0)\n",
    "    for _ in range(n_col):\n",
    "        u, center, v = rnd.sample(nodes_list, 3)\n",
    "        len_u = rnd.randint(1, max_motif_hops)\n",
    "        len_v = rnd.randint(1, max_motif_hops)\n",
    "        exclude_base = {u, v, center}\n",
    "        path_u = sample_distinct_nodes(exclude_base, len_u)\n",
    "        exclude_base.update(path_u)\n",
    "        path_v = sample_distinct_nodes(exclude_base, len_v)\n",
    "        plant_collider_chains(G1, u, center, v, path_u, path_v, motif_tags)\n",
    "\n",
    "    # Instead of listing ALL cycles (Exponential time), we break them one by one.\n",
    "    while True:\n",
    "        try:\n",
    "            # find_cycle finds just *one* cycle. This is O(V+E)\n",
    "            cycle = nx.find_cycle(G1, orientation='original')\n",
    "            # cycle is a list of edges [(u, v), (v, w), ... (z, u)]\n",
    "            # We remove the last edge in the cycle to break it\n",
    "            u_rem, v_rem = cycle[-1][:2]\n",
    "            if G1.has_edge(u_rem, v_rem):\n",
    "                G1.remove_edge(u_rem, v_rem)\n",
    "        except nx.NetworkXNoCycle:\n",
    "            # No more cycles found, we are safe.\n",
    "            break\n",
    "\n",
    "    # 3. Mechanisms\n",
    "    mech_choices = [\"linear\", \"mlp\", \"saturating\"]\n",
    "    node_mechanisms: Dict[int, Dict[str, Any]] = {}\n",
    "    node_noise_params: Dict[int, float] = {}\n",
    "    for node in G1.nodes():\n",
    "        parents = list(G1.predecessors(node))\n",
    "        if len(parents) == 0:\n",
    "            mech = \"linear\"\n",
    "        elif len(parents) == 1:\n",
    "            mech = rnd.choice([\"linear\", \"saturating\"])\n",
    "        else:\n",
    "            mech = rnd.choice(mech_choices)\n",
    "        params = assign_mechanism_params(parents, mech, np_rng)\n",
    "        node_mechanisms[int(node)] = {\"mechanism\": mech, \"params\": params, \"parents\": parents}\n",
    "        base = float(noise_spec.get(\"scale\", 1.0))\n",
    "        noise_scale = base * (1.0 + 0.1 * len(parents)) * (0.9 + rnd.random() * 0.2)\n",
    "        node_noise_params[int(node)] = noise_scale\n",
    "\n",
    "    return G1, node_mechanisms, node_noise_params, motif_tags\n",
    "# --------------------------\n",
    "# Analysis Utils\n",
    "# --------------------------\n",
    "def find_all_directed_paths_up_to_k(G: nx.DiGraph, source: int, target: int, max_hops: int) -> List[List[int]]:\n",
    "    try:\n",
    "        paths = list(nx.all_simple_paths(G, source=source, target=target, cutoff=max_hops))\n",
    "    except Exception:\n",
    "        paths = []\n",
    "    return paths\n",
    "\n",
    "def bfs_sources_within_hops(G: nx.DiGraph, target: int, max_hops: int) -> Set[int]:\n",
    "    Grev = G.reverse(copy=False)\n",
    "    visited = set([target])\n",
    "    frontier = {target}\n",
    "    depth = 0\n",
    "    sources = set()\n",
    "    while frontier and depth < max_hops:\n",
    "        next_front = set()\n",
    "        for node in frontier:\n",
    "            for nbr in Grev.neighbors(node):\n",
    "                if nbr not in visited:\n",
    "                    visited.add(nbr)\n",
    "                    next_front.add(nbr)\n",
    "                    sources.add(nbr)\n",
    "        frontier = next_front\n",
    "        depth += 1\n",
    "    return sources\n",
    "\n",
    "def bfs_descendants_within_hops(G: nx.DiGraph, source: int, max_hops: int) -> Set[int]:\n",
    "    visited = set([source])\n",
    "    frontier = {source}\n",
    "    depth = 0\n",
    "    desc = set()\n",
    "    while frontier and depth < max_hops:\n",
    "        next_front = set()\n",
    "        for node in frontier:\n",
    "            for nbr in G.neighbors(node):\n",
    "                if nbr not in visited:\n",
    "                    visited.add(nbr)\n",
    "                    next_front.add(nbr)\n",
    "                    desc.add(nbr)\n",
    "        frontier = next_front\n",
    "        depth += 1\n",
    "    return desc\n",
    "\n",
    "def analyze_pair(G: nx.DiGraph, i: int, j: int, max_hops: int = 5) -> Dict[str, Any]:\n",
    "    out: Dict[str, Any] = {}\n",
    "    out[\"direct_edge\"] = G.has_edge(i, j)\n",
    "    all_paths = find_all_directed_paths_up_to_k(G, i, j, max_hops)\n",
    "    mediator_paths = [p for p in all_paths if len(p) >= 3]\n",
    "    mediator_nodes = set()\n",
    "    for p in mediator_paths:\n",
    "        mediator_nodes.update(p[1:-1])\n",
    "    out[\"mediator_paths\"] = mediator_paths\n",
    "    out[\"mediator_nodes\"] = sorted(mediator_nodes)\n",
    "\n",
    "    ancestors_i = bfs_sources_within_hops(G, i, max_hops)\n",
    "    ancestors_j = bfs_sources_within_hops(G, j, max_hops)\n",
    "    confounders = sorted(list(ancestors_i.intersection(ancestors_j) - {i, j}))\n",
    "    out[\"confounders\"] = confounders\n",
    "\n",
    "    desc_i = bfs_descendants_within_hops(G, i, max_hops)\n",
    "    desc_j = bfs_descendants_within_hops(G, j, max_hops)\n",
    "    colliders = sorted(list(desc_i.intersection(desc_j) - {i, j}))\n",
    "    out[\"colliders\"] = colliders\n",
    "\n",
    "    out[\"num_all_paths_found\"] = len(all_paths)\n",
    "    out[\"sample_paths\"] = all_paths[:5]\n",
    "    return out\n",
    "\n",
    "def analyze_all_pairs(G: nx.DiGraph, pairs: List[Tuple[int,int]], max_hops: int = 5):\n",
    "    for (i,j) in pairs:\n",
    "        res = analyze_pair(G, i, j, max_hops=max_hops)\n",
    "        print(f\"\\nPair: {i} -> {j}  (max_hops={max_hops})\")\n",
    "        print(f\"  Direct edge present? {res['direct_edge']}\")\n",
    "        if res[\"mediator_paths\"]:\n",
    "            print(f\"  Mediator paths found (count={len(res['mediator_paths'])}):\")\n",
    "            for p in res[\"mediator_paths\"]:\n",
    "                print(f\"    path nodes: {p}\")\n",
    "        else:\n",
    "            print(\"  Mediator paths: None found (no directed path i -> ... -> j within bound)\")\n",
    "\n",
    "# --------------------------\n",
    "# Main Execution \n",
    "# --------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Generating graph with preserved motifs...\")\n",
    "    G_true, node_mech, node_noise, motif_tags = generate_ground_truth_graph(\n",
    "        num_nodes=2000,\n",
    "        motif_counts={\"direct\": 300, \"mediator\": 300, \"confounder\": 200, \"collider\": 100},\n",
    "        seed=12345,\n",
    "        max_motif_hops=4, \n",
    "    )\n",
    "\n",
    "    print(f\"Graph generated: {G_true.number_of_nodes()} nodes, {G_true.number_of_edges()} edges\")\n",
    "\n",
    "    \n",
    "    # 1. Get pairs where we planted a mediator chain AND a direct edge (target_mediator_loop)\n",
    "    target_pairs = []\n",
    "    \n",
    "    # Check the tags dictionary\n",
    "    for (u, v), tag in motif_tags.items():\n",
    "        if \"target_mediator_loop\" in tag:\n",
    "            target_pairs.append((u, v))\n",
    "    \n",
    "    print(f\"\\nFound {len(target_pairs)} planted mediator loop pairs.\")\n",
    "    \n",
    "    # Take a sample of 5 of them\n",
    "    if target_pairs:\n",
    "        # subset = target_pairs[:5]\n",
    "        print(f\"Analyzing subset of {len(target_pairs)} planted mediator pairs:\")\n",
    "        analyze_all_pairs(G_true, pairs=target_pairs, max_hops=6)\n",
    "    else:\n",
    "        print(\"No mediator loops found in tags. Did you run the updated plant_mediator_chain code?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1488ee28",
   "metadata": {},
   "source": [
    "$G_{true}$ is a huge synthetic DAG that serves as the perfect causal universe used to train CoCaDs neural modules so they can replace expensive LLM calls."
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    },
    "image-3.png": {
     "image/png": "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"
    },
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "790d553a",
   "metadata": {},
   "source": [
    "- Above parent: [$\\dots$] means the causal parents of that node.\n",
    "\n",
    "- $f_i$ are functional causal mechanisms above. Each node gets a function $f_i$ randomly choosen from a family of functions $f_i$: \\\n",
    "$v_i$ = $f_i(\\text{parents of i}, n_i)$\n",
    "\n",
    "Ex: \n",
    "- mech: linear \\\n",
    "Means the node follows a linear structural causal model (i.e., the effect of parents is linear). \\\n",
    "![image.png](attachment:image.png) \\\n",
    "Above $c_{ij}$ are random coefficients, $n_i$ is Gaussian noise \n",
    "\n",
    "- mech: saturating \\\n",
    "This uses a sigmoid/tanh saturating non-linearity: \\\n",
    "![image-2.png](attachment:image-2.png) \\\n",
    "This effect is saturating  (has diminishing returns): its like you increase parents the child var increases but beyond a limit the level stops.... (diminishing returns), could be used in economic modelling ig.. \n",
    "\n",
    "- mech: mlp \\ \n",
    "This means the node uses a small neural network (MLP) to compute its value. \\\n",
    "![image-3.png](attachment:image-3.png) \\\n",
    "This highlights a highly non-linear causal interaction... \n",
    "\n",
    "We just generated a synthetic causal graph above. Since we want diverse, realistic causal mechanism so the EM-refinement models learn to detect causal relations like:\n",
    "- detect linear causation\n",
    "- detect nonlinear causation\n",
    "- detect mediated vs confounding structures\n",
    "- distinguish causal vs non-causal edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39b921a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "def find_all_simple_paths_limited(G, source, target, max_hops=5):\n",
    "    \"\"\"Return all simple paths from source  target with length  max_hops.\"\"\"\n",
    "    return [\n",
    "        p for p in nx.all_simple_paths(G, source=source, target=target, cutoff=max_hops)\n",
    "    ]\n",
    "\n",
    "\n",
    "def analyze_pair(G: nx.DiGraph, i: int, j: int, max_hops: int = 5) -> Dict[str, any]:\n",
    "    \"\"\"\n",
    "    Analyze motifs for a given ordered pair (i, j):\n",
    "      - direct edge?\n",
    "      - mediators (multi-hop)\n",
    "      - confounders (multi-hop)\n",
    "      - colliders (multi-hop)\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    # ------------------------------------\n",
    "    # 1. DIRECT EDGE\n",
    "    # ------------------------------------\n",
    "    results[\"direct\"] = G.has_edge(i, j)\n",
    "\n",
    "    # ------------------------------------\n",
    "    # 2. MEDIATORS (all nodes in paths i    j)\n",
    "    # ------------------------------------\n",
    "    paths_ij = find_all_simple_paths_limited(G, i, j, max_hops=max_hops)\n",
    "    mediator_nodes = set()\n",
    "    mediator_paths = []\n",
    "\n",
    "    for p in paths_ij:\n",
    "        if len(p) > 2:  # at least i  k  j\n",
    "            internal = p[1:-1]\n",
    "            mediator_nodes.update(internal)\n",
    "            mediator_paths.append(p)\n",
    "\n",
    "    results[\"mediator_nodes\"] = sorted(mediator_nodes)\n",
    "    results[\"mediator_paths\"] = mediator_paths\n",
    "\n",
    "    # ------------------------------------\n",
    "    # 3. CONFOUNDERS (nodes k    i  AND k    j)\n",
    "    # ------------------------------------\n",
    "    confounders = set()\n",
    "    confounder_paths = []\n",
    "\n",
    "    for k in G.nodes():\n",
    "        if k in (i, j):\n",
    "            continue\n",
    "\n",
    "        # ki ?\n",
    "        paths_k_i = find_all_simple_paths_limited(G, k, i, max_hops=max_hops)\n",
    "\n",
    "        # kj ?\n",
    "        paths_k_j = find_all_simple_paths_limited(G, k, j, max_hops=max_hops)\n",
    "\n",
    "        if paths_k_i and paths_k_j:\n",
    "            confounders.add(k)\n",
    "            confounder_paths.append((k, paths_k_i, paths_k_j))\n",
    "\n",
    "    results[\"confounder_nodes\"] = sorted(confounders)\n",
    "    results[\"confounder_paths\"] = confounder_paths\n",
    "\n",
    "    # ------------------------------------\n",
    "    # 4. COLLIDERS (patterns i  k  j including multi-hop ik and jk)\n",
    "    # ------------------------------------\n",
    "    colliders = set()\n",
    "    collider_paths = []\n",
    "\n",
    "    for k in G.nodes():\n",
    "        if k in (i, j):\n",
    "            continue\n",
    "\n",
    "        # i  ...  k ?\n",
    "        paths_i_k = find_all_simple_paths_limited(G, i, k, max_hops=max_hops)\n",
    "\n",
    "        # j  ...  k ?\n",
    "        paths_j_k = find_all_simple_paths_limited(G, j, k, max_hops=max_hops)\n",
    "\n",
    "        if paths_i_k and paths_j_k:\n",
    "            colliders.add(k)\n",
    "            collider_paths.append((k, paths_i_k, paths_j_k))\n",
    "\n",
    "    results[\"collider_nodes\"] = sorted(colliders)\n",
    "    results[\"collider_paths\"] = collider_paths\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def analyze_all_pairs(G: nx.DiGraph, pairs: List[Tuple[int, int]], max_hops: int = 5):\n",
    "    \"\"\"\n",
    "    Prints full structured analysis for every pair (i, j).\n",
    "    \"\"\"\n",
    "    for (i, j) in pairs:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"PAIR (i={i}, j={j})    structural motif report\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        res = analyze_pair(G, i, j, max_hops=max_hops)\n",
    "\n",
    "        print(f\"\\nDIRECT EDGE ij: {res['direct']}\")\n",
    "\n",
    "        print(\"\\n--- MEDIATORS (multi-hop) ---\")\n",
    "        print(\"Mediator nodes:\", res[\"mediator_nodes\"])\n",
    "        for p in res[\"mediator_paths\"]:\n",
    "            print(\"  path:\", p)\n",
    "\n",
    "        print(\"\\n--- CONFOUNDERS k...i AND k...j ---\")\n",
    "        print(\"Confounder nodes:\", res[\"confounder_nodes\"])\n",
    "        for (k, p_ki, p_kj) in res[\"confounder_paths\"]:\n",
    "            print(f\"  k={k}\")\n",
    "            print(f\"    paths ki:\", p_ki)\n",
    "            print(f\"    paths kj:\", p_kj)\n",
    "\n",
    "        print(\"\\n--- COLLIDERS i...k AND j...k ---\")\n",
    "        print(\"Collider nodes:\", res[\"collider_nodes\"])\n",
    "        for (k, p_ik, p_jk) in res[\"collider_paths\"]:\n",
    "            print(f\"  k={k}\")\n",
    "            print(f\"    paths ik:\", p_ik)\n",
    "            print(f\"    paths jk:\", p_jk)\n",
    "\n",
    "        print(\"=\"*60)\n",
    "        print()\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Example usage on full graph (all edges)\n",
    "# -------------------------------------------------------\n",
    "def analyze_full_graph(G: nx.DiGraph, max_hops: int = 5):\n",
    "    all_pairs = [(u, v) for (u, v) in G.edges()]\n",
    "    analyze_all_pairs(G, pairs=all_pairs, max_hops=max_hops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae2817d",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_full_graph(G_true, max_hops=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6958bb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_to_check = [(485,609), (1098,517)]\n",
    "analyze_all_pairs(G_true, pairs=pairs_to_check, max_hops=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfb6a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" G_true = {type(G_true)}\")\n",
    "print(f\" motif_tags = {type(motif_tags)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb242541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(motif_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4434679",
   "metadata": {},
   "source": [
    "1. The Key-Value Structure:\n",
    "\n",
    "Key (u, v): Represents a directed edge from Node u to Node v.\n",
    "\n",
    "Value 'string;': A tag describing the structural motif that created this edge.\n",
    "\n",
    "A. Mediator Chains (The \"Chain Reaction\"):\n",
    "\n",
    "These edges build a path like $u \\to m_1 \\to m_2 \\to v$.\n",
    "\n",
    "- (2, 105): 'med_chain;\n",
    "\n",
    "'Meaning: This is the start (or middle) of a mediator chain.\n",
    "\n",
    "Interpretation: Node 2 causes Node 105. Node 105 is likely a Mediator.\n",
    "\n",
    "- (9, 1732): 'med_chain_end;\n",
    "\n",
    "'Meaning: This is the final link in a mediator chain.\n",
    "\n",
    "Interpretation: Node 9 (a mediator) causes Node 1732 (the final target).\n",
    "\n",
    "- (2, 1488): 'target_mediator_loop;\n",
    "\n",
    "'Meaning: This is the \"Feed-Forward Loop\" we fixed!\n",
    "\n",
    "Interpretation: This is a direct edge from 2 to 1488. The tag tells you that in addition to this direct edge, there is also a longer path (via mediators) connecting 2 to 1488. This is the most interesting pair for analysis.\n",
    "\n",
    "B. Confounders (The \"Common Cause\"): \n",
    "\n",
    "These edges stem from a hidden common cause ($Conf$) affecting two other nodes ($u$ and $v$): $u \\leftarrow \\dots \\leftarrow Conf \\to \\dots \\to v$.\n",
    "\n",
    "- (13, 921): 'conf_chain_u;\n",
    "\n",
    "'Meaning: An edge leaving a confounder (or intermediate) heading toward target $u$.\n",
    "\n",
    "Interpretation: Node 13 is influencing Node 921 as part of a confounding path.\n",
    "\n",
    "- (3, 1397): 'conf_chain_u_end;\n",
    "\n",
    "'Meaning: The final edge hitting the first target ($u$).\n",
    "\n",
    "Interpretation: Node 3 is the immediate parent of Node 1397 in a confounder structure.\n",
    "\n",
    "- (6, 617): 'conf_chain_v_end;\n",
    "\n",
    "'Meaning: The final edge hitting the second target ($v$).\n",
    "\n",
    "Interpretation: Node 6 is the immediate parent of Node 617.\n",
    "\n",
    "C. Colliders (The \"Common Effect\"): \n",
    "\n",
    "These edges converge on a single node ($Center$): $u \\to \\dots \\to Center \\leftarrow \\dots \\leftarrow v$.\n",
    "\n",
    "- (4, 255): 'coll_chain_v;'\n",
    "\n",
    "Meaning: An edge part of the path coming from source $v$ heading toward the collider center.\n",
    "\n",
    "Interpretation: Node 4 causes Node 255 on the way to a collision.\n",
    "\n",
    "- (5, 1955): 'coll_chain_v_end;'\n",
    "\n",
    "Meaning: The final edge hitting the Collider Center.\n",
    "\n",
    "Interpretation: Node 5 is a parent of Node 1955. Node 1955 is the Collider (the node where two paths collide).\n",
    "\n",
    "D. Direct Edges(6, 279): \n",
    "\n",
    "'direct;\n",
    "\n",
    "'Meaning: A simple random edge added to add density to the graph.\n",
    "\n",
    "Interpretation: Node 6 causes Node 279, but it wasn't planted as part of a complex 3-node or 4-node pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d936b2",
   "metadata": {},
   "source": [
    "### (2). Generation of the Synthetic Text Corpus $D_{corpus}$\n",
    "\n",
    "Convert the synthetic ground-truth causal graph (G_true) into a synthetic text dataset that LOOKS LIKE real-world documents describing those causal relations.\n",
    "\n",
    "To mimic real-world corpora, the text is diversified across domains and enriched\n",
    "with realistic noise.\n",
    "\n",
    "Here we generate dataset coherent with our causal relations in our $G_{true}$. Okk great for this we do the following:\n",
    "\n",
    "- Domain-conditioned generation (one G_true per domain + mixed-domain graphs).\n",
    "- Contrastive snippet generation (hard negatives)\n",
    "- GeneratorLLM-critic loop with model rotation & retries\n",
    " Critic: Its a discriminator model which evaluates whether a generated snippet faithfully reflects its intended causal structure. If the score fails below a threshold, the snippet is regenerated... \\\n",
    "Critic number is a number that represents how strongly and how faithfully the candidate/evidence text supports the causal claim, judged by the model acating as a critic.\n",
    "- Structured noise augmentation.\n",
    "- Persistence of JSONL snippet files and metadata.\n",
    "- Entities saved in your requested rich JSON shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a370d26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the above \n",
    "import pickle\n",
    "import os\n",
    "\n",
    "def load_final_causal_map(base_path=\"extracted_output/cocad/w_direct\"):\n",
    "    \"\"\"\n",
    "    Loads final_causal_map from pickle file.\n",
    "    \"\"\"\n",
    "    load_path = os.path.join(base_path, \"final_causal_map.pkl\")\n",
    "\n",
    "    if not os.path.exists(load_path):\n",
    "        raise FileNotFoundError(f\"No file found at: {load_path}\")\n",
    "\n",
    "    with open(load_path, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    print(f\"[LOAD] final_causal_map loaded  {load_path}\")\n",
    "    return data\n",
    "\n",
    "pairwise_structural_context_retrieval = load_final_causal_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6180e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(pairwise_structural_context_retrieval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8cc88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pairwise_structural_context_retrieval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38631323",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import uuid\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "try:\n",
    "    import google.generativeai as genai\n",
    "except Exception as e:\n",
    "    raise ImportError(\"Required Gemini client 'google.generativeai' not installed or importable.\") from e\n",
    "\n",
    "from graph_generator import generate_ground_truth_graph  # MUST exist in project (Part-1)\n",
    "\n",
    "\n",
    "DOMAINS = [\"finance\", \"politics\", \"medical\"]\n",
    "MODEL_CANDIDATES = [\n",
    "    \"gemini-2.5-flash-lite\",\n",
    "    \"gemini-2.5-flash\",\n",
    "    \"gemini-2.0-flash-lite\",\n",
    "]\n",
    "MAX_LLM_ATTEMPTS_PER_MODEL = 2        \n",
    "LLM_DELAY = 15.0                      # seconds per user request\n",
    "CRITIC_THRESHOLD = 0.75\n",
    "OUT_DIR = Path(\"d_corpus_output\")\n",
    "OUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Deterministic sampling seeds\n",
    "GLOBAL_SEED = 20251127\n",
    "RNG = random.Random(GLOBAL_SEED)\n",
    "\n",
    "# Sampling sizes \n",
    "SAMPLES_PER_DOMAIN = 400   # total record count per domain corpus \n",
    "SAMPLES_MIXED = 1200       # mixed corpus size\n",
    "MAX_PATH_CUTOFF = 4        # max hops when enumerating mediator paths\n",
    "MAX_REGEN = 3              # regeneration attempts per positive snippet\n",
    "\n",
    "# ---------------------------\n",
    "# Utilities\n",
    "# ---------------------------\n",
    "def safe_id(prefix: str = \"doc\") -> str:\n",
    "    return f\"{prefix}_{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "def node_identifier(node_int: int) -> str:\n",
    "    return f\"N{node_int}\"\n",
    "\n",
    "# ---------------------------\n",
    "# Gemini strict wrapper \n",
    "# ---------------------------\n",
    "class GeminiClientStrict:\n",
    "    \"\"\"\n",
    "    Strict Gemini wrapper:\n",
    "     - tries MODEL_CANDIDATES in given order\n",
    "     - sleeps LLM_DELAY before each call\n",
    "     - retries each model up to MAX_LLM_ATTEMPTS_PER_MODEL times\n",
    "     - raises RuntimeError if all models / attempts fail for a call\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 models: List[str],\n",
    "                 attempts_per_model: int,\n",
    "                 llm_delay: float):\n",
    "        if not models:\n",
    "            raise ValueError(\"No Gemini models provided.\")\n",
    "        self.models = models\n",
    "        self.attempts_per_model = attempts_per_model\n",
    "        self.llm_delay = llm_delay\n",
    "\n",
    "    def _sleep(self):\n",
    "        time.sleep(self.llm_delay)\n",
    "\n",
    "    def _call_model_once(self, model: str, prompt: str, temperature: float, max_tokens: int) -> Optional[str]:\n",
    "        \"\"\"Single-model try loop with attempts_per_model retries.\"\"\"\n",
    "        for attempt in range(1, self.attempts_per_model + 1):\n",
    "            self._sleep()\n",
    "            try:\n",
    "                # Deterministic SDK call shape \n",
    "                response = genai.generate_text(model=model, prompt=prompt, temperature=temperature, max_output_tokens=max_tokens)\n",
    "                if response is None:\n",
    "                    continue\n",
    "                # Extract candidate content robustly\n",
    "                if isinstance(response, dict):\n",
    "                    cands = response.get(\"candidates\")\n",
    "                    if isinstance(cands, list) and cands:\n",
    "                        content = cands[0].get(\"content\")\n",
    "                        if content:\n",
    "                            return str(content).strip()\n",
    "                else:\n",
    "                    cands = getattr(response, \"candidates\", None)\n",
    "                    if isinstance(cands, list) and cands:\n",
    "                        first = cands[0]\n",
    "                        if isinstance(first, dict):\n",
    "                            content = first.get(\"content\")\n",
    "                        else:\n",
    "                            content = getattr(first, \"content\", None)\n",
    "                        if content:\n",
    "                            return str(content).strip()\n",
    "            except Exception:\n",
    "                # deterministic backoff\n",
    "                time.sleep(0.5 * attempt)\n",
    "                continue\n",
    "        return None\n",
    "\n",
    "    def generate_text(self, prompt: str, temperature: float = 0.0, max_tokens: int = 256) -> str:\n",
    "        \"\"\"Try all models; return first successful text; raise if none succeed.\"\"\"\n",
    "        for model in self.models:\n",
    "            out = self._call_model_once(model, prompt, temperature, max_tokens)\n",
    "            if out is not None:\n",
    "                return out\n",
    "        # explicit failure\n",
    "        raise RuntimeError(\"All Gemini models exhausted for generate_text. Check credentials / availability.\")\n",
    "\n",
    "    def critique_snippet(self, snippet: str, intended_structure_desc: str, max_tokens: int = 128) -> float:\n",
    "        \"\"\"\n",
    "        Ask Gemini to return a JSON with {\"score\":<0.0-1.0>,\"reason\":\"...\"}.\n",
    "        Returns numeric score 0..1 or raises on failure.\n",
    "        \"\"\"\n",
    "        prompt = (\n",
    "            \"You are a rigorous evaluator. Given an intended causal structure description and a candidate snippet, \"\n",
    "            \"return ONLY valid JSON with fields: {\\\"score\\\": <float between 0.0 and 1.0>, \\\"reason\\\": <short string>}.\\n\\n\"\n",
    "            f\"INTENDED: {intended_structure_desc}\\n\\n\"\n",
    "            f\"SNIPPET: {snippet}\\n\\n\"\n",
    "            \"Return JSON only, no extra commentary.\"\n",
    "        )\n",
    "        raw = self.generate_text(prompt, temperature=0.0, max_tokens=max_tokens)\n",
    "        # parse first {...} block\n",
    "        start = raw.find(\"{\")\n",
    "        end = raw.rfind(\"}\")\n",
    "        if start == -1 or end == -1 or end <= start:\n",
    "            raise RuntimeError(\"Critic returned unparsable output: \" + (raw[:200] if raw else \"<empty>\"))\n",
    "        jtxt = raw[start:end+1]\n",
    "        try:\n",
    "            jj = json.loads(jtxt)\n",
    "            score = float(jj.get(\"score\", 0.0))\n",
    "            return max(0.0, min(1.0, score))\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(\"Critic JSON parse failed: \" + str(e) + \" raw: \" + raw[:200])\n",
    "\n",
    "# ---------------------------\n",
    "# Noise augmentation utilities \n",
    "# ---------------------------\n",
    "def apply_noise(snippet: str, domain: str, rng: random.Random) -> Tuple[str, Dict[str,Any]]:\n",
    "    \"\"\"\n",
    "    Apply structured noise deterministically using provided rng.\n",
    "    Noise types:\n",
    "      - hedging insertion (low probability)\n",
    "      - mild typo (character swap) but avoid entity tokens like 'N\\d+' and entity names (we don't mangled structured entities)\n",
    "      - register shift phrases (prepend or append)\n",
    "    Returns (noisy_snippet, noise_meta)\n",
    "    \"\"\"\n",
    "    noise_meta = {\"hedge\": False, \"typo\": False, \"register_shift\": False}\n",
    "\n",
    "    s = snippet\n",
    "\n",
    "    # 1) Hedging (10% chance)\n",
    "    if rng.random() < 0.10:\n",
    "        hedges = [\"may\", \"might\", \"could\", \"appears to\", \"is likely to\"]\n",
    "        hedge = rng.choice(hedges)\n",
    "        # insert hedge after first verb-ish position: naive insert after first space\n",
    "        parts = s.split(\" \", 1)\n",
    "        if len(parts) == 2:\n",
    "            s = f\"{parts[0]} {hedge} {parts[1]}\"\n",
    "        else:\n",
    "            s = f\"{hedge} {s}\"\n",
    "        noise_meta[\"hedge\"] = True\n",
    "\n",
    "    # 2) Typo (5% chance) \n",
    "    if rng.random() < 0.05:\n",
    "        # choose a position to mangle that is not within uppercase tokens\n",
    "        chars = list(s)\n",
    "        npos = rng.randint(0, max(0, len(chars)-2))\n",
    "        # avoid positions inside uppercase sequences: check neighbor chars\n",
    "        if not (chars[npos].isupper() and (npos == 0 or chars[npos-1] == ' ')):\n",
    "            # swap with next char\n",
    "            chars[npos], chars[npos+1] = chars[npos+1], chars[npos]\n",
    "            s = \"\".join(chars)\n",
    "            noise_meta[\"typo\"] = True\n",
    "\n",
    "    # 3) Register shift (15% chance): prepend domain-appropriate phrase\n",
    "    if rng.random() < 0.15:\n",
    "        if domain == \"medical\":\n",
    "            pre = rng.choice([\"Clinical note:\", \"Case report:\", \"Observationally,\"])\n",
    "        elif domain == \"finance\":\n",
    "            pre = rng.choice([\"Market note:\", \"In recent filings,\", \"Analysts note:\"])\n",
    "        else:\n",
    "            pre = rng.choice([\"Policy brief:\", \"Official release:\", \"Observers say:\"])\n",
    "        s = f\"{pre} {s}\"\n",
    "        noise_meta[\"register_shift\"] = True\n",
    "\n",
    "    return s, noise_meta\n",
    "\n",
    "# ---------------------------\n",
    "# Domain-conditioned prompt templates for motifs \n",
    "# ---------------------------\n",
    "def prompt_for_motif_direct(names: List[str], domain: str) -> str:\n",
    "    a, b = names[0], names[1]\n",
    "    if domain == \"medical\":\n",
    "        return f\"Write a clinical note (one sentence) explaining that {a} directly affects {b}. Return only the sentence.\"\n",
    "    if domain == \"finance\":\n",
    "        return f\"Write a concise financial sentence (one sentence) describing how {a} directly causes changes in {b}. Return only the sentence.\"\n",
    "    # politics\n",
    "    return f\"Write one sentence in a political reporting style stating that {a} directly influences {b}. Return only the sentence.\"\n",
    "\n",
    "def prompt_for_motif_mediator(names: List[str], domain: str) -> str:\n",
    "    # names length >=3\n",
    "    if domain == \"medical\":\n",
    "        return f\"Write a clinical note (one sentence) explaining that {names[0]} affects {names[-1]} by altering {' then '.join(names[1:-1])}. Return only the sentence.\"\n",
    "    if domain == \"finance\":\n",
    "        return f\"Write one sentence describing that {names[0]} influences {names[-1]} via intermediary {' then '.join(names[1:-1])} in a market context. Return only the sentence.\"\n",
    "    return f\"Write one sentence stating that {names[0]} affects {names[-1]} through {' then '.join(names[1:-1])} in a political context. Return only the sentence.\"\n",
    "\n",
    "def prompt_for_motif_confounder(names: List[str], domain: str) -> str:\n",
    "    if len(names) < 3:\n",
    "        # fallback style\n",
    "        return prompt_for_motif_direct(names, domain)\n",
    "    conf = names[1]\n",
    "    return f\"Write one sentence that indicates a shared factor {conf} causes both {names[0]} and {names[-1]}, explaining their association. Return only the sentence.\"\n",
    "\n",
    "def prompt_for_motif_collider(names: List[str], domain: str) -> str:\n",
    "    return f\"Write one sentence explaining that {names[0]} and {names[-1]} both affect {names[1]} (a collider), producing the observed association. Return only the sentence.\"\n",
    "\n",
    "# ---------------------------\n",
    "# Core D_corpus generator class \n",
    "# ---------------------------\n",
    "class DCorpusSpecGenerator:\n",
    "    def __init__(self,\n",
    "                 gemini: GeminiClientStrict,\n",
    "                 domains: List[str],\n",
    "                 out_dir: Path,\n",
    "                 rng_seed: int = GLOBAL_SEED):\n",
    "        self.gemini = gemini\n",
    "        self.domains = list(domains)\n",
    "        self.out_dir = out_dir\n",
    "        self.rng = random.Random(rng_seed)\n",
    "        self.node_entities: Dict[str, Dict[int, Dict[str,Any]]] = {}\n",
    "        self.node_domain_maps: Dict[str, Dict[int, str]] = {}\n",
    "\n",
    "    # create domain-specific views (all nodes assigned same domain)\n",
    "    def create_domain_graph_copies(self, G_true) -> Dict[str, Dict]:\n",
    "        out = {}\n",
    "        for d in self.domains:\n",
    "            out[d] = {\"G\": G_true,\n",
    "                      \"node_domain_map\": {int(n): d for n in G_true.nodes()},\n",
    "                      \"graph_id\": f\"G_domain_{d}\"}\n",
    "        return out\n",
    "\n",
    "    # mixed domain graph view\n",
    "    def create_mixed_domain_graph(self, G_true, seed: int = 1234) -> Dict:\n",
    "        rnd = random.Random(seed)\n",
    "        node_domain_map = {int(n): rnd.choice(self.domains) for n in G_true.nodes()}\n",
    "        return {\"G\": G_true, \"node_domain_map\": node_domain_map, \"graph_id\": f\"G_mixed_{seed}\"}\n",
    "\n",
    "    # ensure structured entity metadata per node (LLM only)\n",
    "    def ensure_node_entities(self, graph_id: str, G, node_domain_map: Dict[int,str]):\n",
    "        if graph_id not in self.node_entities:\n",
    "            self.node_entities[graph_id] = {}\n",
    "            self.node_domain_maps[graph_id] = {}\n",
    "\n",
    "        for node in G.nodes():\n",
    "            n = int(node)\n",
    "            if n in self.node_entities[graph_id]:\n",
    "                continue\n",
    "            domain = node_domain_map.get(n, self.rng.choice(self.domains))\n",
    "            self.node_domain_maps[graph_id][n] = domain\n",
    "\n",
    "            # deterministic prompts for name and description\n",
    "            # Name: 1-4 words, no punctuation\n",
    "            name_prompt = f\"Provide a concise 1-4 word entity name appropriate for domain '{domain}'. This is node id {n}. Return the name only.\"\n",
    "            name = self.gemini.generate_text(name_prompt, temperature=0.0, max_tokens=12)\n",
    "\n",
    "            # Description: 1-2 sentence factual-sounding description\n",
    "            desc_prompt = f\"Write a 1-2 sentence factual-sounding description for the entity named '{name}' in domain '{domain}'. Return description only.\"\n",
    "            description = self.gemini.generate_text(desc_prompt, temperature=0.2, max_tokens=140)\n",
    "\n",
    "            entity = {\n",
    "                \"id\": node_identifier(n),\n",
    "                \"name\": name,\n",
    "                \"type\": \"entity\",\n",
    "                \"time\": None,\n",
    "                \"location\": None,\n",
    "                \"description\": description,\n",
    "                \"source_chunks\": [0],\n",
    "            }\n",
    "            self.node_entities[graph_id][n] = entity\n",
    "\n",
    "    # choose motif-specific prompt\n",
    "    def motif_prompt(self, motif_type: str, names: List[str], domain: str, positive_snippet: Optional[str] = None) -> str:\n",
    "        if motif_type == \"direct\":\n",
    "            return prompt_for_motif_direct(names, domain)\n",
    "        if motif_type == \"mediator\":\n",
    "            return prompt_for_motif_mediator(names, domain)\n",
    "        if motif_type == \"confounder\":\n",
    "            return prompt_for_motif_confounder(names, domain)\n",
    "        if motif_type == \"collider\":\n",
    "            return prompt_for_motif_collider(names, domain)\n",
    "        # fallback strict (shouldn't occur)\n",
    "        return prompt_for_motif_direct(names, domain)\n",
    "\n",
    "    # determine motif type heuristically from path & G\n",
    "    def determine_motif_type(self, G, path: List[int]) -> str:\n",
    "        if len(path) == 2:\n",
    "            return \"direct\"\n",
    "        # path length >=3 -> mediator chain\n",
    "        return \"mediator\"\n",
    "\n",
    "    # generate positive snippet with motif-conditioned prompt + critic loop + noise augmentation\n",
    "    def generate_positive_and_validate(self, graph_id: str, G, path: List[int], domain: str) -> Dict[str,Any]:\n",
    "        names = [ self.node_entities[graph_id][int(n)][\"name\"] for n in path ]\n",
    "        motif = self.determine_motif_type(G, path)\n",
    "        intended_structure_desc = f\"Path {' -> '.join(names)} is a causal relation from {names[0]} to {names[-1]} in domain {domain}.\"\n",
    "        best = None\n",
    "        best_score = -1.0\n",
    "        attempts_meta = []\n",
    "        for attempt in range(1, MAX_REGEN + 1):\n",
    "            # build prompt\n",
    "            prompt = self.motif_prompt(motif, names, domain)\n",
    "            snippet = self.gemini.generate_text(prompt, temperature=0.25, max_tokens=160)\n",
    "            # critic\n",
    "            score = self.gemini.critique_snippet(snippet, intended_structure_desc, max_tokens=128)\n",
    "            attempts_meta.append({\"attempt\": attempt, \"model_try\": MODEL_CANDIDATES, \"prompt\": prompt, \"raw_snippet\": snippet, \"critic_score\": score})\n",
    "            if score >= CRITIC_THRESHOLD:\n",
    "                best = {\"snippet\": snippet, \"meta\": {\"intended_structure\": intended_structure_desc, \"motif\": motif}, \"score\": score, \"attempts_meta\": attempts_meta}\n",
    "                best_score = score\n",
    "                break\n",
    "            if score > best_score:\n",
    "                best = {\"snippet\": snippet, \"meta\": {\"intended_structure\": intended_structure_desc, \"motif\": motif}, \"score\": score, \"attempts_meta\": attempts_meta}\n",
    "                best_score = score\n",
    "            # else retry\n",
    "        if best is None:\n",
    "            raise RuntimeError(\"Failed to produce any positive snippet (unexpected).\")\n",
    "        # structured noise augmentation (deterministic branch using RNG seeded per snippet)\n",
    "        # a deterministic RNG seed per record for reproducible noise decisions\n",
    "        noise_seed = abs(hash((graph_id, tuple(path), best[\"snippet\"]))) % (2**32)\n",
    "        noise_rng = random.Random(noise_seed)\n",
    "        noisy_snippet, noise_meta = apply_noise(best[\"snippet\"], domain, noise_rng)\n",
    "        best[\"noisy_snippet\"] = noisy_snippet\n",
    "        best[\"noise_meta\"] = noise_meta\n",
    "        return best\n",
    "\n",
    "    # generate contrastive negative using LLM & critic (we want low critic score ideally)\n",
    "    def generate_contrastive(self, graph_id: str, best_positive: Dict[str,Any], path: List[int], domain: str) -> Dict[str,Any]:\n",
    "        names = [ self.node_entities[graph_id][int(n)][\"name\"] for n in path ]\n",
    "        # prompt LLM to create contrastive negative\n",
    "        prompt = (\n",
    "            f\"Create a contrastive hard-negative sentence that is semantically close but structurally incorrect relative to the intended relation.\\n\"\n",
    "            f\"INTENDED PATH: {' -> '.join(names)} (domain={domain})\\n\"\n",
    "            f\"Original: {best_positive['snippet'] if 'snippet' in best_positive else best_positive['noisy_snippet']}\\n\"\n",
    "            \"Return only the contrastive sentence.\"\n",
    "        )\n",
    "        neg_snip = self.gemini.generate_text(prompt, temperature=0.35, max_tokens=140)\n",
    "        neg_score = self.gemini.critique_snippet(neg_snip, best_positive[\"meta\"][\"intended_structure\"], max_tokens=128)\n",
    "        # noise augmentation for negative as well \n",
    "        noise_seed = abs(hash((graph_id, tuple(path), neg_snip))) % (2**32)\n",
    "        noise_rng = random.Random(noise_seed)\n",
    "        noisy_neg, noise_meta = apply_noise(neg_snip, domain, noise_rng)\n",
    "        return {\"neg_snippet\": noisy_neg, \"neg_meta\": {\"llm_prompt\": prompt, \"orig\": neg_snip, \"noise_meta\": noise_meta}, \"neg_score\": neg_score}\n",
    "\n",
    "    # build corpus for a single graph view\n",
    "    def build_corpus_for_graph(self, graph_view: Dict[str,Any], out_dir: Path, samples: int):\n",
    "        G = graph_view[\"G\"]\n",
    "        node_domain_map = graph_view[\"node_domain_map\"]\n",
    "        graph_id = graph_view.get(\"graph_id\", f\"G_{int(time.time())}\")\n",
    "\n",
    "        # ensure entities\n",
    "        self.ensure_node_entities(graph_id, G, node_domain_map)\n",
    "\n",
    "        # collect candidate paths: direct edges + k-hop simple paths\n",
    "        import networkx as nx\n",
    "        direct_pairs = [(int(u), int(v)) for (u,v) in G.edges()]\n",
    "        # deterministic shuffle\n",
    "        rng_local = random.Random(GLOBAL_SEED ^ hash(graph_id))\n",
    "        rng_local.shuffle(direct_pairs)\n",
    "\n",
    "        # sample direct and mediator paths up to samples\n",
    "        selected_paths: List[List[int]] = []\n",
    "\n",
    "        # take up to half from direct edges\n",
    "        direct_take = min(len(direct_pairs), samples // 2)\n",
    "        selected_paths.extend([[u,v] for (u,v) in direct_pairs[:direct_take]])\n",
    "\n",
    "        # find mediator paths\n",
    "        nodes = list(G.nodes())\n",
    "        mediator_paths = []\n",
    "        # deterministic sampling for path candidates\n",
    "        attempts = 0\n",
    "        max_attempts = samples * 10\n",
    "        while len(mediator_paths) < (samples - direct_take) and attempts < max_attempts:\n",
    "            attempts += 1\n",
    "            u = rng_local.choice(nodes)\n",
    "            v = rng_local.choice(nodes)\n",
    "            if u == v: continue\n",
    "            try:\n",
    "                paths = list(nx.all_simple_paths(G, source=u, target=v, cutoff=MAX_PATH_CUTOFF))\n",
    "            except Exception:\n",
    "                paths = []\n",
    "            if not paths:\n",
    "                continue\n",
    "            # prefer longer paths (>=3 nodes)\n",
    "            chosen = next((p for p in paths if len(p) >= 3), paths[0])\n",
    "            # ensure uniqueness\n",
    "            if chosen not in mediator_paths and [chosen[0], chosen[-1]] not in [[p[0], p[-1]] for p in mediator_paths]:\n",
    "                mediator_paths.append(chosen)\n",
    "        selected_paths.extend(mediator_paths[:max(0, samples - direct_take)])\n",
    "        # final trim to requested count\n",
    "        selected_paths = selected_paths[:samples]\n",
    "\n",
    "        # create output dir for this graph view\n",
    "        out_subdir = out_dir / graph_id\n",
    "        out_subdir.mkdir(parents=True, exist_ok=True)\n",
    "        out_file = out_subdir / f\"D_corpus_{graph_id}.jsonl\"\n",
    "\n",
    "        # write JSONL\n",
    "        with out_file.open(\"w\", encoding=\"utf8\") as fh:\n",
    "            for path in selected_paths:\n",
    "                domain = node_domain_map.get(int(path[0]), self.rng.choice(self.domains))\n",
    "                # positive + validate + noise\n",
    "                pos_best = self.generate_positive_and_validate(graph_id, G, path, domain)\n",
    "                neg = self.generate_contrastive(graph_id, pos_best, path, domain)\n",
    "                # assemble record\n",
    "                entities = { self.node_entities[graph_id][int(n)][\"id\"]: self.node_entities[graph_id][int(n)] for n in path }\n",
    "                record = {\n",
    "                    \"id_pos\": safe_id(\"pos\"),\n",
    "                    \"id_neg\": safe_id(\"neg\"),\n",
    "                    \"graph_id\": graph_id,\n",
    "                    \"node_pair\": [int(path[0]), int(path[-1])],\n",
    "                    \"path\": [int(x) for x in path],\n",
    "                    \"domain\": domain,\n",
    "                    \"pos_snippet\": pos_best[\"noisy_snippet\"],\n",
    "                    \"pos_meta\": {\n",
    "                        \"intended_structure\": pos_best[\"meta\"][\"intended_structure\"],\n",
    "                        \"motif\": pos_best[\"meta\"][\"motif\"],\n",
    "                        \"attempts_meta\": pos_best[\"attempts_meta\"],\n",
    "                        \"noise_meta\": pos_best[\"noise_meta\"]\n",
    "                    },\n",
    "                    \"pos_score\": pos_best[\"score\"],\n",
    "                    \"neg_snippet\": neg[\"neg_snippet\"],\n",
    "                    \"neg_meta\": neg[\"neg_meta\"],\n",
    "                    \"neg_score\": neg[\"neg_score\"],\n",
    "                    \"isdirect\": int(len(path) == 2 and G.has_edge(path[0], path[-1])),\n",
    "                    \"trueindirectscore\": None,   \n",
    "                    \"entities\": entities\n",
    "                }\n",
    "                fh.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "        print(f\"Wrote D_corpus file: {out_file}  (records={len(selected_paths)})\")\n",
    "\n",
    "    # high-level wrapper to build domain-specific & mixed corpora\n",
    "    def build_all(self, G_true):\n",
    "        # domain-specific\n",
    "        domain_views = self.create_domain_graph_copies(G_true)\n",
    "        for domain, view in domain_views.items():\n",
    "            # deterministic sample size per domain\n",
    "            samples = SAMPLES_PER_DOMAIN\n",
    "            self.build_corpus_for_graph(view, self.out_dir, samples)\n",
    "\n",
    "        # mixed-domain\n",
    "        mixed_view = self.create_mixed_domain_graph(G_true, seed=GLOBAL_SEED ^ 0xDEADBEEF)\n",
    "        self.build_corpus_for_graph(mixed_view, self.out_dir, SAMPLES_MIXED)\n",
    "\n",
    "# ---------------------------\n",
    "# Main runner\n",
    "# ---------------------------\n",
    "def main():\n",
    "    # 1) Generate G_true deterministically using Part-1 generator\n",
    "    G_true, node_mech, node_noise, motif_tags = generate_ground_truth_graph(\n",
    "        num_nodes=2000,\n",
    "        motif_counts={\"direct\": 300, \"mediator\": 300, \"confounder\": 200, \"collider\": 100},\n",
    "        seed=12345,\n",
    "        max_motif_hops=4,\n",
    "    )\n",
    "\n",
    "    # 2) Instantiate strict Gemini client\n",
    "    gemini = GeminiClientStrict(models=MODEL_CANDIDATES, attempts_per_model=MAX_LLM_ATTEMPTS_PER_MODEL, llm_delay=LLM_DELAY)\n",
    "\n",
    "    # 3) Build corpora deterministically\n",
    "    generator = DCorpusSpecGenerator(gemini=gemini, domains=DOMAINS, out_dir=OUT_DIR, rng_seed=GLOBAL_SEED)\n",
    "    generator.build_all(G_true)\n",
    "\n",
    "    print(\"D_corpus generation complete. Output directory:\", OUT_DIR.resolve())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7930609f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe04204a",
   "metadata": {},
   "source": [
    "### (3). Generation of the Fully Labeled Dataset $D_{synth}$\n",
    "\n",
    "- $D_{corpus}$ = Generate natural-language documents that describe relations in G_true.\n",
    "    Below is an example taken from above generated:\n",
    "    ```\n",
    "    {\n",
    "        \"path\": [12, 47, 88],\n",
    "        \"domain\": \"medical\",\n",
    "\n",
    "        \"pos_snippet\": \"Protein P53 increases Disease Y by modulating Biomarker X.\",\n",
    "        \"neg_snippet\": \"Disease Y elevates Protein P53 due to patient workload factors.\",\n",
    "\n",
    "        \"entities\": {\n",
    "            \"N12\": {\"name\": \"Protein P53\", \"description\": \"A tumor-suppressor protein...\", ...},\n",
    "            \"N47\": {\"name\": \"Biomarker X\", ...},\n",
    "            \"N88\": {\"name\": \"Disease Y\", ...}\n",
    "        },\n",
    "\n",
    "        \"pos_score\": 0.92,\n",
    "        \"neg_score\": 0.11\n",
    "    }\n",
    "    ```\n",
    "\n",
    "    $D_{corpus}$ is just synthetic text. No labels. No features. No causal scores.\n",
    "\n",
    "- $D_{synth}$ = labeled training data for all models in the pipeline.\n",
    "\n",
    "Ex:\n",
    "    D_synth (fusion set):\n",
    "        ```\n",
    "        {\n",
    "            \"i\": 12,\n",
    "            \"j\": 88,\n",
    "            \"v_ij\": [0.12, -0.44, 0.91, ...],   // structural + embedding features\n",
    "            \"label_direct\": 0.95,               // smoothed (true = 1)\n",
    "            \"label_indirect\": 0.00              // no indirect path\n",
    "        }\n",
    "\n",
    "        ```\n",
    "\n",
    "    D_synth (LPA set):\n",
    "        ```\n",
    "        {\n",
    "            \"path\": [12, 47, 88],\n",
    "            \"path_embedding\": [0.45, 0.01, -0.78, ...],\n",
    "            \"true_indirect_score\": 0.81        // from SCM simulation do(12)\n",
    "        }\n",
    "        ```\n",
    "    \n",
    "    D_synth (Embedder triplet):\n",
    "        ```\n",
    "        {\n",
    "            \"query\": \"Protein P53\",\n",
    "            \"positive\": \"Biomarker X contributes to Disease Y\",\n",
    "            \"negative\": \"An unrelated political committee affects trade tariffs\"\n",
    "        }\n",
    "        ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f86228",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Any, Optional\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "from graph_generator import generate_ground_truth_graph  \n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# Configuration \n",
    "# --------------------------------------------------------------------\n",
    "GLOBAL_SEED = 20251127\n",
    "random.seed(GLOBAL_SEED)\n",
    "NP_RNG = np.random.default_rng(GLOBAL_SEED)\n",
    "\n",
    "DCORPUS_BASE = Path(\"d_corpus_output\")    \n",
    "PHASE1_SAVE = DCORPUS_BASE / \"phase1_ground_truth.pkl\"  \n",
    "OUT_DIR = Path(\"out/dsynth\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# SCM Monte Carlo settings \n",
    "MC_SAMPLES = 128\n",
    "DELTA = 1e-2\n",
    "SIGMOID_SCALE = 1.0\n",
    "EPSILON_SMOOTH = 0.05\n",
    "\n",
    "EMBED_DIM = 64\n",
    "MAX_PATH_CUTOFF = 4\n",
    "NEG_CANDIDATES = 50\n",
    "\n",
    "# Output files\n",
    "FUSION_FILE = OUT_DIR / \"TrainingSetFusion.jsonl\"\n",
    "LPA_FILE = OUT_DIR / \"TrainingSetLPA.jsonl\"\n",
    "PATH_FILE = OUT_DIR / \"TrainingSetPath.jsonl\"\n",
    "EMBEDDER_FILE = OUT_DIR / \"TrainingSetEmbedder.jsonl\"\n",
    "CPC_FILE = OUT_DIR / \"TrainingSetCPC.jsonl\"\n",
    "INDEX_FILE = OUT_DIR / \"TrainingSetIndex.jsonl\"\n",
    "\n",
    "# params used in Phase-1 originally\n",
    "PH1_NUM_NODES = 2000\n",
    "PH1_MOTIF_COUNTS = {\"direct\": 300, \"mediator\": 300, \"confounder\": 200, \"collider\": 100}\n",
    "PH1_SEED = 12345\n",
    "PH1_MAX_MOTIF_HOPS = 4\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# Utilities\n",
    "# --------------------------------------------------------------------\n",
    "def safe_id(prefix: str = \"id\") -> str:\n",
    "    return f\"{prefix}_{uuid.uuid4().hex[:12]}\"\n",
    "\n",
    "def sigmoid(x: float) -> float:\n",
    "    return 1.0 / (1.0 + math.exp(-x))\n",
    "\n",
    "def clamp01(x: float) -> float:\n",
    "    return float(max(0.0, min(1.0, x)))\n",
    "\n",
    "# deterministic text embedding\n",
    "def deterministic_text_embedding(text: str, dim: int = EMBED_DIM) -> np.ndarray:\n",
    "    vec = np.zeros(dim, dtype=float)\n",
    "    h = abs(hash(text)) % (2**32)\n",
    "    rng = np.random.default_rng(h)\n",
    "    for i, ch in enumerate(text):\n",
    "        idx = (ord(ch) + i) % dim\n",
    "        vec[idx] += (ord(ch) % 97 + 1) * (0.001 + (i % 5) * 0.0001)\n",
    "    vec += rng.normal(scale=0.01, size=dim)\n",
    "    norm = np.linalg.norm(vec)\n",
    "    if norm > 0:\n",
    "        vec /= norm\n",
    "    return vec\n",
    "\n",
    "def cosine_sim(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    na = np.linalg.norm(a)\n",
    "    nb = np.linalg.norm(b)\n",
    "    if na == 0 or nb == 0:\n",
    "        return 0.0\n",
    "    return float(np.dot(a, b) / (na * nb))\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# SCM simulator (Option A: deterministic Monte Carlo)\n",
    "# --------------------------------------------------------------------\n",
    "class SCMSimulator:\n",
    "    def __init__(self, G: nx.DiGraph, node_mech: Dict[int, Dict[str, Any]], node_noise: Dict[int, float], global_seed: int = GLOBAL_SEED):\n",
    "        self.G = G\n",
    "        self.node_mech = node_mech\n",
    "        self.node_noise = node_noise\n",
    "        if not nx.is_directed_acyclic_graph(G):\n",
    "            raise RuntimeError(\"G_true must be a DAG for SCM simulation.\")\n",
    "        self.topo = list(nx.topological_sort(G))\n",
    "        self.global_seed = global_seed\n",
    "        self._mlp_weights = {}\n",
    "        self._prepare_mlp_weights()\n",
    "\n",
    "    def _prepare_mlp_weights(self):\n",
    "        for node, info in self.node_mech.items():\n",
    "            mech = info.get(\"mechanism\")\n",
    "            if mech == \"mlp\":\n",
    "                parents = info.get(\"parents\", [])\n",
    "                in_dim = max(1, len(parents))\n",
    "                hidden = int(info[\"params\"].get(\"hidden_dim\", max(4, 2*in_dim + 4)))\n",
    "                seed = (self.global_seed ^ int(node)) & 0xFFFFFFFF\n",
    "                rng = np.random.default_rng(seed)\n",
    "                W1 = rng.normal(loc=0.0, scale=0.5 / max(1.0, math.sqrt(in_dim)), size=(hidden, in_dim))\n",
    "                b1 = rng.normal(loc=0.0, scale=0.1, size=(hidden,))\n",
    "                W2 = rng.normal(loc=0.0, scale=0.5 / math.sqrt(hidden), size=(1, hidden))\n",
    "                b2 = rng.normal(loc=0.0, scale=0.05, size=(1,))\n",
    "                self._mlp_weights[int(node)] = (W1, b1, W2, b2)\n",
    "\n",
    "    def _eval_node(self, node: int, parent_vals: np.ndarray, noise: np.ndarray) -> np.ndarray:\n",
    "        info = self.node_mech[int(node)]\n",
    "        mech = info[\"mechanism\"]\n",
    "        params = info[\"params\"]\n",
    "        if mech == \"linear\":\n",
    "            coeffs = np.array(params.get(\"coeffs\", [0.5]*len(parent_vals.T))) if parent_vals.size else np.array([])\n",
    "            bias = float(params.get(\"bias\", 0.0))\n",
    "            if parent_vals.size:\n",
    "                out = parent_vals @ coeffs + bias\n",
    "            else:\n",
    "                out = np.full((noise.shape[0],), bias)\n",
    "            out = out + noise\n",
    "            return out\n",
    "        elif mech == \"saturating\":\n",
    "            coeffs = np.array(params.get(\"coeffs\", [0.7]*len(parent_vals.T))) if parent_vals.size else np.array([])\n",
    "            bias = float(params.get(\"bias\", 0.0))\n",
    "            if parent_vals.size:\n",
    "                lin = parent_vals @ coeffs + bias\n",
    "                out = 1.0 / (1.0 + np.exp(-lin))\n",
    "            else:\n",
    "                out = 1.0 / (1.0 + np.exp(-bias)) * np.ones((noise.shape[0],))\n",
    "            out = out + noise\n",
    "            return out\n",
    "        else:  # mlp\n",
    "            W1, b1, W2, b2 = self._mlp_weights[int(node)]\n",
    "            if parent_vals.ndim == 1:\n",
    "                parent_vals = parent_vals.reshape(1, -1)\n",
    "            z1 = parent_vals @ W1.T + b1\n",
    "            h = np.tanh(z1)\n",
    "            out = h @ W2.T + b2\n",
    "            out = out.reshape(-1) + noise\n",
    "            return out\n",
    "\n",
    "    def _sample_noise(self, node: int, S: int, rng: np.random.Generator) -> np.ndarray:\n",
    "        scale = float(self.node_noise.get(int(node), 1.0))\n",
    "        return rng.normal(loc=0.0, scale=scale, size=(S,))\n",
    "\n",
    "    def simulate_do(self, intervened: Dict[int, float], samples: int = MC_SAMPLES, rng_seed_offset: int = 0) -> Dict[int, np.ndarray]:\n",
    "        seed = (self.global_seed ^ rng_seed_offset) & 0xFFFFFFFF\n",
    "        rng = np.random.default_rng(seed)\n",
    "        S = samples\n",
    "        vals: Dict[int, np.ndarray] = {}\n",
    "        for node in self.topo:\n",
    "            n = int(node)\n",
    "            if n in intervened:\n",
    "                vals[n] = np.full((S,), float(intervened[n]), dtype=float)\n",
    "        for node in self.topo:\n",
    "            n = int(node)\n",
    "            if n in vals:\n",
    "                continue\n",
    "            parents = self.node_mech[n].get(\"parents\", [])\n",
    "            if not parents:\n",
    "                # no parents: treat parent_vals as zeros or bias-only mapping\n",
    "                parent_vals = np.zeros((S, 0))\n",
    "                noise = self._sample_noise(n, S, rng)\n",
    "                vals[n] = self._eval_node(n, parent_vals, noise)\n",
    "            else:\n",
    "                parent_vals = np.stack([vals[int(p)] for p in parents], axis=1)\n",
    "                noise = self._sample_noise(n, S, rng)\n",
    "                vals[n] = self._eval_node(n, parent_vals, noise)\n",
    "        return vals\n",
    "\n",
    "    def compute_true_indirect_score(self, source: int, target: int, base_value: float = 0.0, delta: float = DELTA, samples: int = MC_SAMPLES) -> float:\n",
    "        seed_offset = (int(source) * 73856093) ^ (int(target) * 19349663)\n",
    "        vals_base = self.simulate_do({int(source): base_value}, samples=samples, rng_seed_offset=seed_offset)\n",
    "        Ej_base = float(np.mean(vals_base[int(target)]))\n",
    "        vals_delta = self.simulate_do({int(source): base_value + delta}, samples=samples, rng_seed_offset=seed_offset ^ 0xDEADBEEF)\n",
    "        Ej_delta = float(np.mean(vals_delta[int(target)]))\n",
    "        derivative = (Ej_delta - Ej_base) / (delta if delta != 0 else 1e-9)\n",
    "        score = sigmoid(SIGMOID_SCALE * abs(derivative))\n",
    "        return clamp01(score)\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# Dsynth generator that reads D_corpus only \n",
    "# --------------------------------------------------------------------\n",
    "class DsynthGeneratorFromDcorpus:\n",
    "    def __init__(self, dcorpus_base: Path, out_dir: Path):\n",
    "        self.dcorpus_base = dcorpus_base\n",
    "        self.out_dir = out_dir\n",
    "        self.records_by_graph: Dict[str, List[Dict[str,Any]]] = {}\n",
    "        self._load_d_corpus()\n",
    "        # load saved Phase-1 ground truth \n",
    "        self.G, self.node_mech, self.node_noise, self.motif_tags = self._load_or_regenerate_ground_truth()\n",
    "        self.scm = SCMSimulator(self.G, self.node_mech, self.node_noise, global_seed=GLOBAL_SEED)\n",
    "        # precompute entity embeddings for hard-negative sampling\n",
    "        self.entity_embeddings: Dict[str, np.ndarray] = {}\n",
    "        self._precompute_entity_embeddings()\n",
    "        self._open_output_files()\n",
    "\n",
    "    def _load_d_corpus(self):\n",
    "        if not self.dcorpus_base.exists():\n",
    "            raise RuntimeError(f\"D_corpus base dir not found: {self.dcorpus_base}\")\n",
    "        for sub in sorted([p for p in self.dcorpus_base.iterdir() if p.is_dir()]):\n",
    "            graph_id = sub.name\n",
    "            jsonl_files = list(sub.glob(\"D_corpus_*.jsonl\"))\n",
    "            if not jsonl_files:\n",
    "                continue\n",
    "            file_path = jsonl_files[0]\n",
    "            recs = []\n",
    "            with file_path.open(\"r\", encoding=\"utf8\") as fh:\n",
    "                for line in fh:\n",
    "                    line = line.strip()\n",
    "                    if not line:\n",
    "                        continue\n",
    "                    rec = json.loads(line)\n",
    "                    rec.setdefault(\"graph_id\", graph_id)\n",
    "                    recs.append(rec)\n",
    "            self.records_by_graph[graph_id] = recs\n",
    "        if not self.records_by_graph:\n",
    "            raise RuntimeError(f\"No D_corpus records loaded from {self.dcorpus_base}\")\n",
    "\n",
    "    def _load_or_regenerate_ground_truth(self):\n",
    "        candidates = [PHASE1_SAVE, Path(\"phase1_ground_truth.pkl\"), Path(\"ground_truth_phase1.pkl\")]\n",
    "        for p in candidates:\n",
    "            if p.exists():\n",
    "                with p.open(\"rb\") as fh:\n",
    "                    data = pickle.load(fh)\n",
    "                    if isinstance(data, tuple) and len(data) >= 4:\n",
    "                        G_true, node_mech, node_noise, motif_tags = data[0], data[1], data[2], data[3]\n",
    "                        print(f\"Loaded saved ground-truth from {p}\")\n",
    "                        return G_true, node_mech, node_noise, motif_tags\n",
    "        print(\"Warning: phase1_ground_truth not found. Deterministically regenerating G_true using generate_ground_truth_graph(...) with seed=12345.\")\n",
    "        G_true, node_mech, node_noise, motif_tags = generate_ground_truth_graph(\n",
    "            num_nodes=PH1_NUM_NODES,\n",
    "            motif_counts=PH1_MOTIF_COUNTS,\n",
    "            seed=PH1_SEED,\n",
    "            max_motif_hops=PH1_MAX_MOTIF_HOPS,\n",
    "            avg_deg=4,\n",
    "            num_communities=5\n",
    "        )\n",
    "        return G_true, node_mech, node_noise, motif_tags\n",
    "\n",
    "    def _precompute_entity_embeddings(self):\n",
    "        for graph_id, recs in self.records_by_graph.items():\n",
    "            for rec in recs:\n",
    "                ents = rec.get(\"entities\", {})\n",
    "                for ent_id, ent in ents.items():\n",
    "                    key = f\"{graph_id}::{ent_id}\"\n",
    "                    if key not in self.entity_embeddings:\n",
    "                        text = (ent.get(\"name\",\"\") + \" \" + (ent.get(\"description\",\"\") or \"\")).strip()\n",
    "                        self.entity_embeddings[key] = deterministic_text_embedding(text)\n",
    "\n",
    "    def _open_output_files(self):\n",
    "        self.f_fusion = open(FUSION_FILE, \"w\", encoding=\"utf8\")\n",
    "        self.f_lpa = open(LPA_FILE, \"w\", encoding=\"utf8\")\n",
    "        self.f_path = open(PATH_FILE, \"w\", encoding=\"utf8\")\n",
    "        self.f_embedder = open(EMBEDDER_FILE, \"w\", encoding=\"utf8\")\n",
    "        self.f_cpc = open(CPC_FILE, \"w\", encoding=\"utf8\")\n",
    "        self.f_index = open(INDEX_FILE, \"w\", encoding=\"utf8\")\n",
    "\n",
    "    def _close_output_files(self):\n",
    "        for fh in [self.f_fusion, self.f_lpa, self.f_path, self.f_embedder, self.f_cpc, self.f_index]:\n",
    "            try:\n",
    "                fh.close()\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    def _extract_structural_features(self, i: int, j: int) -> List[float]:\n",
    "        indeg_i = self.G.in_degree(i)\n",
    "        outdeg_i = self.G.out_degree(i)\n",
    "        indeg_j = self.G.in_degree(j)\n",
    "        outdeg_j = self.G.out_degree(j)\n",
    "        try:\n",
    "            spl = nx.shortest_path_length(self.G, source=i, target=j)\n",
    "        except Exception:\n",
    "            spl = -1\n",
    "        try:\n",
    "            paths = list(nx.all_simple_paths(self.G, source=i, target=j, cutoff=MAX_PATH_CUTOFF))\n",
    "            num_paths = len(paths)\n",
    "            max_path_len = max((len(p) for p in paths), default=0)\n",
    "        except Exception:\n",
    "            num_paths = 0\n",
    "            max_path_len = 0\n",
    "        anc_i = set(nx.ancestors(self.G, i))\n",
    "        anc_j = set(nx.ancestors(self.G, j))\n",
    "        common_anc = len(anc_i & anc_j)\n",
    "        feat = [float(indeg_i), float(outdeg_i), float(indeg_j), float(outdeg_j),\n",
    "                float(spl if spl>=0 else 999.0), float(num_paths), float(max_path_len), float(common_anc)]\n",
    "        return feat\n",
    "\n",
    "    def _compute_text_embedding_for_pair(self, rec: Dict[str,Any]) -> np.ndarray:\n",
    "        pos = rec.get(\"pos_snippet\", \"\")\n",
    "        entities = rec.get(\"entities\", {})\n",
    "        names_concat = \" \".join([ent.get(\"name\",\"\") for ent in entities.values()])\n",
    "        txt = f\"{pos} {names_concat}\"\n",
    "        return deterministic_text_embedding(txt)\n",
    "\n",
    "    def _compute_path_embedding(self, graph_id: str, path: List[int]) -> np.ndarray:\n",
    "        embs = []\n",
    "        for node in path:\n",
    "            ent_id = f\"N{int(node)}\"\n",
    "            key = f\"{graph_id}::{ent_id}\"\n",
    "            emb = self.entity_embeddings.get(key, deterministic_text_embedding(ent_id))\n",
    "            embs.append(emb)\n",
    "        if not embs:\n",
    "            return np.zeros(EMBED_DIM, dtype=float)\n",
    "        return np.mean(np.stack(embs, axis=0), axis=0)\n",
    "\n",
    "    def _hard_negative_for_target(self, graph_id: str, target_node: int, exclude_set: set) -> int:\n",
    "        nodes_all = list(self.G.nodes())\n",
    "        rng = random.Random(GLOBAL_SEED ^ abs(hash(graph_id)))\n",
    "        cand_nodes = nodes_all[:]\n",
    "        rng.shuffle(cand_nodes)\n",
    "        cand_nodes = [n for n in cand_nodes if n not in exclude_set][:NEG_CANDIDATES]\n",
    "        target_key = f\"{graph_id}::N{int(target_node)}\"\n",
    "        target_emb = self.entity_embeddings.get(target_key, deterministic_text_embedding(str(target_node)))\n",
    "        best_k = None\n",
    "        best_sim = -1.0\n",
    "        for k in cand_nodes:\n",
    "            if (int(target_node), int(k)) in self.G.edges():\n",
    "                pass\n",
    "            key = f\"{graph_id}::N{int(k)}\"\n",
    "            emb = self.entity_embeddings.get(key, deterministic_text_embedding(str(k)))\n",
    "            sim = cosine_sim(target_emb, emb)\n",
    "            if sim > best_sim:\n",
    "                best_sim = sim\n",
    "                best_k = k\n",
    "        if best_k is None:\n",
    "            for node in self.G.nodes():\n",
    "                if node not in exclude_set and node != target_node:\n",
    "                    best_k = int(node)\n",
    "                    break\n",
    "        return int(best_k)\n",
    "\n",
    "    def generate(self):\n",
    "        idx_count = 0\n",
    "        for graph_id, recs in self.records_by_graph.items():\n",
    "            for rec in recs:\n",
    "                idx_count += 1\n",
    "                path = rec.get(\"path\", [])\n",
    "                if not path or len(path) < 2:\n",
    "                    continue\n",
    "                i = int(path[0]); j = int(path[-1])\n",
    "                is_direct = 1 if self.G.has_edge(i, j) else 0\n",
    "                y_gold = float(is_direct)\n",
    "                y_smoothed = y_gold * (1.0 - EPSILON_SMOOTH) + EPSILON_SMOOTH * 0.5\n",
    "                true_indirect = self.scm.compute_true_indirect_score(source=i, target=j, base_value=0.0, delta=DELTA, samples=MC_SAMPLES)\n",
    "                structural_feats = self._extract_structural_features(i, j)\n",
    "                text_emb = self._compute_text_embedding_for_pair(rec)\n",
    "                pos_score = float(rec.get(\"pos_score\", 1.0))\n",
    "                neg_score = float(rec.get(\"neg_score\", 0.0) if rec.get(\"neg_score\") is not None else 0.0)\n",
    "                v_ij = structural_feats + [pos_score, neg_score] + list(text_emb.tolist())\n",
    "                fusion_record = {\n",
    "                    \"record_id\": safe_id(\"fus\"),\n",
    "                    \"graph_id\": graph_id,\n",
    "                    \"i\": int(i),\n",
    "                    \"j\": int(j),\n",
    "                    \"v_ij\": v_ij,\n",
    "                    \"label_direct_smoothed\": float(y_smoothed),\n",
    "                    \"isdirect_gold\": int(is_direct)\n",
    "                }\n",
    "                self.f_fusion.write(json.dumps(fusion_record, ensure_ascii=False) + \"\\n\")\n",
    "                path_emb = self._compute_path_embedding(graph_id, path)\n",
    "                lpa_record = {\n",
    "                    \"record_id\": safe_id(\"lpa\"),\n",
    "                    \"graph_id\": graph_id,\n",
    "                    \"path\": [int(x) for x in path],\n",
    "                    \"path_embedding\": path_emb.tolist(),\n",
    "                    \"true_indirect_score\": float(true_indirect)\n",
    "                }\n",
    "                self.f_lpa.write(json.dumps(lpa_record, ensure_ascii=False) + \"\\n\")\n",
    "                excl = set(path)\n",
    "                k = self._hard_negative_for_target(graph_id, j, exclude_set=excl)\n",
    "                try:\n",
    "                    paths_ik = list(nx.all_simple_paths(self.G, source=i, target=k, cutoff=MAX_PATH_CUTOFF))\n",
    "                except Exception:\n",
    "                    paths_ik = []\n",
    "                if paths_ik:\n",
    "                    neg_path = paths_ik[0]\n",
    "                else:\n",
    "                    neg_path = [int(i), int(k)]\n",
    "                path_record = {\n",
    "                    \"record_id\": safe_id(\"path\"),\n",
    "                    \"graph_id\": graph_id,\n",
    "                    \"anchor_path\": [int(x) for x in path],\n",
    "                    \"positive_path\": [int(x) for x in path],\n",
    "                    \"negative_path\": [int(x) for x in neg_path]\n",
    "                }\n",
    "                self.f_path.write(json.dumps(path_record, ensure_ascii=False) + \"\\n\")\n",
    "                ent_i = rec.get(\"entities\", {}).get(f\"N{int(i)}\", {})\n",
    "                q = ent_i.get(\"name\", str(i))\n",
    "                pos_text = rec.get(\"pos_snippet\", \"\")\n",
    "                neg_text = rec.get(\"neg_snippet\", \"\")\n",
    "                embedder_record = {\n",
    "                    \"record_id\": safe_id(\"emb\"),\n",
    "                    \"graph_id\": graph_id,\n",
    "                    \"query\": q,\n",
    "                    \"positive\": pos_text,\n",
    "                    \"negative\": neg_text\n",
    "                }\n",
    "                self.f_embedder.write(json.dumps(embedder_record, ensure_ascii=False) + \"\\n\")\n",
    "                cpc_record = {\n",
    "                    \"record_id\": safe_id(\"cpc\"),\n",
    "                    \"graph_id\": graph_id,\n",
    "                    \"i\": int(i),\n",
    "                    \"j\": int(j),\n",
    "                    \"domain\": rec.get(\"domain\", \"unknown\"),\n",
    "                    \"pos_snippet\": pos_text,\n",
    "                    \"neg_snippet\": neg_text,\n",
    "                    \"pos_score\": float(pos_score),\n",
    "                    \"neg_score\": float(neg_score),\n",
    "                    \"label_plausible_pos\": int(pos_score >= 0.5),\n",
    "                    \"label_plausible_neg\": int(neg_score >= 0.5)\n",
    "                }\n",
    "                self.f_cpc.write(json.dumps(cpc_record, ensure_ascii=False) + \"\\n\")\n",
    "                index_entry = {\n",
    "                    \"index_id\": safe_id(\"idx\"),\n",
    "                    \"graph_id\": graph_id,\n",
    "                    \"i\": int(i),\n",
    "                    \"j\": int(j),\n",
    "                    \"fusion_id\": fusion_record[\"record_id\"],\n",
    "                    \"lpa_id\": lpa_record[\"record_id\"],\n",
    "                    \"path_id\": path_record[\"record_id\"],\n",
    "                    \"embedder_id\": embedder_record[\"record_id\"],\n",
    "                    \"cpc_id\": cpc_record[\"record_id\"]\n",
    "                }\n",
    "                self.f_index.write(json.dumps(index_entry, ensure_ascii=False) + \"\\n\")\n",
    "        self._close_output_files()\n",
    "        print(\"Dsynth generation finished. Output files in:\", self.out_dir.resolve())\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# main\n",
    "# --------------------------------------------------------------------\n",
    "def main():\n",
    "    gen = DsynthGeneratorFromDcorpus(dcorpus_base=DCORPUS_BASE, out_dir=OUT_DIR)\n",
    "    gen.generate()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4aa486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2262097c",
   "metadata": {},
   "source": [
    "## (b). Pre-train Models (Bootstrap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc4ec03",
   "metadata": {},
   "source": [
    "### i. Train $f_{embed-sota}$ (causality-aware embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2276e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import sys\n",
    "from dataclasses import dataclass, asdict\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---------------------------\n",
    "# Configuration \n",
    "# ---------------------------\n",
    "RNG_SEED = 20251127\n",
    "random.seed(RNG_SEED)\n",
    "np.random.seed(RNG_SEED)\n",
    "torch.manual_seed(RNG_SEED)\n",
    "\n",
    "DATA_PATH = Path(\"out/dsynth/TrainingSetEmbedder.jsonl\")\n",
    "MODEL_DIR = Path(\"models/fembed_sota\")\n",
    "LOG_DIR = Path(\"logs\")\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LOG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "BACKBONE_NAME = \"all-MiniLM-L6-v2\"   # sentence-transformers model\n",
    "DBACKBONE = 384                      # all-MiniLM-L6-v2 typical dim\n",
    "DEMBED = 256                         # target embedding dim after projection head\n",
    "BATCH_SIZE = 64                      # total batch size \n",
    "LR = 2e-5\n",
    "WEIGHT_DECAY = 1e-6\n",
    "NUM_EPOCHS = 10\n",
    "TEMPERATURE = 0.07\n",
    "GRAD_ACCUM_STEPS = 1\n",
    "PATIENCE = 3                         # early stopping patience on validation loss\n",
    "VAL_SPLIT = 0.05                     # fraction of records used for heldout validation\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "MIN_POS_PER_QUERY = 1            \n",
    "\n",
    "# ---------------------------\n",
    "# Utilities\n",
    "# ---------------------------\n",
    "def write_log(msg: str):\n",
    "    path = LOG_DIR / \"fembed_train.log\"\n",
    "    with open(path, \"a\", encoding=\"utf8\") as fh:\n",
    "        fh.write(msg + \"\\n\")\n",
    "    print(msg)\n",
    "\n",
    "@dataclass\n",
    "class HyperParams:\n",
    "    backbone: str = BACKBONE_NAME\n",
    "    d_backbone: int = DBACKBONE\n",
    "    d_embed: int = DEMBED\n",
    "    batch_size: int = BATCH_SIZE\n",
    "    lr: float = LR\n",
    "    weight_decay: float = WEIGHT_DECAY\n",
    "    epochs: int = NUM_EPOCHS\n",
    "    temperature: float = TEMPERATURE\n",
    "    device: str = DEVICE\n",
    "    val_split: float = VAL_SPLIT\n",
    "\n",
    "# ---------------------------\n",
    "# Dataset\n",
    "# ---------------------------\n",
    "class EmbedderTripletDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Loads TrainingSetEmbedder JSONL and yields structured examples:\n",
    "      {\n",
    "        \"query\": str,\n",
    "        \"positives\": List[str],\n",
    "        \"negatives\": List[str],\n",
    "        \"domain\": str\n",
    "      }\n",
    "    \"\"\"\n",
    "    def __init__(self, path: Path):\n",
    "        if not path.exists():\n",
    "            raise FileNotFoundError(f\"TrainingSetEmbedder not found at {path}. Please run Phase-3 to generate it.\")\n",
    "        self.records = []\n",
    "        with path.open(\"r\", encoding=\"utf8\") as fh:\n",
    "            for line in fh:\n",
    "                rec = json.loads(line)\n",
    "                # normalize fields\n",
    "                query = rec.get(\"query\") or rec.get(\"q\") or \"\"\n",
    "                pos = rec.get(\"positive\") or rec.get(\"positives\") or rec.get(\"spos\") or []\n",
    "                neg = rec.get(\"negative\") or rec.get(\"negatives\") or rec.get(\"sneg\") or []\n",
    "                domain = rec.get(\"domain\") or rec.get(\"graph_id\") or \"unknown\"\n",
    "                if isinstance(pos, str):\n",
    "                    pos = [pos]\n",
    "                if isinstance(neg, str):\n",
    "                    neg = [neg]\n",
    "                if len(pos) == 0:\n",
    "                    continue\n",
    "                self.records.append({\"query\": query, \"positives\": pos, \"negatives\": neg, \"domain\": domain})\n",
    "        if len(self.records) == 0:\n",
    "            raise RuntimeError(\"No records loaded from TrainingSetEmbedder. Aborting.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.records)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.records[idx]\n",
    "\n",
    "# ---------------------------\n",
    "# Domain-balanced sampler\n",
    "# ---------------------------\n",
    "class DomainBalancedBatchSampler(Sampler):\n",
    "    \"\"\"\n",
    "    Produces batches that are domain-balanced.\n",
    "    Implementation:\n",
    "      - Group indices by domain\n",
    "      - For each batch, sample ceil(batch_size / num_domains) indices from each domain group (deterministic shuffle)\n",
    "      - If a domain runs out, cycle deterministically\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset: EmbedderTripletDataset, batch_size: int):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        # group indices\n",
    "        self.groups: Dict[str, List[int]] = {}\n",
    "        for i, rec in enumerate(self.dataset.records):\n",
    "            d = rec[\"domain\"]\n",
    "            self.groups.setdefault(d, []).append(i)\n",
    "        # deterministic shuffle per group\n",
    "        for d, arr in self.groups.items():\n",
    "            rng = random.Random(RNG_SEED ^ abs(hash(d)))\n",
    "            rng.shuffle(arr)\n",
    "            self.groups[d] = arr\n",
    "        self.domains = sorted(list(self.groups.keys()))\n",
    "        self.domain_iter_pos = {d: 0 for d in self.domains}\n",
    "        self.num_batches = math.ceil(len(dataset) / batch_size)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for _ in range(self.num_batches):\n",
    "            per_domain = math.ceil(self.batch_size / max(1, len(self.domains)))\n",
    "            batch = []\n",
    "            for d in self.domains:\n",
    "                arr = self.groups[d]\n",
    "                pos = self.domain_iter_pos[d]\n",
    "                take = per_domain\n",
    "                selected = []\n",
    "                for t in range(take):\n",
    "                    if len(arr) == 0:\n",
    "                        continue\n",
    "                    selected.append(arr[(pos + t) % len(arr)])\n",
    "                # advance position\n",
    "                self.domain_iter_pos[d] = (pos + take) % (len(arr) if len(arr) > 0 else 1)\n",
    "                batch.extend(selected)\n",
    "                if len(batch) >= self.batch_size:\n",
    "                    break\n",
    "            # trim to exact batch size\n",
    "            batch = batch[:self.batch_size]\n",
    "            yield batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_batches\n",
    "\n",
    "# ---------------------------\n",
    "# Model: backbone + projection head + L2 norm\n",
    "# ---------------------------\n",
    "class FEmbedSOTA(nn.Module):\n",
    "    def __init__(self, backbone_name: str = BACKBONE_NAME, d_embed: int = DEMBED):\n",
    "        super().__init__()\n",
    "        # sentence-transformers backbone\n",
    "        self.backbone = SentenceTransformer(backbone_name)\n",
    "        self.backbone.max_seq_length = 256\n",
    "        d_backbone = self.backbone.get_sentence_embedding_dimension()\n",
    "        # two-layer MLP projection head\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Linear(d_backbone, d_backbone),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(d_backbone, d_embed)\n",
    "        )\n",
    "        # small dropout for stochastic views (dropout acts as stochastic view in training)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "\n",
    "    def encode(self, texts: List[str], batch_size: int = 64, device: str = DEVICE) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Encode a list of texts into normalized embeddings (torch.Tensor shape [N, d_embed]).\n",
    "        Uses backbone's encode in batches for speed.\n",
    "        \"\"\"\n",
    "        # backbone.encode returns numpy float32\n",
    "        embs = self.backbone.encode(texts, batch_size=batch_size, show_progress_bar=False)\n",
    "        embs = torch.from_numpy(embs).to(device)\n",
    "        with torch.no_grad():\n",
    "            # pass through projection\n",
    "            z = self.proj(embs)\n",
    "            z = F.normalize(z, p=2, dim=1)\n",
    "        return z\n",
    "\n",
    "    def forward(self, texts: List[str]) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward for training: compute backbone repr then projection (with dropout for stochasticity).\n",
    "        Returns L2-normalized embeddings tensor [len(texts), d_embed]\n",
    "        \"\"\"\n",
    "        # backbone.encode is not differentiable through sentence-transformers easily,\n",
    "        # but sentence-transformers models support forward call; use self.backbone.encode for simplicity.\n",
    "        # To enable backprop through backbone, we use .tokenize + backbone._first_module_forward? For simplicity and clarity\n",
    "        # we will use the backbone model's forward via encode (SentenceTransformers handles gradient if model in train())\n",
    "        # So we will use encode with convert_to_tensor=True\n",
    "        # However to keep code simple & robust across library versions, we do a two-step via SentenceTransformer's model:\n",
    "        models = self.backbone._first_module().auto_model.config if hasattr(self.backbone._first_module(), \"auto_model\") else None\n",
    "        emb = self.backbone.encode(texts, convert_to_tensor=True, show_progress_bar=False)\n",
    "        x = self.dropout(emb)\n",
    "        z = self.proj(x)\n",
    "        z = F.normalize(z, p=2, dim=1)\n",
    "        return z\n",
    "\n",
    "# ---------------------------\n",
    "# Loss: supervised contrastive for a batch of queries\n",
    "# ---------------------------\n",
    "def supervised_contrastive_loss(queries_emb: torch.Tensor,\n",
    "                                positives_emb_list: List[torch.Tensor],\n",
    "                                negatives_emb: torch.Tensor,\n",
    "                                temperature: float = TEMPERATURE,\n",
    "                                device: str = DEVICE) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    queries_emb: [B, D]\n",
    "    positives_emb_list: list of tensors, each [B, D] (one positive view per list element). Typically length > 0.\n",
    "    negatives_emb: [Nneg, D] negatives pool (in-batch + external)\n",
    "    Computes per-query supervised contrastive where P(q) = {positives for that query} and N(q) = negatives_emb.\n",
    "    Formula:\n",
    "      For each query i:\n",
    "        L_i = - (1/|P_i|) sum_{p in P_i} log (exp(sim(qi, p)/tau) / sum_{z in P_i  N} exp(sim(qi, z)/tau))\n",
    "    Returns scalar loss averaged over batch.\n",
    "    \"\"\"\n",
    "    eps = 1e-8\n",
    "    B, D = queries_emb.shape\n",
    "    # concatenate positives into a single matrix P_all [P_total, D], but we need per-query indexing.\n",
    "    # positives_emb_list is list of [B,D] (each entry corresponds to a \"view\" of positives aligned by batch)\n",
    "    # We will compute for each query i numerator terms over the positives at index i across the list.\n",
    "    negatives = negatives_emb  # [Nneg, D]\n",
    "    # Precompute similarities\n",
    "    # queries_emb: [B, D]; positives_emb_list: L x [B, D]; negatives: [Nneg, D]\n",
    "    loss_sum = 0.0\n",
    "    count_q = 0\n",
    "    # move to device\n",
    "    queries_emb = queries_emb.to(device)\n",
    "    negatives = negatives.to(device) if negatives is not None and negatives.numel() > 0 else torch.empty((0, D), device=device)\n",
    "    for i in range(B):\n",
    "        q = queries_emb[i].unsqueeze(0)  # [1,D]\n",
    "        # gather positives for query i\n",
    "        P_i = []\n",
    "        for p_emb in positives_emb_list:\n",
    "            P_i.append(p_emb[i].unsqueeze(0))  # [1,D]\n",
    "        if len(P_i) == 0:\n",
    "            continue\n",
    "        P_i = torch.cat(P_i, dim=0)  # [P, D]\n",
    "        # compute sims\n",
    "        sims_pos = torch.matmul(P_i, q.t()).squeeze(1) / temperature  # [P]\n",
    "        # denominator: exp over P_i and negatives\n",
    "        denom_terms = torch.exp(sims_pos)\n",
    "        if negatives.numel() > 0:\n",
    "            sims_neg = torch.matmul(negatives, q.t()).squeeze(1) / temperature  # [Nneg]\n",
    "            denom_terms = torch.cat([denom_terms, torch.exp(sims_neg)], dim=0)\n",
    "        denom = denom_terms.sum() + eps\n",
    "        numer = torch.exp(sims_pos)\n",
    "        # loss_i = - (1/|P|) sum_p log(numer_p / denom)\n",
    "        loss_i = - (1.0 / float(P_i.shape[0])) * torch.sum(torch.log(numer / denom + 1e-12))\n",
    "        loss_sum += loss_i\n",
    "        count_q += 1\n",
    "    if count_q == 0:\n",
    "        return torch.tensor(0.0, requires_grad=True, device=device)\n",
    "    return (loss_sum / float(count_q)).to(device)\n",
    "\n",
    "# ---------------------------\n",
    "# Collate function for DataLoader\n",
    "# ---------------------------\n",
    "def collate_batch(dataset: EmbedderTripletDataset, indices: List[int]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Build batch dict:\n",
    "      - queries: List[str] length B\n",
    "      - positives: List[List[str]] length B x P_i\n",
    "      - negatives_pool: List[str] containing negatives aggregated across batch and optionally in-batch negatives\n",
    "      - domains: List[str]\n",
    "    \"\"\"\n",
    "    queries = []\n",
    "    pos_views_per_query = []\n",
    "    neg_pool = []\n",
    "    domains = []\n",
    "    # also gather in-batch positives as possible negatives for other queries (in-batch negatives)\n",
    "    for idx in indices:\n",
    "        rec = dataset.records[idx]\n",
    "        q = rec[\"query\"]\n",
    "        pos = rec[\"positives\"]\n",
    "        neg = rec[\"negatives\"]\n",
    "        d = rec.get(\"domain\", \"unknown\")\n",
    "        queries.append(q)\n",
    "        pos_views_per_query.append(pos[:])   # copy list\n",
    "        neg_pool.extend(neg)\n",
    "        domains.append(d)\n",
    "    # include in-batch positives into negatives_pool (so they act as in-batch negatives)\n",
    "    for p_list in pos_views_per_query:\n",
    "        neg_pool.extend(p_list)\n",
    "    # deduplicate negatives pool deterministically\n",
    "    seen = set()\n",
    "    neg_pool_unique = []\n",
    "    for t in neg_pool:\n",
    "        if t not in seen:\n",
    "            neg_pool_unique.append(t)\n",
    "            seen.add(t)\n",
    "    return {\"queries\": queries, \"positives\": pos_views_per_query, \"neg_pool\": neg_pool_unique, \"domains\": domains}\n",
    "\n",
    "# ---------------------------\n",
    "# Training loop\n",
    "# ---------------------------\n",
    "def train():\n",
    "    hp = HyperParams()\n",
    "    with open(MODEL_DIR / \"config.json\", \"w\", encoding=\"utf8\") as fh:\n",
    "        json.dump(asdict(hp), fh, indent=2)\n",
    "\n",
    "    dataset = EmbedderTripletDataset(DATA_PATH)\n",
    "    # split into train/val deterministically\n",
    "    n = len(dataset)\n",
    "    n_val = max(1, int(n * VAL_SPLIT))\n",
    "    # deterministic split\n",
    "    indices = list(range(n))\n",
    "    rng = random.Random(RNG_SEED)\n",
    "    rng.shuffle(indices)\n",
    "    val_indices = indices[:n_val]\n",
    "    train_indices = indices[n_val:]\n",
    "\n",
    "    train_subset = torch.utils.data.Subset(dataset, train_indices)\n",
    "    val_subset = torch.utils.data.Subset(dataset, val_indices)\n",
    "\n",
    "    train_sampler = DomainBalancedBatchSampler(dataset=dataset, batch_size=BATCH_SIZE)\n",
    "    train_loader = DataLoader(dataset, batch_sampler=train_sampler, collate_fn=lambda idxs: collate_batch(dataset, idxs), num_workers=0)\n",
    "\n",
    "    # validation loader: simple sequential batches\n",
    "    val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=lambda batch: collate_batch(dataset, [dataset.records.index(x) for x in batch]))\n",
    "\n",
    "    # model\n",
    "    model = FEmbedSOTA(backbone_name=BACKBONE_NAME, d_embed=DEMBED).to(DEVICE)\n",
    "    # optimizer only for projection head + backbone parameters (sentence-transformers internal param grouping)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    # training loop\n",
    "    global_step = 0\n",
    "    for epoch in range(1, NUM_EPOCHS + 1):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        step = 0\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{NUM_EPOCHS}\")\n",
    "        for batch in pbar:\n",
    "            global_step += 1\n",
    "            step += 1\n",
    "            queries = batch[\"queries\"]                # list length B\n",
    "            positives_list = batch[\"positives\"]       # list length B, each list of strings (>=1)\n",
    "            neg_pool = batch[\"neg_pool\"]              # list of strings (negatives pool)\n",
    "            # 1) construct lists for embedding: we will compute embeddings for queries, for positives views, and for negatives pool\n",
    "            # Flatten positives views into L lists where each list is a length-B list (if some queries have fewer views, pad by repeating)\n",
    "            # Strategy: we create up to max_views views per query (determined by max positives in batch)\n",
    "            max_views = max(len(p) for p in positives_list)\n",
    "            pos_views_texts = []   # each entry is list of length B\n",
    "            for v in range(max_views):\n",
    "                view = []\n",
    "                for p in positives_list:\n",
    "                    if v < len(p):\n",
    "                        view.append(p[v])\n",
    "                    else:\n",
    "                        view.append(p[0])  # repeat first positive deterministically\n",
    "                pos_views_texts.append(view)\n",
    "            # compute embeddings\n",
    "            # queries embeddings [B, D]\n",
    "            queries_emb = model(queries)  # model.forward handles batching\n",
    "            # positives embeddings: list of tensors each [B, D]\n",
    "            positives_emb_list = []\n",
    "            for view_texts in pos_views_texts:\n",
    "                emb = model(view_texts)\n",
    "                positives_emb_list.append(emb)\n",
    "            # negatives pool embeddings [Nneg, D]\n",
    "            neg_emb = None\n",
    "            if len(neg_pool) > 0:\n",
    "                neg_emb = model(neg_pool)\n",
    "            else:\n",
    "                neg_emb = torch.empty((0, DEMBED), device=DEVICE)\n",
    "            # compute loss\n",
    "            loss = supervised_contrastive_loss(queries_emb, positives_emb_list, neg_emb, temperature=TEMPERATURE, device=DEVICE)\n",
    "            # backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += float(loss.item())\n",
    "            pbar.set_postfix({\"loss\": f\"{epoch_loss/step:.6f}\"})\n",
    "            write_log(f\"epoch={epoch} step={step} loss={float(loss.item()):.6f}\")\n",
    "        avg_epoch_loss = epoch_loss / max(1, step)\n",
    "        write_log(f\"[EPOCH {epoch}] train_loss={avg_epoch_loss:.6f}\")\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss_accum = 0.0\n",
    "        val_steps = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=\"Validation\"):\n",
    "                queries = batch[\"queries\"]\n",
    "                positives_list = batch[\"positives\"]\n",
    "                neg_pool = batch[\"neg_pool\"]\n",
    "                queries_emb = model(queries)\n",
    "                max_views = max(len(p) for p in positives_list)\n",
    "                pos_views_texts = []\n",
    "                for v in range(max_views):\n",
    "                    view = []\n",
    "                    for p in positives_list:\n",
    "                        if v < len(p):\n",
    "                            view.append(p[v])\n",
    "                        else:\n",
    "                            view.append(p[0])\n",
    "                    pos_views_texts.append(view)\n",
    "                positives_emb_list = [model(view_texts) for view_texts in pos_views_texts]\n",
    "                neg_emb = model(neg_pool) if len(neg_pool)>0 else torch.empty((0, DEMBED), device=DEVICE)\n",
    "                loss_val = supervised_contrastive_loss(queries_emb, positives_emb_list, neg_emb, temperature=TEMPERATURE, device=DEVICE)\n",
    "                val_loss_accum += float(loss_val.item())\n",
    "                val_steps += 1\n",
    "        avg_val_loss = val_loss_accum / max(1, val_steps)\n",
    "        write_log(f\"[EPOCH {epoch}] val_loss={avg_val_loss:.6f}\")\n",
    "\n",
    "        # Early stopping & checkpointing\n",
    "        # Save last\n",
    "        torch.save(model.state_dict(), MODEL_DIR / \"checkpoint_last.pth\")\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(), MODEL_DIR / \"checkpoint_best.pth\")\n",
    "            write_log(f\"[EPOCH {epoch}] new best_val_loss={best_val_loss:.6f} -> saved checkpoint_best.pth\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            write_log(f\"[EPOCH {epoch}] no improvement ({epochs_no_improve}/{PATIENCE})\")\n",
    "            if epochs_no_improve >= PATIENCE:\n",
    "                write_log(f\"Early stopping triggered at epoch {epoch}\")\n",
    "                break\n",
    "\n",
    "    # After training: compute embeddings for validation queries and save\n",
    "    model.eval()\n",
    "    val_queries = [dataset.records[i][\"query\"] for i in val_indices]\n",
    "    if len(val_queries) > 0:\n",
    "        batch_size_emb = 64\n",
    "        all_embs = []\n",
    "        for i in range(0, len(val_queries), batch_size_emb):\n",
    "            batch_texts = val_queries[i:i+batch_size_emb]\n",
    "            emb = model(batch_texts).detach().cpu().numpy()\n",
    "            all_embs.append(emb)\n",
    "        all_embs = np.vstack(all_embs)\n",
    "        np.save(MODEL_DIR / \"val_embeddings.npy\", all_embs)\n",
    "        write_log(f\"Saved val embeddings: shape={all_embs.shape} -> {MODEL_DIR/'val_embeddings.npy'}\")\n",
    "\n",
    "    write_log(\"Training finished.\")\n",
    "    with open(MODEL_DIR / \"train_info.json\", \"w\", encoding=\"utf8\") as fh:\n",
    "        meta = {\n",
    "            \"model_dir\": str(MODEL_DIR.resolve()),\n",
    "            \"device\": DEVICE,\n",
    "            \"num_epochs_run\": epoch,\n",
    "            \"best_val_loss\": float(best_val_loss)\n",
    "        }\n",
    "        json.dump(meta, fh, indent=2)\n",
    "    return\n",
    "\n",
    "# ---------------------------\n",
    "# Entrypoint\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    write_log(\"Starting f_embed-sota training run\")\n",
    "    try:\n",
    "        train()\n",
    "    except Exception as e:\n",
    "        write_log(f\"FATAL ERROR: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2ff0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluating the above:\n",
    "\n",
    "\n",
    "from __future__ import annotations\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---------------------------\n",
    "# Config \n",
    "# ---------------------------\n",
    "RNG_SEED = 20251127\n",
    "random.seed(RNG_SEED)\n",
    "np.random.seed(RNG_SEED)\n",
    "torch.manual_seed(RNG_SEED)\n",
    "\n",
    "DATA_PATH = Path(\"out/dsynth/TrainingSetEmbedder.jsonl\")\n",
    "MODEL_DIR = Path(\"models/fembed_sota\")\n",
    "CHECKPOINT = MODEL_DIR / \"checkpoint_best.pth\"\n",
    "CONFIG_JSON = MODEL_DIR / \"config.json\"\n",
    "LOG_OUT = Path(\"logs/fembed_eval.json\")\n",
    "BACKBONE_NAME = \"all-MiniLM-L6-v2\"\n",
    "DEMBED = 256\n",
    "VAL_SPLIT = 0.05\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_ENC = 128\n",
    "\n",
    "# ---------------------------\n",
    "# Model class\n",
    "# ---------------------------\n",
    "class FEmbedSOTA(nn.Module):\n",
    "    def __init__(self, backbone_name: str = BACKBONE_NAME, d_embed: int = DEMBED):\n",
    "        super().__init__()\n",
    "        self.backbone = SentenceTransformer(backbone_name)\n",
    "        self.backbone.max_seq_length = 256\n",
    "        d_backbone = self.backbone.get_sentence_embedding_dimension()\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Linear(d_backbone, d_backbone),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(d_backbone, d_embed)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(p=0.0)  # no dropout for eval\n",
    "\n",
    "    def encode_texts(self, texts: List[str], batch_size: int = BATCH_ENC, device: str = DEVICE) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Returns numpy array shape [N, d_embed] L2-normalized\n",
    "        \"\"\"\n",
    "        all_embs = []\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i+batch_size]\n",
    "            emb = self.backbone.encode(batch, convert_to_tensor=True, show_progress_bar=False)\n",
    "            with torch.no_grad():\n",
    "                emb = emb.to(device)\n",
    "                z = self.proj(emb)\n",
    "                z = F.normalize(z, p=2, dim=1)\n",
    "                all_embs.append(z.cpu().numpy())\n",
    "        if not all_embs:\n",
    "            return np.zeros((0, DEMBED), dtype=np.float32)\n",
    "        return np.vstack(all_embs)\n",
    "\n",
    "# ---------------------------\n",
    "# Data loader for validation split\n",
    "# ---------------------------\n",
    "def load_embedder_records(path: Path) -> List[Dict[str,Any]]:\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"TrainingSetEmbedder not found at {path}\")\n",
    "    recs = []\n",
    "    with path.open(\"r\", encoding=\"utf8\") as fh:\n",
    "        for line in fh:\n",
    "            rec = json.loads(line)\n",
    "            # normalize\n",
    "            query = rec.get(\"query\") or \"\"\n",
    "            pos = rec.get(\"positive\") or rec.get(\"positives\") or []\n",
    "            neg = rec.get(\"negative\") or rec.get(\"negatives\") or []\n",
    "            domain = rec.get(\"domain\") or rec.get(\"graph_id\") or \"unknown\"\n",
    "            if isinstance(pos, str):\n",
    "                pos = [pos]\n",
    "            if isinstance(neg, str):\n",
    "                neg = [neg]\n",
    "            recs.append({\"query\": query, \"positives\": pos, \"negatives\": neg, \"domain\": domain, \"raw\": rec})\n",
    "    return recs\n",
    "\n",
    "def deterministic_split(records: List[Dict[str,Any]], val_frac: float = VAL_SPLIT):\n",
    "    n = len(records)\n",
    "    n_val = max(1, int(n * val_frac))\n",
    "    indices = list(range(n))\n",
    "    rng = random.Random(RNG_SEED)\n",
    "    rng.shuffle(indices)\n",
    "    val_idx = set(indices[:n_val])\n",
    "    train_idx = set(indices[n_val:])\n",
    "    val = [records[i] for i in sorted(val_idx)]\n",
    "    train = [records[i] for i in sorted(train_idx)]\n",
    "    return train, val\n",
    "\n",
    "# ---------------------------\n",
    "# Metrics\n",
    "# ---------------------------\n",
    "def recall_at_k(query_emb: np.ndarray, positives_idx: List[int], candidate_embs: np.ndarray, k: int) -> int:\n",
    "    # query_emb: [d,], candidate_embs: [M, d]\n",
    "    sims = candidate_embs @ query_emb\n",
    "    topk = np.argsort(-sims)[:k]\n",
    "    # if any positive index in topk -> success (1), else 0\n",
    "    return int(any((pi in topk) for pi in positives_idx))\n",
    "\n",
    "def mrr_score(query_emb: np.ndarray, positives_idx: List[int], candidate_embs: np.ndarray) -> float:\n",
    "    sims = candidate_embs @ query_emb\n",
    "    order = np.argsort(-sims)\n",
    "    # find rank of first relevant\n",
    "    for rank, idx in enumerate(order, start=1):\n",
    "        if idx in positives_idx:\n",
    "            return 1.0 / rank\n",
    "    return 0.0\n",
    "\n",
    "def ndcg_at_k(query_emb: np.ndarray, positives_idx: List[int], candidate_embs: np.ndarray, k: int) -> float:\n",
    "    sims = candidate_embs @ query_emb\n",
    "    order = np.argsort(-sims)[:k]\n",
    "    dcg = 0.0\n",
    "    idcg = 0.0\n",
    "    # gain 1 for each relevant\n",
    "    for i, idx in enumerate(order):\n",
    "        rel = 1 if idx in positives_idx else 0\n",
    "        dcg += (2**rel - 1) / math.log2(i + 2)\n",
    "    ideal_rels = min(len(positives_idx), k)\n",
    "    for i in range(ideal_rels):\n",
    "        idcg += (2**1 - 1) / math.log2(i + 2)\n",
    "    return (dcg / idcg) if idcg > 0 else 0.0\n",
    "\n",
    "# ---------------------------\n",
    "# Build candidate pool and index map\n",
    "# ---------------------------\n",
    "def build_candidate_pool(val_records: List[Dict[str,Any]]):\n",
    "    # pool = unique positives + unique negatives across val set\n",
    "    pool_texts = []\n",
    "    pool_map = {}  # text -> index\n",
    "    # deterministic order: iterate val_records then pos then neg\n",
    "    for rec in val_records:\n",
    "        for p in rec[\"positives\"]:\n",
    "            if p not in pool_map:\n",
    "                pool_map[p] = len(pool_texts)\n",
    "                pool_texts.append(p)\n",
    "        for n in rec[\"negatives\"]:\n",
    "            if n not in pool_map:\n",
    "                pool_map[n] = len(pool_texts)\n",
    "                pool_texts.append(n)\n",
    "    return pool_texts, pool_map\n",
    "\n",
    "# ---------------------------\n",
    "# Main eval flow\n",
    "# ---------------------------\n",
    "def evaluate():\n",
    "    # 1) load records and split\n",
    "    records = load_embedder_records(DATA_PATH)\n",
    "    train, val = deterministic_split(records, val_frac=VAL_SPLIT)\n",
    "    print(f\"Total records: {len(records)}  Train: {len(train)}  Val: {len(val)}\")\n",
    "\n",
    "    # 2) build candidate pool from val\n",
    "    pool_texts, pool_map = build_candidate_pool(val)\n",
    "    if len(pool_texts) == 0:\n",
    "        raise RuntimeError(\"No candidate texts in validation set.\")\n",
    "    print(f\"Candidate pool size: {len(pool_texts)}\")\n",
    "\n",
    "    # 3) load model\n",
    "    model = FEmbedSOTA(BACKBONE_NAME, DEMBED)\n",
    "    model.to(DEVICE)\n",
    "    if not CHECKPOINT.exists():\n",
    "        raise FileNotFoundError(f\"Model checkpoint not found: {CHECKPOINT}. Train first.\")\n",
    "    state = torch.load(CHECKPOINT, map_location=DEVICE)\n",
    "    \n",
    "    try:\n",
    "        model.load_state_dict(state)\n",
    "    except Exception:\n",
    "        missing = model.state_dict()\n",
    "        for k in state:\n",
    "            if k in missing:\n",
    "                missing[k] = state[k]\n",
    "        model.load_state_dict(state, strict=False)\n",
    "    model.eval()\n",
    "\n",
    "    # 4) compute candidate pool embeddings\n",
    "    print(\"Encoding candidate pool...\")\n",
    "    pool_embs = model.encode_texts(pool_texts, batch_size=BATCH_ENC, device=DEVICE)  # [M, d]\n",
    "\n",
    "    # 5) evaluation: for each query in val, compute metrics\n",
    "    recalls_k = {1: 0, 5: 0, 10: 0}\n",
    "    mrr_acc = 0.0\n",
    "    ndcg_acc = {1: 0.0, 5: 0.0, 10: 0.0}\n",
    "    mean_pos_cos = []\n",
    "    mean_neg_cos = []\n",
    "\n",
    "    for rec in tqdm(val, desc=\"Evaluating\"):\n",
    "        q = rec[\"query\"]\n",
    "        if not q:\n",
    "            continue\n",
    "        q_emb = model.encode_texts([q], batch_size=1, device=DEVICE)[0]  # [d]\n",
    "        # positives index set\n",
    "        pos_indices = [pool_map[p] for p in rec[\"positives\"] if p in pool_map]\n",
    "        # negatives index set \n",
    "        neg_indices = [pool_map[n] for n in rec[\"negatives\"] if n in pool_map]\n",
    "        # metrics\n",
    "        for k in [1,5,10]:\n",
    "            recalls_k[k] += recall_at_k(q_emb, pos_indices, pool_embs, k)\n",
    "        mrr_acc += mrr_score(q_emb, pos_indices, pool_embs)\n",
    "        for k in [1,5,10]:\n",
    "            ndcg_acc[k] += ndcg_at_k(q_emb, pos_indices, pool_embs, k)\n",
    "        # cosines\n",
    "        if pos_indices:\n",
    "            cos_pos = np.mean(pool_embs[pos_indices] @ q_emb)\n",
    "            mean_pos_cos.append(float(cos_pos))\n",
    "        if neg_indices:\n",
    "            cos_neg = np.mean(pool_embs[neg_indices] @ q_emb)\n",
    "            mean_neg_cos.append(float(cos_neg))\n",
    "\n",
    "    N = len(val)\n",
    "    metrics = {\n",
    "        \"num_val\": int(N),\n",
    "        \"recall@1\": float(recalls_k[1] / N),\n",
    "        \"recall@5\": float(recalls_k[5] / N),\n",
    "        \"recall@10\": float(recalls_k[10] / N),\n",
    "        \"mrr\": float(mrr_acc / N),\n",
    "        \"ndcg@1\": float(ndcg_acc[1] / N),\n",
    "        \"ndcg@5\": float(ndcg_acc[5] / N),\n",
    "        \"ndcg@10\": float(ndcg_acc[10] / N),\n",
    "        \"mean_pos_cos\": float(np.mean(mean_pos_cos) if mean_pos_cos else 0.0),\n",
    "        \"mean_neg_cos\": float(np.mean(mean_neg_cos) if mean_neg_cos else 0.0),\n",
    "    }\n",
    "\n",
    "    # sample nearest neighbors for first 5 val queries for inspection\n",
    "    neighbors_sample = []\n",
    "    for rec in val[:5]:\n",
    "        q = rec[\"query\"]\n",
    "        q_emb = model.encode_texts([q], batch_size=1, device=DEVICE)[0]\n",
    "        sims = pool_embs @ q_emb\n",
    "        order = np.argsort(-sims)[:20]\n",
    "        neighbors = [{\"text\": pool_texts[int(idx)], \"score\": float(sims[int(idx)])} for idx in order[:10]]\n",
    "        neighbors_sample.append({\"query\": q, \"neighbors\": neighbors})\n",
    "\n",
    "    out = {\"metrics\": metrics, \"sample_neighbors\": neighbors_sample}\n",
    "    LOG_OUT.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with LOG_OUT.open(\"w\", encoding=\"utf8\") as fh:\n",
    "        json.dump(out, fh, indent=2)\n",
    "\n",
    "    print(\"\\nEvaluation Summary:\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "    print(f\"\\nDetailed sample neighbors & metrics saved to: {LOG_OUT.resolve()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641193a9",
   "metadata": {},
   "source": [
    "Benchmarks & evaluation protocols (what else you can evaluate against)\n",
    "\n",
    "Retrieval metrics (we implemented): Recall@K, MRR, NDCG@K  primary for embedder quality.\n",
    "\n",
    "Alignment with CPC: compute cosine/euclidean distance between CPC-projection embeddings (if CPC trained) and f_embed outputs for same contexts; report mean L2 and Spearman correlation.\n",
    "\n",
    "Downstream retrieval+classification: feed top-K retrieved snippets into CPC + Fusion, then measure end-to-end direct-cause detection (AUC / PR) using Dsynth or held-out synthetic test set.\n",
    "\n",
    "Hard-negative robustness: evaluate how metrics change when replacing in-batch negatives by curated hard-negatives only.\n",
    "\n",
    "Domain generalization: compute per-domain metrics (finance/politics/medical) to ensure balanced performance.\n",
    "\n",
    "Ablation checks: train/validate with/without projection head, different , different embedding dims.\n",
    "\n",
    "Latent-space probing: cluster purity (k-means on embeddings against motif/regime labels), and silhouette scores to quantify separability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c51b07e",
   "metadata": {},
   "source": [
    "### ii. Train $CPC_{model}$ (semantic filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05601915",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "from dataclasses import dataclass, asdict\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---------------------------\n",
    "# Configuration \n",
    "# ---------------------------\n",
    "RNG_SEED = 20251127\n",
    "random.seed(RNG_SEED)\n",
    "np.random.seed(RNG_SEED)\n",
    "torch.manual_seed(RNG_SEED)\n",
    "\n",
    "TRAINING_SET_PATH = Path(\"out/dsynth/TrainingSetCPC.jsonl\")\n",
    "FEMBED_MODEL_DIR = Path(\"models/fembed_sota\")\n",
    "FEMBED_CHECKPOINT = FEMBED_MODEL_DIR / \"checkpoint_best.pth\"\n",
    "FEMBED_CONFIG = FEMBED_MODEL_DIR / \"config.json\"\n",
    "\n",
    "# Output\n",
    "MODEL_DIR = Path(\"models/cpc_model\")\n",
    "LOG_DIR = Path(\"logs\")\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LOG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Model & training hyperparams\n",
    "ENCODER_MODEL_NAME = \"microsoft/deberta-v3-small\"   # DeBERTa-v3-small (transformers)\n",
    "ENCODER_MAX_LEN = 256\n",
    "D_EMBED = 256             \n",
    "BATCH_SIZE = 64\n",
    "LR = 3e-5\n",
    "WEIGHT_DECAY = 1e-6\n",
    "NUM_EPOCHS = 12\n",
    "GRAD_ACCUM_STEPS = 1\n",
    "VAL_SPLIT = 0.05\n",
    "PATIENCE = 3              # early stopping patience (on val plausibility AUC)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Focal loss params (per-task can be the same initially)\n",
    "FOCAL_GAMMA = 2.0\n",
    "FOCAL_ALPHA = 0.25\n",
    "LABEL_SMOOTH_EPS = 0.05\n",
    "\n",
    "# Alignment weight\n",
    "LAMBDA_ALIGN = 0.1\n",
    "\n",
    "# Curriculum - assumed regime labels present in TrainingSetCPC records as \"regimeid\" with values \"easy\",\"moderate\",\"hard\"\n",
    "CURRICULUM_STAGES = [\"easy\", \"moderate\", \"hard\"]  # training will proceed stage-by-stage\n",
    "USE_CURRICULUM = False   # set to True to enforce stage A->B->C; False runs on full dataset\n",
    "# (USE_CURRICULUM is meant to be used as we want; default False to avoid missing regime tags.)\n",
    "\n",
    "# Logging\n",
    "LOG_FILE = LOG_DIR / \"cpc_train.log\"\n",
    "\n",
    "# ---------------------------\n",
    "# Utilities\n",
    "# ---------------------------\n",
    "def write_log(msg: str):\n",
    "    ts = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "    line = f\"[{ts}] {msg}\"\n",
    "    print(line)\n",
    "    with open(LOG_FILE, \"a\", encoding=\"utf8\") as fh:\n",
    "        fh.write(line + \"\\n\")\n",
    "\n",
    "@dataclass\n",
    "class HyperParams:\n",
    "    encoder_name: str = ENCODER_MODEL_NAME\n",
    "    d_embed: int = D_EMBED\n",
    "    batch_size: int = BATCH_SIZE\n",
    "    lr: float = LR\n",
    "    weight_decay: float = WEIGHT_DECAY\n",
    "    epochs: int = NUM_EPOCHS\n",
    "    focal_gamma: float = FOCAL_GAMMA\n",
    "    focal_alpha: float = FOCAL_ALPHA\n",
    "    label_smooth_eps: float = LABEL_SMOOTH_EPS\n",
    "    lambda_align: float = LAMBDA_ALIGN\n",
    "    device: str = DEVICE\n",
    "\n",
    "# ---------------------------\n",
    "# Data loading: TrainingSetCPC JSONL\n",
    "# ---------------------------\n",
    "class CPCDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Expects each JSON line to contain at least:\n",
    "      - context: str (text)\n",
    "      - i: int or \"pair\": [i,j]  OR fields \"node_i\", \"node_j\"\n",
    "      - yplaus: 0/1 or plaus\n",
    "      - ytemp: 0/1\n",
    "      - ymech: 0/1\n",
    "      - domain: optional\n",
    "      - regimeid: optional (easy/moderate/hard)\n",
    "      - entities: optional mapping id->entity dict (useful to build contextual input)\n",
    "    \"\"\"\n",
    "    def __init__(self, path: Path):\n",
    "        if not path.exists():\n",
    "            raise FileNotFoundError(f\"TrainingSetCPC file not found at {path}\")\n",
    "        self.records: List[Dict[str,Any]] = []\n",
    "        with open(path, \"r\", encoding=\"utf8\") as fh:\n",
    "            for line in fh:\n",
    "                rec = json.loads(line)\n",
    "                # normalize fields\n",
    "                context = rec.get(\"context\") or rec.get(\"pos_snippet\") or rec.get(\"text\") or \"\"\n",
    "                # pair extraction\n",
    "                if \"pair\" in rec and isinstance(rec[\"pair\"], (list, tuple)) and len(rec[\"pair\"])>=2:\n",
    "                    i, j = int(rec[\"pair\"][0]), int(rec[\"pair\"][1])\n",
    "                else:\n",
    "                    i = int(rec.get(\"i\") or rec.get(\"node_i\") or (rec.get(\"node_pair\") or [None,None])[0] or -1)\n",
    "                    j = int(rec.get(\"j\") or rec.get(\"node_j\") or (rec.get(\"node_pair\") or [None,None])[1] or -1)\n",
    "                yplaus = int(rec.get(\"yplaus\", rec.get(\"plaus\", rec.get(\"label_plaus\", 0))))\n",
    "                ytemp = int(rec.get(\"ytemp\", rec.get(\"temp\", 0)))\n",
    "                ymech = int(rec.get(\"ymech\", rec.get(\"mech\", 0)))\n",
    "                domain = rec.get(\"domain\") or rec.get(\"graph_id\") or \"unknown\"\n",
    "                regimeid = rec.get(\"regimeid\") or rec.get(\"regime\") or \"unknown\"\n",
    "                entities = rec.get(\"entities\", {})\n",
    "                self.records.append({\n",
    "                    \"context\": context,\n",
    "                    \"i\": i, \"j\": j,\n",
    "                    \"yplaus\": yplaus, \"ytemp\": ytemp, \"ymech\": ymech,\n",
    "                    \"domain\": domain, \"regimeid\": regimeid, \"entities\": entities\n",
    "                })\n",
    "        if len(self.records) == 0:\n",
    "            raise RuntimeError(\"Loaded 0 records from TrainingSetCPC - aborting.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.records)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.records[idx]\n",
    "\n",
    "# ---------------------------\n",
    "# Domain-balanced sampler \n",
    "# ---------------------------\n",
    "class DomainBalancedBatchSampler(Sampler):\n",
    "    def __init__(self, dataset: CPCDataset, batch_size: int):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.groups: Dict[str, List[int]] = {}\n",
    "        for i, rec in enumerate(self.dataset.records):\n",
    "            d = rec.get(\"domain\", \"unknown\")\n",
    "            self.groups.setdefault(d, []).append(i)\n",
    "        # deterministic shuffle each group\n",
    "        for d, arr in self.groups.items():\n",
    "            rng = random.Random(RNG_SEED ^ abs(hash(d)))\n",
    "            rng.shuffle(arr)\n",
    "            self.groups[d] = arr\n",
    "        self.domains = sorted(list(self.groups.keys()))\n",
    "        # compute number of batches\n",
    "        self.num_batches = math.ceil(len(dataset) / batch_size)\n",
    "        self.positions = {d: 0 for d in self.domains}\n",
    "\n",
    "    def __iter__(self):\n",
    "        for _ in range(self.num_batches):\n",
    "            per_domain = math.ceil(self.batch_size / max(1, len(self.domains)))\n",
    "            batch = []\n",
    "            for d in self.domains:\n",
    "                arr = self.groups[d]\n",
    "                pos = self.positions[d]\n",
    "                take = per_domain\n",
    "                if len(arr) == 0:\n",
    "                    continue\n",
    "                for t in range(take):\n",
    "                    batch.append(arr[(pos + t) % len(arr)])\n",
    "                self.positions[d] = (pos + take) % len(arr)\n",
    "                if len(batch) >= self.batch_size:\n",
    "                    break\n",
    "            batch = batch[: self.batch_size]\n",
    "            yield batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_batches\n",
    "\n",
    "# ---------------------------\n",
    "# Text builder: how to present context + node pair to encoder\n",
    "# ---------------------------\n",
    "def build_encoder_input(rec: Dict[str,Any]) -> str:\n",
    "    \"\"\"\n",
    "    Build text for encoder from context and node-pair.\n",
    "    Use explicit entity names if available in rec['entities'].\n",
    "    Format:\n",
    "      \"[ENT_A] <name_i> [ENT_B] <name_j> [CONTEXT] <context>\"\n",
    "    Deterministic formatting.\n",
    "    \"\"\"\n",
    "    ctx = (rec.get(\"context\") or \"\").strip()\n",
    "    i = rec.get(\"i\"); j = rec.get(\"j\")\n",
    "    ents = rec.get(\"entities\", {})\n",
    "    name_i = None; name_j = None\n",
    "    # entities may be stored keyed by \"N{idx}\" strings; try both int and string keys\n",
    "    key_i = f\"N{int(i)}\"\n",
    "    key_j = f\"N{int(j)}\"\n",
    "    if key_i in ents:\n",
    "        name_i = ents[key_i].get(\"name\")\n",
    "    if key_j in ents:\n",
    "        name_j = ents[key_j].get(\"name\")\n",
    "    # fallback to placeholder textual ids \n",
    "    if not name_i:\n",
    "        name_i = f\"Entity_{int(i)}\"\n",
    "    if not name_j:\n",
    "        name_j = f\"Entity_{int(j)}\"\n",
    "    out = f\"[ENT_A] {name_i} [ENT_B] {name_j} [CONTEXT] {ctx}\"\n",
    "    return out\n",
    "\n",
    "# ---------------------------\n",
    "# Model: CPCModel (encoder + heads + alignment head + uncertainty params)\n",
    "# ---------------------------\n",
    "class CPCModel(nn.Module):\n",
    "    def __init__(self, encoder_name: str = ENCODER_MODEL_NAME, d_embed: int = D_EMBED):\n",
    "        super().__init__()\n",
    "        self.encoder_name = encoder_name\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(encoder_name, use_fast=True)\n",
    "        self.encoder = AutoModel.from_pretrained(encoder_name)\n",
    "        d_enc = self.encoder.config.hidden_size\n",
    "        # classification heads\n",
    "        self.head_plaus = nn.Linear(d_enc, 1)\n",
    "        self.head_temp = nn.Linear(d_enc, 1)\n",
    "        self.head_mech = nn.Linear(d_enc, 1)\n",
    "        # alignment projection head -> maps d_enc -> d_embed\n",
    "        self.align = nn.Linear(d_enc, d_embed)\n",
    "        # uncertainty parameters: we learn log_sigma for numeric stability (init log_sigma=0 -> sigma=1)\n",
    "        self.log_sigma_plaus = nn.Parameter(torch.zeros(()))\n",
    "        self.log_sigma_temp = nn.Parameter(torch.zeros(()))\n",
    "        self.log_sigma_mech = nn.Parameter(torch.zeros(()))\n",
    "\n",
    "    def encode_texts(self, texts: List[str], max_length: int = ENCODER_MAX_LEN, device: str = DEVICE) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Tokenize and pass through encoder, return pooled vector HCLS (CLS pooling).\n",
    "        Returns tensor shape [N, d_enc] on specified device.\n",
    "        \"\"\"\n",
    "        # batch tokenization\n",
    "        enc = self.tokenizer.batch_encode_plus(texts, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
    "        input_ids = enc[\"input_ids\"].to(device)\n",
    "        attention_mask = enc[\"attention_mask\"].to(device)\n",
    "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        # Use pooled output if available (DeBERTa provides last_hidden_state; use CLS token [0] vector)\n",
    "        last_hidden = outputs.last_hidden_state  # [B, L, H]\n",
    "        cls = last_hidden[:, 0, :]               # [B, H]\n",
    "        return cls\n",
    "\n",
    "    def forward(self, texts: List[str], device: str = DEVICE) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Returns dict:\n",
    "          - hcls: [B, d_enc]\n",
    "          - p_plaus_logits: [B,]\n",
    "          - p_temp_logits: [B,]\n",
    "          - p_mech_logits: [B,]\n",
    "          - e_hat: [B, d_embed]\n",
    "        \"\"\"\n",
    "        hcls = self.encode_texts(texts, device=device)\n",
    "        logits_plaus = self.head_plaus(hcls).squeeze(-1)\n",
    "        logits_temp = self.head_temp(hcls).squeeze(-1)\n",
    "        logits_mech = self.head_mech(hcls).squeeze(-1)\n",
    "        e_hat = self.align(hcls)  # raw vector, not normalized\n",
    "        return {\n",
    "            \"hcls\": hcls,\n",
    "            \"logits_plaus\": logits_plaus,\n",
    "            \"logits_temp\": logits_temp,\n",
    "            \"logits_mech\": logits_mech,\n",
    "            \"e_hat\": e_hat\n",
    "        }\n",
    "\n",
    "# ---------------------------\n",
    "# Deterministic f_embed helper (loads SentenceTransformer backbone + projection)\n",
    "# ---------------------------\n",
    "class FEmbedWrapper:\n",
    "    \"\"\"\n",
    "    Wraps the trained f_embed-sota for computing e_embed for the same context.\n",
    "    This assumes models/fembed_sota/checkpoint_best.pth exists and config.json specifies the backbone name.\n",
    "    The code uses SentenceTransformer + projection head same as training script.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_dir: Path):\n",
    "        cfgp = model_dir / \"config.json\"\n",
    "        if not cfgp.exists():\n",
    "            raise FileNotFoundError(f\"Embedder config missing at {cfgp}\")\n",
    "        cfg = json.loads(cfgp.read_text(encoding=\"utf8\"))\n",
    "        backbone = cfg.get(\"backbone\", \"all-MiniLM-L6-v2\")\n",
    "        d_embed = int(cfg.get(\"d_embed\", D_EMBED))\n",
    "        # load backbone\n",
    "        self.backbone = SentenceTransformer(backbone)\n",
    "        # build projection head with d_backbone -> d_embed (we must create params and load checkpoint)\n",
    "        d_backbone = self.backbone.get_sentence_embedding_dimension()\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Linear(d_backbone, d_backbone),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(d_backbone, d_embed)\n",
    "        )\n",
    "        # load checkpoint\n",
    "        ckpt = model_dir / \"checkpoint_best.pth\"\n",
    "        if not ckpt.exists():\n",
    "            raise FileNotFoundError(f\"Embedder checkpoint not found at {ckpt}\")\n",
    "        state = torch.load(ckpt, map_location=\"cpu\")\n",
    "        try:\n",
    "            proj_state = {k.replace(\"proj.\", \"\"): v for k, v in state.items() if k.startswith(\"proj.\")}\n",
    "            if proj_state:\n",
    "                self.proj.load_state_dict(proj_state, strict=False)\n",
    "            else:\n",
    "                self.proj.load_state_dict(state, strict=False)\n",
    "        except Exception:\n",
    "            write_log(\"Warning: could not fully load projection weights for f_embed. Proceeding with init projection.\")\n",
    "        self.backbone.max_seq_length = 256\n",
    "        self.proj.eval()\n",
    "        self.backbone.eval()\n",
    "\n",
    "    def encode(self, texts: List[str], batch_size: int = 64, device: str = DEVICE) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Returns numpy array [N, d_embed], L2-normalized.\n",
    "        \"\"\"\n",
    "        all_embs = []\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i+batch_size]\n",
    "            emb = self.backbone.encode(batch, convert_to_tensor=True, show_progress_bar=False)\n",
    "            with torch.no_grad():\n",
    "                z = self.proj(emb.to(torch.device(\"cpu\")))\n",
    "                z = F.normalize(z, p=2, dim=1)\n",
    "                all_embs.append(z.cpu().numpy())\n",
    "        if not all_embs:\n",
    "            return np.zeros((0, D_EMBED), dtype=np.float32)\n",
    "        out = np.vstack(all_embs)\n",
    "        return out\n",
    "\n",
    "# ---------------------------\n",
    "# Loss functions (focal + smoothing + multi-task weighting)\n",
    "# ---------------------------\n",
    "def smooth_label(y: torch.Tensor, eps: float = LABEL_SMOOTH_EPS) -> torch.Tensor:\n",
    "    # y in {0,1}\n",
    "    return y * (1.0 - eps) + eps * 0.5\n",
    "\n",
    "def focal_loss_from_logits(logits: torch.Tensor, targets: torch.Tensor, alpha: float = FOCAL_ALPHA, gamma: float = FOCAL_GAMMA) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    logits: [B,], targets: [B,] in {0,1} floats (smoothed)\n",
    "    returns scalar tensor (mean over batch)\n",
    "    \"\"\"\n",
    "    probs = torch.sigmoid(logits)\n",
    "    pt = probs * targets + (1 - probs) * (1 - targets)  # pt = p if y=1 else 1-p\n",
    "    alpha_t = alpha * targets + (1 - alpha) * (1 - targets)\n",
    "    # focal term\n",
    "    loss = -alpha_t * ((1 - pt) ** gamma) * (targets * torch.log(probs + 1e-12) + (1 - targets) * torch.log(1 - probs + 1e-12))\n",
    "    return loss.mean()\n",
    "\n",
    "def multi_task_loss_with_uncertainty(loss_plaus: torch.Tensor, loss_temp: torch.Tensor, loss_mech: torch.Tensor,\n",
    "                                    log_sigma_plaus: torch.Tensor, log_sigma_temp: torch.Tensor, log_sigma_mech: torch.Tensor) -> torch.Tensor:\n",
    "    # sigma^2 = exp(log_sigma)\n",
    "    s_pl = torch.exp(log_sigma_plaus)\n",
    "    s_tm = torch.exp(log_sigma_temp)\n",
    "    s_mh = torch.exp(log_sigma_mech)\n",
    "    term_pl = 0.5 / s_pl * loss_plaus + 0.5 * torch.log(s_pl)\n",
    "    term_tm = 0.5 / s_tm * loss_temp + 0.5 * torch.log(s_tm)\n",
    "    term_mh = 0.5 / s_mh * loss_mech + 0.5 * torch.log(s_mh)\n",
    "    return term_pl + term_tm + term_mh\n",
    "\n",
    "# ---------------------------\n",
    "# Training & evaluation loops\n",
    "# ---------------------------\n",
    "def collate_batch(dataset: CPCDataset, indices: List[int]) -> Dict[str, Any]:\n",
    "    texts = []\n",
    "    y_plaus = []\n",
    "    y_temp = []\n",
    "    y_mech = []\n",
    "    domains = []\n",
    "    regimes = []\n",
    "    for idx in indices:\n",
    "        rec = dataset.records[idx]\n",
    "        texts.append(build_encoder_input(rec))\n",
    "        y_plaus.append(float(rec[\"yplaus\"]))\n",
    "        y_temp.append(float(rec[\"ytemp\"]))\n",
    "        y_mech.append(float(rec[\"ymech\"]))\n",
    "        domains.append(rec.get(\"domain\", \"unknown\"))\n",
    "        regimes.append(rec.get(\"regimeid\", \"unknown\"))\n",
    "    return {\n",
    "        \"texts\": texts,\n",
    "        \"y_plaus\": torch.tensor(y_plaus, dtype=torch.float32, device=DEVICE),\n",
    "        \"y_temp\": torch.tensor(y_temp, dtype=torch.float32, device=DEVICE),\n",
    "        \"y_mech\": torch.tensor(y_mech, dtype=torch.float32, device=DEVICE),\n",
    "        \"domains\": domains,\n",
    "        \"regimes\": regimes\n",
    "    }\n",
    "\n",
    "def evaluate_model_on_loader(model: CPCModel, embedder: FEmbedWrapper, loader, dataset: CPCDataset) -> Dict[str, float]:\n",
    "    model.eval()\n",
    "    all_targets = {\"plaus\": [], \"temp\": [], \"mech\": []}\n",
    "    all_preds = {\"plaus\": [], \"temp\": [], \"mech\": []}\n",
    "    with torch.no_grad():\n",
    "        for batch_indices in loader:\n",
    "            batch = collate_batch(dataset, batch_indices)\n",
    "            texts = batch[\"texts\"]\n",
    "            out = model.forward(texts, device=DEVICE)\n",
    "            logits_p = out[\"logits_plaus\"].detach().cpu().numpy()\n",
    "            logits_t = out[\"logits_temp\"].detach().cpu().numpy()\n",
    "            logits_m = out[\"logits_mech\"].detach().cpu().numpy()\n",
    "            probs_p = 1.0 / (1.0 + np.exp(-logits_p))\n",
    "            probs_t = 1.0 / (1.0 + np.exp(-logits_t))\n",
    "            probs_m = 1.0 / (1.0 + np.exp(-logits_m))\n",
    "            all_preds[\"plaus\"].extend(probs_p.tolist())\n",
    "            all_preds[\"temp\"].extend(probs_t.tolist())\n",
    "            all_preds[\"mech\"].extend(probs_m.tolist())\n",
    "            all_targets[\"plaus\"].extend(batch[\"y_plaus\"].detach().cpu().numpy().tolist())\n",
    "            all_targets[\"temp\"].extend(batch[\"y_temp\"].detach().cpu().numpy().tolist())\n",
    "            all_targets[\"mech\"].extend(batch[\"y_mech\"].detach().cpu().numpy().tolist())\n",
    "    # compute AUCs (use roc_auc_score, handle single-class cases)\n",
    "    res = {}\n",
    "    for name in [\"plaus\", \"temp\", \"mech\"]:\n",
    "        try:\n",
    "            res[f\"auc_{name}\"] = float(roc_auc_score(all_targets[name], all_preds[name]))\n",
    "        except Exception:\n",
    "            res[f\"auc_{name}\"] = float(\"nan\")\n",
    "    return res\n",
    "\n",
    "def train():\n",
    "    write_log(\"Starting CPC training run\")\n",
    "    # 1) Load dataset\n",
    "    dataset = CPCDataset(TRAINING_SET_PATH)\n",
    "    n = len(dataset)\n",
    "    n_val = max(1, int(n * VAL_SPLIT))\n",
    "    indices = list(range(n))\n",
    "    rng = random.Random(RNG_SEED)\n",
    "    rng.shuffle(indices)\n",
    "    val_idx = set(indices[:n_val])\n",
    "    train_idx = set(indices[n_val:])\n",
    "    # Prepare samplers & loaders (domain-balanced for train)\n",
    "    train_sampler = DomainBalancedBatchSampler(dataset, BATCH_SIZE)\n",
    "    # We'll pass batches as lists of indices\n",
    "    train_loader = list(iter(train_sampler))\n",
    "    # validation loader as deterministic fixed chunks\n",
    "    val_batches = []\n",
    "    val_list = sorted(list(val_idx))\n",
    "    for i in range(0, len(val_list), BATCH_SIZE):\n",
    "        val_batches.append(val_list[i:i+BATCH_SIZE])\n",
    "\n",
    "    # 2) instantiate models\n",
    "    model = CPCModel(encoder_name=ENCODER_MODEL_NAME, d_embed=D_EMBED).to(DEVICE)\n",
    "    # load f_embed wrapper (frozen)\n",
    "    embedder = FEmbedWrapper(FEMBED_MODEL_DIR)\n",
    "\n",
    "    # 3) optimizer: update encoder + heads + align + log_sigma\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.AdamW(params, lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "    best_val_auc = -1.0\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    hp = HyperParams()\n",
    "    with open(MODEL_DIR / \"config.json\", \"w\", encoding=\"utf8\") as fh:\n",
    "        json.dump(asdict(hp), fh, indent=2)\n",
    "\n",
    "    # training epochs (if USE_CURRICULUM True, restrict train batches to specific regimeids)\n",
    "    for epoch in range(1, NUM_EPOCHS + 1):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        step = 0\n",
    "        write_log(f\"Epoch {epoch} start\")\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch}\", unit=\"batch\")\n",
    "        for batch_indices in pbar:\n",
    "            # If curriculum active, filter batch_indices to only examples with allowed regimes for this epoch stage \n",
    "            batch = collate_batch(dataset, batch_indices)\n",
    "            texts = batch[\"texts\"]\n",
    "            # forward CPC\n",
    "            out = model.forward(texts, device=DEVICE)\n",
    "            logits_p = out[\"logits_plaus\"]\n",
    "            logits_t = out[\"logits_temp\"]\n",
    "            logits_m = out[\"logits_mech\"]\n",
    "            e_hat = out[\"e_hat\"]  # [B, d_embed]\n",
    "            # smooth labels\n",
    "            y_p = smooth_label(batch[\"y_plaus\"])\n",
    "            y_t = smooth_label(batch[\"y_temp\"])\n",
    "            y_m = smooth_label(batch[\"y_mech\"])\n",
    "            # focal losses\n",
    "            loss_p = focal_loss_from_logits(logits_p, y_p, alpha=FOCAL_ALPHA, gamma=FOCAL_GAMMA)\n",
    "            loss_t = focal_loss_from_logits(logits_t, y_t, alpha=FOCAL_ALPHA, gamma=FOCAL_GAMMA)\n",
    "            loss_m = focal_loss_from_logits(logits_m, y_m, alpha=FOCAL_ALPHA, gamma=FOCAL_GAMMA)\n",
    "            # multi-task uncertainty weighting\n",
    "            loss_multi = multi_task_loss_with_uncertainty(loss_p, loss_t, loss_m, model.log_sigma_plaus, model.log_sigma_temp, model.log_sigma_mech)\n",
    "            # alignment: compute e_embed for batch contexts\n",
    "            texts_for_embed = [t for t in texts]  # deterministic order\n",
    "            e_emb_np = embedder.encode(texts_for_embed, batch_size=min(64, max(1, len(texts_for_embed))))\n",
    "            e_emb_t = torch.from_numpy(e_emb_np).to(DEVICE).float()  # [B, d_embed]\n",
    "            # alignment L2\n",
    "            align_loss = F.mse_loss(e_hat, e_emb_t, reduction=\"mean\")\n",
    "            total_loss = loss_multi + LAMBDA_ALIGN * align_loss\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += float(total_loss.item())\n",
    "            step += 1\n",
    "            pbar.set_postfix({\"loss\": f\"{epoch_loss/step:.6f}\"})\n",
    "            write_log(f\"epoch={epoch} step={step} loss={float(total_loss.item()):.6f} loss_multi={float(loss_multi.item()):.6f} align={float(align_loss.item()):.6f}\")\n",
    "\n",
    "        avg_epoch_loss = epoch_loss / max(1, step)\n",
    "        write_log(f\"[EPOCH {epoch}] train_loss={avg_epoch_loss:.6f}\")\n",
    "\n",
    "        # Validation\n",
    "        write_log(\"Running validation...\")\n",
    "        model.eval()\n",
    "        all_targets_p = []\n",
    "        all_preds_p = []\n",
    "        for vb in tqdm(val_batches, desc=\"Valid\"):\n",
    "            batch = collate_batch(dataset, vb)\n",
    "            texts = batch[\"texts\"]\n",
    "            with torch.no_grad():\n",
    "                out = model.forward(texts, device=DEVICE)\n",
    "                probs_p = torch.sigmoid(out[\"logits_plaus\"]).detach().cpu().numpy().tolist()\n",
    "            all_preds_p.extend(probs_p)\n",
    "            all_targets_p.extend(batch[\"y_plaus\"].detach().cpu().numpy().tolist())\n",
    "        # compute plausibility AUC\n",
    "        try:\n",
    "            val_auc = float(roc_auc_score(all_targets_p, all_preds_p))\n",
    "        except Exception:\n",
    "            val_auc = float(\"nan\")\n",
    "        write_log(f\"[EPOCH {epoch}] val_auc_plaus={val_auc:.6f}\")\n",
    "\n",
    "        # save checkpoints\n",
    "        torch.save(model.state_dict(), MODEL_DIR / \"checkpoint_last.pth\")\n",
    "        if not math.isnan(val_auc) and val_auc > best_val_auc:\n",
    "            best_val_auc = val_auc\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(), MODEL_DIR / \"checkpoint_best.pth\")\n",
    "            write_log(f\"[EPOCH {epoch}] new best plaus AUC={best_val_auc:.6f} -> saved checkpoint_best.pth\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            write_log(f\"[EPOCH {epoch}] no improvement ({epochs_no_improve}/{PATIENCE})\")\n",
    "            if epochs_no_improve >= PATIENCE:\n",
    "                write_log(f\"Early stopping triggered at epoch {epoch}\")\n",
    "                break\n",
    "\n",
    "    # final save metadata\n",
    "    meta = {\n",
    "        \"best_val_auc_plaus\": best_val_auc,\n",
    "        \"epochs_run\": epoch,\n",
    "        \"model_dir\": str(MODEL_DIR.resolve())\n",
    "    }\n",
    "    with open(MODEL_DIR / \"train_info.json\", \"w\", encoding=\"utf8\") as fh:\n",
    "        json.dump(meta, fh, indent=2)\n",
    "    write_log(\"Training complete.\")\n",
    "    write_log(f\"Best val plaus AUC: {best_val_auc}\")\n",
    "    return\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaa021d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from __future__ import annotations\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss\n",
    "from tqdm import tqdm\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "# ---------------------------\n",
    "# Config \n",
    "# ---------------------------\n",
    "RNG_SEED = 20251127\n",
    "random.seed(RNG_SEED)\n",
    "np.random.seed(RNG_SEED)\n",
    "torch.manual_seed(RNG_SEED)\n",
    "\n",
    "TRAINING_SET_PATH = Path(\"out/dsynth/TrainingSetCPC.jsonl\")\n",
    "CPC_MODEL_DIR = Path(\"models/cpc_model\")\n",
    "CPC_CHECKPOINT = CPC_MODEL_DIR / \"checkpoint_best.pth\"\n",
    "FEMBED_MODEL_DIR = Path(\"models/fembed_sota\")\n",
    "FEMBED_CHECKPOINT = FEMBED_MODEL_DIR / \"checkpoint_best.pth\"\n",
    "FEMBED_CONFIG = FEMBED_MODEL_DIR / \"config.json\"\n",
    "\n",
    "LOG_OUT = Path(\"logs/cpc_eval.json\")\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_ENC = 64\n",
    "ECE_BINS = 10\n",
    "\n",
    "# ---------------------------\n",
    "# Basic checks\n",
    "# ---------------------------\n",
    "def fatal(msg: str):\n",
    "    raise FileNotFoundError(msg)\n",
    "\n",
    "if not TRAINING_SET_PATH.exists():\n",
    "    fatal(f\"Missing TrainingSetCPC: {TRAINING_SET_PATH}\")\n",
    "if not CPC_CHECKPOINT.exists():\n",
    "    fatal(f\"Missing CPC checkpoint: {CPC_CHECKPOINT}\")\n",
    "if not FEMBED_MODEL_DIR.exists() or not FEMBED_CONFIG.exists() or not FEMBED_CHECKPOINT.exists():\n",
    "    fatal(f\"Missing f_embed artifacts in {FEMBED_MODEL_DIR}. Required: config.json and checkpoint_best.pth\")\n",
    "\n",
    "# ---------------------------\n",
    "# Dataset loader (same normalization as train)\n",
    "# ---------------------------\n",
    "def load_cpc_records(path: Path) -> List[Dict[str,Any]]:\n",
    "    recs = []\n",
    "    with path.open(\"r\", encoding=\"utf8\") as fh:\n",
    "        for line in fh:\n",
    "            rec = json.loads(line)\n",
    "            context = rec.get(\"context\") or rec.get(\"pos_snippet\") or rec.get(\"text\") or \"\"\n",
    "            if \"pair\" in rec and isinstance(rec[\"pair\"], (list, tuple)) and len(rec[\"pair\"])>=2:\n",
    "                i, j = int(rec[\"pair\"][0]), int(rec[\"pair\"][1])\n",
    "            else:\n",
    "                i = int(rec.get(\"i\") or rec.get(\"node_i\") or (rec.get(\"node_pair\") or [None,None])[0] or -1)\n",
    "                j = int(rec.get(\"j\") or rec.get(\"node_j\") or (rec.get(\"node_pair\") or [None,None])[1] or -1)\n",
    "            yplaus = int(rec.get(\"yplaus\", rec.get(\"plaus\", rec.get(\"label_plaus\", 0))))\n",
    "            ytemp = int(rec.get(\"ytemp\", rec.get(\"temp\", 0)))\n",
    "            ymech = int(rec.get(\"ymech\", rec.get(\"mech\", 0)))\n",
    "            domain = rec.get(\"domain\") or rec.get(\"graph_id\") or \"unknown\"\n",
    "            regimeid = rec.get(\"regimeid\") or rec.get(\"regime\") or \"unknown\"\n",
    "            entities = rec.get(\"entities\", {})\n",
    "            recs.append({\n",
    "                \"context\": context,\n",
    "                \"i\": i, \"j\": j,\n",
    "                \"yplaus\": yplaus, \"ytemp\": ytemp, \"ymech\": ymech,\n",
    "                \"domain\": domain, \"regimeid\": regimeid, \"entities\": entities,\n",
    "                \"raw\": rec\n",
    "            })\n",
    "    if not recs:\n",
    "        fatal(f\"No records loaded from {path}\")\n",
    "    return recs\n",
    "\n",
    "# ---------------------------\n",
    "# Helper: build encoder input identical to training format\n",
    "# ---------------------------\n",
    "def build_encoder_input(rec: Dict[str,Any]) -> str:\n",
    "    ctx = (rec.get(\"context\") or \"\").strip()\n",
    "    i = rec.get(\"i\"); j = rec.get(\"j\")\n",
    "    ents = rec.get(\"entities\", {})\n",
    "    key_i = f\"N{int(i)}\"\n",
    "    key_j = f\"N{int(j)}\"\n",
    "    name_i = ents.get(key_i, {}).get(\"name\") if isinstance(ents, dict) else None\n",
    "    name_j = ents.get(key_j, {}).get(\"name\") if isinstance(ents, dict) else None\n",
    "    if not name_i:\n",
    "        name_i = f\"Entity_{int(i)}\"\n",
    "    if not name_j:\n",
    "        name_j = f\"Entity_{int(j)}\"\n",
    "    return f\"[ENT_A] {name_i} [ENT_B] {name_j} [CONTEXT] {ctx}\"\n",
    "\n",
    "# ---------------------------\n",
    "# CPC model class \n",
    "# ---------------------------\n",
    "class CPCModelEval(torch.nn.Module):\n",
    "    def __init__(self, encoder_name: str = \"microsoft/deberta-v3-small\", d_embed: int = 256):\n",
    "        super().__init__()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(encoder_name, use_fast=True)\n",
    "        self.encoder = AutoModel.from_pretrained(encoder_name)\n",
    "        d_enc = self.encoder.config.hidden_size\n",
    "        self.head_plaus = torch.nn.Linear(d_enc, 1)\n",
    "        self.head_temp = torch.nn.Linear(d_enc, 1)\n",
    "        self.head_mech = torch.nn.Linear(d_enc, 1)\n",
    "        self.align = torch.nn.Linear(d_enc, d_embed)\n",
    "\n",
    "    def encode_texts(self, texts: List[str], max_length: int = 256) -> torch.Tensor:\n",
    "        enc = self.tokenizer.batch_encode_plus(texts, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
    "        input_ids = enc[\"input_ids\"].to(DEVICE)\n",
    "        attention_mask = enc[\"attention_mask\"].to(DEVICE)\n",
    "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        last_hidden = outputs.last_hidden_state\n",
    "        cls = last_hidden[:, 0, :]\n",
    "        return cls\n",
    "\n",
    "    def forward(self, texts: List[str]) -> Dict[str, torch.Tensor]:\n",
    "        hcls = self.encode_texts(texts)\n",
    "        logits_plaus = self.head_plaus(hcls).squeeze(-1)\n",
    "        logits_temp = self.head_temp(hcls).squeeze(-1)\n",
    "        logits_mech = self.head_mech(hcls).squeeze(-1)\n",
    "        e_hat = self.align(hcls)\n",
    "        return {\"hcls\": hcls, \"logits_plaus\": logits_plaus, \"logits_temp\": logits_temp, \"logits_mech\": logits_mech, \"e_hat\": e_hat}\n",
    "\n",
    "# ---------------------------\n",
    "# f_embed wrapper (loads backbone+proj) \n",
    "# ---------------------------\n",
    "class FEmbedEval:\n",
    "    def __init__(self, model_dir: Path):\n",
    "        cfgp = model_dir / \"config.json\"\n",
    "        if not cfgp.exists():\n",
    "            fatal(f\"Missing embedder config: {cfgp}\")\n",
    "        cfg = json.loads(cfgp.read_text(encoding=\"utf8\"))\n",
    "        backbone = cfg.get(\"backbone\", \"all-MiniLM-L6-v2\")\n",
    "        d_embed = int(cfg.get(\"d_embed\", 256))\n",
    "        self.backbone = SentenceTransformer(backbone)\n",
    "        d_backbone = self.backbone.get_sentence_embedding_dimension()\n",
    "        # build projection head (same architecture)\n",
    "        self.proj = torch.nn.Sequential(\n",
    "            torch.nn.Linear(d_backbone, d_backbone),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Linear(d_backbone, d_embed)\n",
    "        )\n",
    "        ckpt = model_dir / \"checkpoint_best.pth\"\n",
    "        if not ckpt.exists():\n",
    "            fatal(f\"Embedder checkpoint missing: {ckpt}\")\n",
    "        state = torch.load(ckpt, map_location=\"cpu\")\n",
    "        try:\n",
    "            proj_state = {k.replace(\"proj.\", \"\"): v for k, v in state.items() if k.startswith(\"proj.\")}\n",
    "            if proj_state:\n",
    "                self.proj.load_state_dict(proj_state, strict=False)\n",
    "            else:\n",
    "                self.proj.load_state_dict(state, strict=False)\n",
    "        except Exception:\n",
    "            print(\"Warning: could not fully load embedder projection weights; proceeding with init proj.\")\n",
    "        self.backbone.max_seq_length = 256\n",
    "        self.backbone.eval()\n",
    "        self.proj.eval()\n",
    "\n",
    "    def encode(self, texts: List[str], batch_size: int = 64) -> np.ndarray:\n",
    "        all_embs = []\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i+batch_size]\n",
    "            emb = self.backbone.encode(batch, convert_to_tensor=True, show_progress_bar=False)\n",
    "            with torch.no_grad():\n",
    "                z = self.proj(emb.to(torch.device(\"cpu\")))\n",
    "                z = F.normalize(z, p=2, dim=1)\n",
    "                all_embs.append(z.cpu().numpy())\n",
    "        if not all_embs:\n",
    "            return np.zeros((0, 256), dtype=np.float32)\n",
    "        return np.vstack(all_embs)\n",
    "\n",
    "# ---------------------------\n",
    "# Calibration helpers\n",
    "# ---------------------------\n",
    "def compute_ece(probs: List[float], labels: List[int], n_bins: int = ECE_BINS) -> float:\n",
    "    \"\"\"\n",
    "    Expected Calibration Error (ECE) - histogram binning\n",
    "    probs: list of predicted probabilities in [0,1]\n",
    "    labels: list of 0/1 labels\n",
    "    \"\"\"\n",
    "    probs = np.array(probs)\n",
    "    labels = np.array(labels)\n",
    "    bins = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "    ece = 0.0\n",
    "    for i in range(n_bins):\n",
    "        lo = bins[i]; hi = bins[i+1]\n",
    "        mask = (probs >= lo) & (probs < hi) if i < n_bins-1 else (probs >= lo) & (probs <= hi)\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        avg_conf = probs[mask].mean()\n",
    "        avg_acc = labels[mask].mean()\n",
    "        ece += (mask.sum() / len(probs)) * abs(avg_conf - avg_acc)\n",
    "    return float(ece)\n",
    "\n",
    "# ---------------------------\n",
    "# Main evaluation flow\n",
    "# ---------------------------\n",
    "def evaluate():\n",
    "    records = load_cpc_records(TRAINING_SET_PATH)\n",
    "    n = len(records)\n",
    "    n_val = max(1, int(n * 0.05))\n",
    "    idxs = list(range(n))\n",
    "    rng = random.Random(RNG_SEED)\n",
    "    rng.shuffle(idxs)\n",
    "    val_indices = set(idxs[:n_val])\n",
    "    val_records = [records[i] for i in sorted(val_indices)]\n",
    "    print(f\"Total records: {n}  Validation: {len(val_records)}\")\n",
    "\n",
    "    # load models\n",
    "    print(\"Loading CPC model (checkpoint)...\")\n",
    "    cpc = CPCModelEval(encoder_name=\"microsoft/deberta-v3-small\", d_embed=256).to(DEVICE)\n",
    "    state = torch.load(CPC_CHECKPOINT, map_location=DEVICE)\n",
    "    try:\n",
    "        cpc.load_state_dict(state)\n",
    "    except Exception:\n",
    "        # try non-strict load\n",
    "        cpc.load_state_dict(state, strict=False)\n",
    "    cpc.eval()\n",
    "\n",
    "    print(\"Loading f_embed...\")\n",
    "    fembed = FEmbedEval(FEMBED_MODEL_DIR)\n",
    "\n",
    "    # prepare evaluation lists\n",
    "    probs_plaus = []\n",
    "    labels_plaus = []\n",
    "    probs_temp = []\n",
    "    labels_temp = []\n",
    "    probs_mech = []\n",
    "    labels_mech = []\n",
    "    align_l2 = []\n",
    "    align_cos = []\n",
    "\n",
    "    # We'll batch-encode val records for speed\n",
    "    texts = [build_encoder_input(rec) for rec in val_records]\n",
    "    # process in batches\n",
    "    for i in tqdm(range(0, len(texts), BATCH_ENC), desc=\"Eval batches\"):\n",
    "        batch_texts = texts[i:i+BATCH_ENC]\n",
    "        # CPC forward\n",
    "        with torch.no_grad():\n",
    "            out = cpc.forward(batch_texts)\n",
    "            logits_p = out[\"logits_plaus\"].detach().cpu().numpy()\n",
    "            logits_t = out[\"logits_temp\"].detach().cpu().numpy()\n",
    "            logits_m = out[\"logits_mech\"].detach().cpu().numpy()\n",
    "            e_hat = out[\"e_hat\"].detach().cpu().numpy()  # shape [B, d]\n",
    "        probs_p = 1.0 / (1.0 + np.exp(-logits_p))\n",
    "        probs_t = 1.0 / (1.0 + np.exp(-logits_t))\n",
    "        probs_m = 1.0 / (1.0 + np.exp(-logits_m))\n",
    "        # f_embed encodes same batch_texts into e_embed\n",
    "        e_embed = fembed.encode(batch_texts, batch_size=min(BATCH_ENC, len(batch_texts)))  # [B, d]\n",
    "        # ensure shapes match\n",
    "        Bbatch = len(batch_texts)\n",
    "        for k in range(Bbatch):\n",
    "            rec = val_records[i + k]\n",
    "            probs_plaus.append(float(probs_p[k]))\n",
    "            labels_plaus.append(int(rec[\"yplaus\"]))\n",
    "            probs_temp.append(float(probs_t[k]))\n",
    "            labels_temp.append(int(rec[\"ytemp\"]))\n",
    "            probs_mech.append(float(probs_m[k]))\n",
    "            labels_mech.append(int(rec[\"ymech\"]))\n",
    "            # alignment metrics\n",
    "            eh = e_hat[k]\n",
    "            ee = e_embed[k]\n",
    "            l2 = float(np.linalg.norm(eh - ee, ord=2))\n",
    "            # cosine: ensure nonzero\n",
    "            denom = (np.linalg.norm(eh) * np.linalg.norm(ee) + 1e-12)\n",
    "            cos = float(np.dot(eh, ee) / denom)\n",
    "            align_l2.append(l2)\n",
    "            align_cos.append(cos)\n",
    "\n",
    "    # compute per-task AUCs\n",
    "    def safe_auc(labels, probs):\n",
    "        try:\n",
    "            return float(roc_auc_score(labels, probs))\n",
    "        except Exception:\n",
    "            return float(\"nan\")\n",
    "\n",
    "    auc_plaus = safe_auc(labels_plaus, probs_plaus)\n",
    "    auc_temp = safe_auc(labels_temp, probs_temp)\n",
    "    auc_mech = safe_auc(labels_mech, probs_mech)\n",
    "\n",
    "    # calibration: ECE + Brier\n",
    "    ece_plaus = compute_ece(probs_plaus, labels_plaus, n_bins=ECE_BINS)\n",
    "    ece_temp  = compute_ece(probs_temp, labels_temp, n_bins=ECE_BINS)\n",
    "    ece_mech  = compute_ece(probs_mech, labels_mech, n_bins=ECE_BINS)\n",
    "\n",
    "    brier_plaus = float(brier_score_loss(labels_plaus, probs_plaus))\n",
    "    brier_temp  = float(brier_score_loss(labels_temp, probs_temp))\n",
    "    brier_mech  = float(brier_score_loss(labels_mech, probs_mech))\n",
    "\n",
    "    # alignment aggregates\n",
    "    align_stats = {\n",
    "        \"l2_mean\": float(np.mean(align_l2)),\n",
    "        \"l2_median\": float(np.median(align_l2)),\n",
    "        \"l2_std\": float(np.std(align_l2)),\n",
    "        \"cos_mean\": float(np.mean(align_cos)),\n",
    "        \"cos_median\": float(np.median(align_cos)),\n",
    "        \"cos_std\": float(np.std(align_cos))\n",
    "    }\n",
    "\n",
    "    # create small sample of examples with predictions and neighbor alignment\n",
    "    samples = []\n",
    "    for idx in range(min(10, len(val_records))):\n",
    "        rec = val_records[idx]\n",
    "        txt = build_encoder_input(rec)\n",
    "        with torch.no_grad():\n",
    "            out = cpc.forward([txt])\n",
    "            prob_p = float(torch.sigmoid(out[\"logits_plaus\"]).cpu().numpy()[0])\n",
    "            eh = out[\"e_hat\"].detach().cpu().numpy()[0]\n",
    "            ee = fembed.encode([txt], batch_size=1)[0]\n",
    "            l2 = float(np.linalg.norm(eh - ee))\n",
    "            cos = float(np.dot(eh, ee) / (np.linalg.norm(eh) * np.linalg.norm(ee) + 1e-12))\n",
    "        samples.append({\n",
    "            \"query\": txt,\n",
    "            \"p_plaus\": prob_p,\n",
    "            \"label_plaus\": int(rec[\"yplaus\"]),\n",
    "            \"align_l2\": l2,\n",
    "            \"align_cos\": cos\n",
    "        })\n",
    "\n",
    "    results = {\n",
    "        \"n_val\": len(val_records),\n",
    "        \"auc\": {\"plaus\": auc_plaus, \"temp\": auc_temp, \"mech\": auc_mech},\n",
    "        \"calibration\": {\n",
    "            \"ece\": {\"plaus\": ece_plaus, \"temp\": ece_temp, \"mech\": ece_mech},\n",
    "            \"brier\": {\"plaus\": brier_plaus, \"temp\": brier_temp, \"mech\": brier_mech}\n",
    "        },\n",
    "        \"alignment\": align_stats,\n",
    "        \"samples\": samples,\n",
    "        \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "    }\n",
    "\n",
    "    # save to JSON\n",
    "    LOG_OUT.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with LOG_OUT.open(\"w\", encoding=\"utf8\") as fh:\n",
    "        json.dump(results, fh, indent=2)\n",
    "\n",
    "    # print summary\n",
    "    print(\"\\nCPC Evaluation summary:\")\n",
    "    print(f\"  n_val = {len(val_records)}\")\n",
    "    print(f\"  AUC - plaus: {auc_plaus:.4f}, temp: {auc_temp:.4f}, mech: {auc_mech:.4f}\")\n",
    "    print(f\"  ECE - plaus: {ece_plaus:.4f}, temp: {ece_temp:.4f}, mech: {ece_mech:.4f}\")\n",
    "    print(f\"  Brier - plaus: {brier_plaus:.4f}, temp: {brier_temp:.4f}, mech: {brier_mech:.4f}\")\n",
    "    print(f\"  Align L2 mean: {align_stats['l2_mean']:.4f}, median: {align_stats['l2_median']:.4f}\")\n",
    "    print(f\"  Align cos mean: {align_stats['cos_mean']:.4f}, median: {align_stats['cos_median']:.4f}\")\n",
    "    print(f\"\\nDetailed JSON saved to: {LOG_OUT.resolve()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58aeaa7a",
   "metadata": {},
   "source": [
    "### iii. Train $f_{fusion}$ (fusion model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70dc8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ML libraries\n",
    "import lightgbm as lgb\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import joblib\n",
    "import shap\n",
    "\n",
    "# ---------------------------\n",
    "# configuration\n",
    "# ---------------------------\n",
    "RNG_SEED = 20251127\n",
    "random.seed(RNG_SEED)\n",
    "np.random.seed(RNG_SEED)\n",
    "\n",
    "DCORPUS_DIR = Path(\"d_corpus_output\")               # directory containing D_corpus JSONL files (domain & mixed)\n",
    "G_TRUE_PATH = Path(\"graphs/G_true.gpickle\")         # NetworkX saved ground-truth graph (DiGraph)\n",
    "FEMBED_DIR = Path(\"models/fembed_sota\")             # embedder artifacts (config.json + checkpoint_best.pth)\n",
    "\n",
    "# Output paths\n",
    "OUT_DIR = Path(\"out/fusion\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TRAINING_CSV = OUT_DIR / \"TrainingSetFusion.csv\"\n",
    "MODEL_DIR = OUT_DIR / \"model_bundle\"\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LOG_FILE = Path(\"logs/fusion_train.log\")\n",
    "LOG_FILE.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Feature / model hyperparameters\n",
    "MAX_PATH_CUTOFF = 4\n",
    "MAX_DISJOINT_PATHS = 4   # cap expensive computation\n",
    "HARD_NEGATIVES_PER_POS = 1\n",
    "TEST_SIZE = 0.10\n",
    "CALIBRATION_SIZE = 0.10    # portion of train reserved for isotonic calibrator\n",
    "LAMBDA_RANK_WEIGHT = 0.3   # weight of ranker when combining final raw scores\n",
    "CLASSIFIER_WEIGHT = 0.7    # weight of classifier raw scores\n",
    "LIGHTGBM_PARAMS = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 128,\n",
    "    \"max_depth\": 8,\n",
    "    \"min_data_in_leaf\": 50,\n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 1,\n",
    "    \"seed\": RNG_SEED,\n",
    "    \"verbose\": -1,\n",
    "    # monotone_constraints to be injected dynamically\n",
    "}\n",
    "\n",
    "RANKER_PARAMS = {\n",
    "    \"objective\": \"lambdarank\",\n",
    "    \"metric\": \"ndcg\",\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 64,\n",
    "    \"max_depth\": 8,\n",
    "    \"min_data_in_leaf\": 20,\n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"seed\": RNG_SEED,\n",
    "    \"verbose\": -1,\n",
    "    \"ndcg_eval_at\": [5],\n",
    "}\n",
    "\n",
    "# ---------------------------\n",
    "# Logging\n",
    "# ---------------------------\n",
    "def write_log(msg: str):\n",
    "    ts = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "    s = f\"[{ts}] {msg}\"\n",
    "    print(s)\n",
    "    with open(LOG_FILE, \"a\", encoding=\"utf8\") as fh:\n",
    "        fh.write(s + \"\\n\")\n",
    "\n",
    "# ---------------------------\n",
    "# Sanity checks for required files\n",
    "# ---------------------------\n",
    "if not DCORPUS_DIR.exists() or not any(DCORPUS_DIR.glob(\"*.jsonl\")):\n",
    "    raise FileNotFoundError(f\"Required D_corpus JSONL files not found in '{DCORPUS_DIR}'. Generate D_corpus first.\")\n",
    "\n",
    "if not G_TRUE_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Required ground-truth graph file not found: '{G_TRUE_PATH}'. Save G_true as a networkx gpickle.\")\n",
    "\n",
    "if not FEMBED_DIR.exists() or not (FEMBED_DIR / \"config.json\").exists() or not (FEMBED_DIR / \"checkpoint_best.pth\").exists():\n",
    "    raise FileNotFoundError(f\"f_embed artifacts missing in '{FEMBED_DIR}'. Required: config.json and checkpoint_best.pth\")\n",
    "\n",
    "write_log(\"All required inputs exist. Starting data-prep and training pipeline.\")\n",
    "\n",
    "# ---------------------------\n",
    "# Utilities: f_embed loader \n",
    "# ---------------------------\n",
    "class FEmbed:\n",
    "    def __init__(self, model_dir: Path):\n",
    "        cfgp = model_dir / \"config.json\"\n",
    "        cfg = json.loads(cfgp.read_text(encoding=\"utf8\"))\n",
    "        backbone = cfg.get(\"backbone\", \"all-MiniLM-L6-v2\")\n",
    "        d_embed = int(cfg.get(\"d_embed\", 256))\n",
    "        self.backbone = SentenceTransformer(backbone)\n",
    "        # try to load projection if present in checkpoint\n",
    "        ckpt = model_dir / \"checkpoint_best.pth\"\n",
    "        state = None\n",
    "        try:\n",
    "            state = joblib.load(ckpt) if str(ckpt).endswith(\".pkl\") else None\n",
    "        except Exception:\n",
    "            state = None\n",
    "        self.backbone.max_seq_length = 256\n",
    "\n",
    "    def encode(self, texts: List[str], batch_size: int = 64) -> np.ndarray:\n",
    "        if len(texts) == 0:\n",
    "            return np.zeros((0, self.backbone.get_sentence_embedding_dimension()))\n",
    "        embeddings = self.backbone.encode(texts, convert_to_tensor=False, show_progress_bar=False)\n",
    "        return np.array(embeddings)\n",
    "\n",
    "# ---------------------------\n",
    "# 1) Data-prep: parse D_corpus JSONL files\n",
    "# ---------------------------\n",
    "def load_d_corpus_files(dcorpus_dir: Path) -> List[Dict[str,Any]]:\n",
    "    records = []\n",
    "    files = sorted(dcorpus_dir.glob(\"*.jsonl\"))\n",
    "    write_log(f\"Found {len(files)} D_corpus files.\")\n",
    "    for p in files:\n",
    "        write_log(f\"Loading D_corpus file: {p}\")\n",
    "        with p.open(\"r\", encoding=\"utf8\") as fh:\n",
    "            for ln in fh:\n",
    "                rec = json.loads(ln)\n",
    "                records.append(rec)\n",
    "    write_log(f\"Loaded total {len(records)} D_corpus records.\")\n",
    "    return records\n",
    "\n",
    "# Graph utilities\n",
    "def compute_structural_features(G: nx.DiGraph, i: int, j: int, max_hops: int = MAX_PATH_CUTOFF) -> Dict[str, Any]:\n",
    "    \"\"\"Deterministic structural features using G_true\"\"\"\n",
    "    features = {}\n",
    "    features[\"isdirect\"] = 1 if G.has_edge(i, j) else 0\n",
    "    features[\"deg_i\"] = int(G.degree(i))\n",
    "    features[\"deg_j\"] = int(G.degree(j))\n",
    "    features[\"in_deg_i\"] = int(G.in_degree(i))\n",
    "    features[\"out_deg_i\"] = int(G.out_degree(i))\n",
    "    features[\"in_deg_j\"] = int(G.in_degree(j))\n",
    "    features[\"out_deg_j\"] = int(G.out_degree(j))\n",
    "    try:\n",
    "        paths = list(nx.all_simple_paths(G, source=i, target=j, cutoff=max_hops))\n",
    "    except Exception:\n",
    "        paths = []\n",
    "    features[\"num_paths_upto_k\"] = len(paths)\n",
    "    # average path length and average degree along paths\n",
    "    if len(paths) > 0:\n",
    "        lengths = [len(p)-1 for p in paths]  # hop count\n",
    "        features[\"avg_path_len\"] = float(sum(lengths)/len(lengths))\n",
    "        # compute average degree of intermediate nodes over all paths\n",
    "        degs = []\n",
    "        for p in paths:\n",
    "            internal = p[1:-1]\n",
    "            if internal:\n",
    "                degs.extend([G.degree(n) for n in internal])\n",
    "        features[\"avg_path_internal_deg\"] = float(np.mean(degs)) if degs else 0.0\n",
    "    else:\n",
    "        features[\"avg_path_len\"] = 0.0\n",
    "        features[\"avg_path_internal_deg\"] = 0.0\n",
    "\n",
    "    # node-disjoint path count (cap expensive computation)\n",
    "    try:\n",
    "        # networkx has node_disjoint_paths generator; count up to cap\n",
    "        gen = nx.algorithms.connectivity.disjoint_paths.node_disjoint_paths(G, i, j)\n",
    "        count = 0\n",
    "        for _ in gen:\n",
    "            count += 1\n",
    "            if count >= MAX_DISJOINT_PATHS:\n",
    "                break\n",
    "        features[\"k_node_disjoint_paths\"] = int(count)\n",
    "    except Exception:\n",
    "        features[\"k_node_disjoint_paths\"] = 0\n",
    "\n",
    "    return features\n",
    "\n",
    "# feature assembly for a single record\n",
    "def assemble_features_for_record(rec: Dict[str,Any], G: nx.DiGraph, fembed: FEmbed) -> Dict[str,Any]:\n",
    "    # node_pair (list) or node_pair stored as 'node_pair' or 'path'\n",
    "    if \"node_pair\" in rec:\n",
    "        i, j = int(rec[\"node_pair\"][0]), int(rec[\"node_pair\"][1])\n",
    "    elif \"path\" in rec and isinstance(rec[\"path\"], list) and len(rec[\"path\"]) >= 2:\n",
    "        i, j = int(rec[\"path\"][0]), int(rec[\"path\"][-1])\n",
    "    else:\n",
    "        # If not present, raise\n",
    "        raise KeyError(\"Record missing 'node_pair' and 'path' fields required to extract i,j.\")\n",
    "    structural = compute_structural_features(G, i, j)\n",
    "\n",
    "    pos_score = float(rec.get(\"pos_score\") if rec.get(\"pos_score\") is not None else rec.get(\"pos_score\", 0.0))\n",
    "    neg_score = float(rec.get(\"neg_score\") if rec.get(\"neg_score\") is not None else rec.get(\"neg_score\", 0.0))\n",
    "    if pos_score is None:\n",
    "        pos_score = float(rec.get(\"pos_meta\", {}).get(\"score\", 0.0) or 0.0)\n",
    "    if neg_score is None:\n",
    "        neg_score = float(rec.get(\"neg_meta\", {}).get(\"score\", 0.0) or 0.0)\n",
    "\n",
    "    # derive features inspired by paper spec\n",
    "    mu_LLM = pos_score\n",
    "    var_LLM = (pos_score - neg_score) ** 2\n",
    "    mu_LLM_cond = pos_score  \n",
    "    var_LLM_cond = var_LLM\n",
    "\n",
    "    p_plaus = float(rec.get(\"pos_score\", 0.0))  # proxy\n",
    "    p_temp = float(rec.get(\"pos_meta\", {}).get(\"temp_score\", 0.0) or rec.get(\"pos_temp\", 0.0) or 0.0)\n",
    "    p_mech = float(rec.get(\"pos_meta\", {}).get(\"mech_score\", 0.0) or rec.get(\"pos_mech\", 0.0) or 0.0)\n",
    "\n",
    "    # SGAE proxy: structural aggregate = avg(global clustering + degrees) across nodes on paths\n",
    "    paths = rec.get(\"path\") or []\n",
    "    if paths and isinstance(paths[0], list):\n",
    "        # list of node ids path already\n",
    "        all_path_nodes = []\n",
    "        for p in paths:\n",
    "            all_path_nodes.extend([int(x) for x in p])\n",
    "    elif isinstance(paths, list):\n",
    "        # might be direct list of ints representing single path\n",
    "        all_path_nodes = [int(x) for x in paths]\n",
    "    else:\n",
    "        all_path_nodes = []\n",
    "\n",
    "    if all_path_nodes:\n",
    "        unique_nodes = list(set(all_path_nodes))\n",
    "        degs = [G.degree(n) for n in unique_nodes]\n",
    "        sgae = float(np.mean(degs)) if degs else 0.0\n",
    "    else:\n",
    "        sgae = 0.0\n",
    "\n",
    "    # k disjoint already computed as structural[\"k_node_disjoint_paths\"]\n",
    "    kdisjoint = structural.get(\"k_node_disjoint_paths\", 0)\n",
    "\n",
    "    # combine features\n",
    "    feat = {\n",
    "        \"i\": int(i), \"j\": int(j),\n",
    "        \"graph_id\": rec.get(\"graph_id\", \"unknown\"),\n",
    "        \"domain\": rec.get(\"domain\", \"unknown\"),\n",
    "        \"pos_snippet\": rec.get(\"pos_snippet\", \"\")[:300],  # keep small preview\n",
    "        # structural features\n",
    "        \"isdirect_label\": int(rec.get(\"isdirect\", structural.get(\"isdirect\", 0))),\n",
    "        \"deg_i\": structural[\"deg_i\"],\n",
    "        \"deg_j\": structural[\"deg_j\"],\n",
    "        \"in_deg_i\": structural[\"in_deg_i\"],\n",
    "        \"out_deg_i\": structural[\"out_deg_i\"],\n",
    "        \"in_deg_j\": structural[\"in_deg_j\"],\n",
    "        \"out_deg_j\": structural[\"out_deg_j\"],\n",
    "        \"num_paths_upto_k\": structural[\"num_paths_upto_k\"],\n",
    "        \"avg_path_len\": structural[\"avg_path_len\"],\n",
    "        \"avg_path_internal_deg\": structural[\"avg_path_internal_deg\"],\n",
    "        \"kdisjoint\": kdisjoint,\n",
    "        # LLM features\n",
    "        \"mu_LLM\": mu_LLM,\n",
    "        \"var_LLM\": var_LLM,\n",
    "        \"mu_LLM_cond\": mu_LLM_cond,\n",
    "        \"var_LLM_cond\": var_LLM_cond,\n",
    "        # CPC-like proxies\n",
    "        \"p_plaus\": p_plaus,\n",
    "        \"p_temp\": p_temp,\n",
    "        \"p_mech\": p_mech,\n",
    "        # SGAE\n",
    "        \"SGAE\": sgae,\n",
    "        # path-level counts\n",
    "        \"path_node_count\": len(all_path_nodes),\n",
    "        \"pos_neg_diff\": pos_score - neg_score,\n",
    "        # metadata\n",
    "        \"record_id\": rec.get(\"id_pos\") or rec.get(\"id\") or random.randint(0, 10**9)\n",
    "    }\n",
    "    return feat\n",
    "\n",
    "# Hard negative mining using embedder similarity\n",
    "def mine_hard_negatives(records: List[Dict[str,Any]], fembed: FEmbed, per_pos: int = HARD_NEGATIVES_PER_POS) -> Dict[int, List[int]]:\n",
    "    \"\"\"\n",
    "    For each positive record index r (where isdirect==1) find 'per_pos' hard negatives indices\n",
    "    such that (i, k) not true and text similarity to positive is high.\n",
    "    Returns map pos_idx -> list of neg_indices\n",
    "    \"\"\"\n",
    "    write_log(\"Mining hard negatives using embedder similarity (this may take time)...\")\n",
    "    # Build corpus texts for all records (using pos_snippet)\n",
    "    texts = [rec.get(\"pos_snippet\", \"\") or rec.get(\"pos_snippet\", \"\") or \"\" for rec in records]\n",
    "    emb = fembed.encode(texts, batch_size=64)  # shape [N, d]\n",
    "    N = len(records)\n",
    "    if N == 0:\n",
    "        return {}\n",
    "    # Normalize\n",
    "    norms = np.linalg.norm(emb, axis=1, keepdims=True) + 1e-12\n",
    "    embn = emb / norms\n",
    "    # precompute\n",
    "    hard_neg_map = {}\n",
    "    # For efficiency compute dot products in blocks\n",
    "    for idx, rec in enumerate(tqdm(records, desc=\"hard-neg mining\")):\n",
    "        if int(rec.get(\"isdirect\", 0)) != 1:\n",
    "            continue\n",
    "        i = int(rec.get(\"node_pair\", [rec.get(\"path\",[None])[0], None])[0])\n",
    "        # similarity to others\n",
    "        qv = embn[idx:idx+1]  # [1,d]\n",
    "        sims = (embn @ qv.T).reshape(-1)  # [N,]\n",
    "        # sort by descending similarity, exclude itself and those with same (i,k) being true in G (we'll filter below)\n",
    "        order = np.argsort(-sims)\n",
    "        negs = []\n",
    "        for cand in order:\n",
    "            if cand == idx:\n",
    "                continue\n",
    "            # ensure candidate is not a true direct for same i\n",
    "            # get candidate j\n",
    "            try:\n",
    "                cand_pair = records[cand].get(\"node_pair\")\n",
    "                if cand_pair:\n",
    "                    cand_i = int(cand_pair[0]); cand_j = int(cand_pair[1])\n",
    "                else:\n",
    "                    pathc = records[cand].get(\"path\", [])\n",
    "                    cand_i = int(pathc[0]) if pathc else -1\n",
    "                    cand_j = int(pathc[-1]) if pathc else -1\n",
    "            except Exception:\n",
    "                cand_i, cand_j = -1, -1\n",
    "            if cand_i == i and records[cand].get(\"isdirect\", 0) == 1:\n",
    "                # skip true positives\n",
    "                continue\n",
    "            # else candidate is potential hard negative\n",
    "            negs.append(cand)\n",
    "            if len(negs) >= per_pos:\n",
    "                break\n",
    "        hard_neg_map[idx] = negs\n",
    "    write_log(f\"Found hard negatives for {len(hard_neg_map)} positive records.\")\n",
    "    return hard_neg_map\n",
    "\n",
    "# ---------------------------\n",
    "# Run Data-prep\n",
    "# ---------------------------\n",
    "write_log(\"Loading ground-truth graph...\")\n",
    "G_true = nx.read_gpickle(G_TRUE_PATH)\n",
    "if not isinstance(G_true, nx.DiGraph):\n",
    "    # If undirected or MultiDiGraph, convert to DiGraph \n",
    "    G_true = nx.DiGraph(G_true)\n",
    "\n",
    "write_log(\"Loading D_corpus JSONL records...\")\n",
    "drecords = load_d_corpus_files(DCORPUS_DIR)\n",
    "if len(drecords) == 0:\n",
    "    raise RuntimeError(\"No D_corpus records loaded; aborting.\")\n",
    "\n",
    "write_log(\"Initializing embedder for hard-negative mining...\")\n",
    "fembed = FEmbed(FEMBED_DIR)\n",
    "\n",
    "# Mine hard negatives (used later in ranking dataset construction)\n",
    "hard_neg_map = mine_hard_negatives(drecords, fembed, per_pos=HARD_NEGATIVES_PER_POS)\n",
    "\n",
    "# Assemble features for all records\n",
    "write_log(\"Assembling feature rows for TrainingSetFusion...\")\n",
    "rows = []\n",
    "for idx, rec in enumerate(tqdm(drecords, desc=\"assembling features\")):\n",
    "    try:\n",
    "        feat = assemble_features_for_record(rec, G_true, fembed)\n",
    "        feat[\"dcorpus_index\"] = idx\n",
    "        rows.append(feat)\n",
    "    except Exception as e:\n",
    "        write_log(f\"ERROR assembling record idx={idx}: {e}\")\n",
    "        raise\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "# Make deterministic column order (feature schema)\n",
    "feature_cols = [\n",
    "    \"deg_i\", \"deg_j\", \"in_deg_i\", \"out_deg_i\", \"in_deg_j\", \"out_deg_j\",\n",
    "    \"num_paths_upto_k\", \"avg_path_len\", \"avg_path_internal_deg\", \"kdisjoint\",\n",
    "    \"mu_LLM\", \"var_LLM\", \"mu_LLM_cond\", \"var_LLM_cond\",\n",
    "    \"p_plaus\", \"p_temp\", \"p_mech\",\n",
    "    \"SGAE\", \"path_node_count\", \"pos_neg_diff\"\n",
    "]\n",
    "# ensure all columns present\n",
    "for c in feature_cols:\n",
    "    if c not in df.columns:\n",
    "        df[c] = 0.0\n",
    "\n",
    "# label column\n",
    "label_col = \"isdirect_label\"\n",
    "if label_col not in df.columns:\n",
    "    raise RuntimeError(f\"Label column '{label_col}' not found in assembled features.\")\n",
    "\n",
    "# Save training CSV\n",
    "write_log(f\"Saving TrainingSetFusion CSV to {TRAINING_CSV} with {len(df)} rows.\")\n",
    "df_to_save = df[[\"dcorpus_index\", \"i\", \"j\", \"graph_id\", \"domain\", \"record_id\"] + feature_cols + [label_col]]\n",
    "df_to_save.to_csv(TRAINING_CSV, index=False)\n",
    "\n",
    "# ---------------------------\n",
    "# 2) Train f_fusion: classifier + ranker + calibrator\n",
    "# ---------------------------\n",
    "write_log(\"Starting training of fusion models...\")\n",
    "\n",
    "# Prepare feature matrix and labels\n",
    "X = df[feature_cols].astype(float).values\n",
    "y = df[label_col].astype(int).values\n",
    "meta = df[[\"i\", \"j\", \"graph_id\", \"domain\", \"dcorpus_index\"]].copy()\n",
    "\n",
    "# Train/val split deterministic\n",
    "train_idx, test_idx = train_test_split(np.arange(len(X)), test_size=TEST_SIZE, random_state=RNG_SEED, shuffle=True, stratify=None)\n",
    "X_train, X_test = X[train_idx], X[test_idx]\n",
    "y_train, y_test = y[train_idx], y[test_idx]\n",
    "meta_train, meta_test = meta.iloc[train_idx], meta.iloc[test_idx]\n",
    "\n",
    "# further split train-> train & calibrator set\n",
    "train_idx2, calib_idx = train_test_split(np.arange(len(X_train)), test_size=CALIBRATION_SIZE, random_state=RNG_SEED, shuffle=True)\n",
    "X_train2, X_calib = X_train[train_idx2], X_train[calib_idx]\n",
    "y_train2, y_calib = y_train[train_idx2], y_train[calib_idx]\n",
    "meta_train2 = meta_train.iloc[train_idx2]\n",
    "meta_calib = meta_train.iloc[calib_idx]\n",
    "\n",
    "write_log(f\"Data split sizes: train={len(X_train2)}, calib={len(X_calib)}, test={len(X_test)}\")\n",
    "\n",
    "monotone_map = []\n",
    "for c in feature_cols:\n",
    "    if c in (\"mu_LLM_cond\", \"SGAE\", \"kdisjoint\"):\n",
    "        monotone_map.append(1)\n",
    "    elif c in (\"var_LLM\", \"var_LLM_cond\"):\n",
    "        monotone_map.append(-1)\n",
    "    else:\n",
    "        monotone_map.append(0)\n",
    "LIGHTGBM_PARAMS[\"monotone_constraints\"] = monotone_map\n",
    "\n",
    "# Train classifier (LightGBM)\n",
    "dtrain = lgb.Dataset(X_train2, label=y_train2)\n",
    "dval = lgb.Dataset(X_calib, label=y_calib, reference=dtrain)\n",
    "write_log(\"Training LightGBM classifier with monotonic constraints...\")\n",
    "clf = lgb.train(LIGHTGBM_PARAMS, dtrain, num_boost_round=2000, valid_sets=[dval], early_stopping_rounds=100, verbose_eval=100)\n",
    "\n",
    "# Save classifier\n",
    "clf_path = MODEL_DIR / \"classifier.txt\"\n",
    "clfp = str(clf_path)\n",
    "clf.save_model(clfp)\n",
    "write_log(f\"Classifier saved to {clf_path}\")\n",
    "\n",
    "write_log(\"Preparing group structure for lambdarank ranker (group by source node i)...\")\n",
    "groups = meta_train2[\"i\"].values\n",
    "train_order = np.argsort(groups, kind=\"stable\")\n",
    "X_rank_train = X_train2[train_order]\n",
    "y_rank_train = y_train2[train_order]\n",
    "meta_rank_train = meta_train2.iloc[train_order]\n",
    "\n",
    "# create group sizes array\n",
    "unique_sources, counts = np.unique(meta_rank_train[\"i\"].values, return_counts=True)\n",
    "group_train = counts.tolist()\n",
    "write_log(f\"Ranker groups: {len(group_train)} unique source nodes, total rows {len(X_rank_train)}\")\n",
    "\n",
    "# create LightGBM dataset for ranking\n",
    "dtrain_rank = lgb.Dataset(X_rank_train, label=y_rank_train, group=group_train)\n",
    "meta_calib_sources = meta_calib[\"i\"].values\n",
    "calib_order = np.argsort(meta_calib_sources, kind=\"stable\")\n",
    "X_rank_calib = X_calib[calib_order]\n",
    "y_rank_calib = y_calib[calib_order]\n",
    "unique_sources_calib, counts_calib = np.unique(meta_calib[\"i\"].values, return_counts=True)\n",
    "group_calib = counts_calib.tolist() if len(counts_calib)>0 else [len(X_rank_calib)]\n",
    "dval_rank = lgb.Dataset(X_rank_calib, label=y_rank_calib, group=group_calib, reference=dtrain_rank)\n",
    "\n",
    "write_log(\"Training LightGBM Lambdarank model (for ranking behavior)...\")\n",
    "ranker = lgb.train(RANKER_PARAMS, dtrain_rank, num_boost_round=1000, valid_sets=[dval_rank], early_stopping_rounds=50, verbose_eval=100)\n",
    "\n",
    "ranker_path = MODEL_DIR / \"ranker.txt\"\n",
    "ranker.save_model(str(ranker_path))\n",
    "write_log(f\"Ranker saved to {ranker_path}\")\n",
    "\n",
    "# Combine classifier and ranker raw scores on calibration set and fit isotonic calibrator\n",
    "write_log(\"Generating raw scores for calibration (combining classifier & ranker raw outputs)...\")\n",
    "# classifier raw score: model.predict(X, raw_score=True) -> raw_margin\n",
    "clf_raw_calib = clf.predict(X_calib, raw_score=True)\n",
    "# for ranker we need to predict raw score as well (predict returns ranking score)\n",
    "rank_raw_calib = ranker.predict(X_calib, raw_score=True)\n",
    "# combine\n",
    "combined_raw_calib = CLASSIFIER_WEIGHT * clf_raw_calib + LAMBDA_RANK_WEIGHT * rank_raw_calib\n",
    "# map to probability via sigmoid then fit isotonic on probabilities\n",
    "p_raw_calib = 1.0 / (1.0 + np.exp(-combined_raw_calib))\n",
    "# Fit isotonic regressor mapping p_raw_calib -> y_calib\n",
    "write_log(\"Fitting isotonic calibrator on calibration set...\")\n",
    "iso_cal = IsotonicRegression(out_of_bounds=\"clip\")\n",
    "iso_cal.fit(p_raw_calib, y_calib)\n",
    "\n",
    "# Evaluate on test set\n",
    "write_log(\"Evaluating on held-out test set...\")\n",
    "clf_raw_test = clf.predict(X_test, raw_score=True)\n",
    "rank_raw_test = ranker.predict(X_test, raw_score=True)\n",
    "combined_raw_test = CLASSIFIER_WEIGHT * clf_raw_test + LAMBDA_RANK_WEIGHT * rank_raw_test\n",
    "p_raw_test = 1.0 / (1.0 + np.exp(-combined_raw_test))\n",
    "p_cal_test = iso_cal.transform(p_raw_test)\n",
    "\n",
    "auc_raw = roc_auc_score(y_test, p_raw_test)\n",
    "auc_cal = roc_auc_score(y_test, p_cal_test)\n",
    "ap_raw = average_precision_score(y_test, p_raw_test)\n",
    "ap_cal = average_precision_score(y_test, p_cal_test)\n",
    "ll_raw = log_loss(y_test, np.clip(p_raw_test, 1e-8, 1-1e-8))\n",
    "ll_cal = log_loss(y_test, np.clip(p_cal_test, 1e-8, 1-1e-8))\n",
    "\n",
    "write_log(f\"Test AUC raw: {auc_raw:.6f}  calibrated: {auc_cal:.6f}\")\n",
    "write_log(f\"Test AP raw: {ap_raw:.6f}  calibrated: {ap_cal:.6f}\")\n",
    "write_log(f\"Test logloss raw: {ll_raw:.6f}  calibrated: {ll_cal:.6f}\")\n",
    "\n",
    "# Save calibrator\n",
    "calib_path = MODEL_DIR / \"calibrator.pkl\"\n",
    "joblib.dump(iso_cal, calib_path)\n",
    "write_log(f\"Isotonic calibrator saved to {calib_path}\")\n",
    "\n",
    "# Save model metadata & feature schema\n",
    "feature_schema = {\"feature_order\": feature_cols, \"monotone_vector\": monotone_map, \"classifier_weight\": CLASSIFIER_WEIGHT, \"rank_weight\": LAMBDA_RANK_WEIGHT}\n",
    "with (MODEL_DIR / \"feature_schema.json\").open(\"w\", encoding=\"utf8\") as fh:\n",
    "    json.dump(feature_schema, fh, indent=2)\n",
    "\n",
    "train_info = {\n",
    "    \"n_total\": len(X),\n",
    "    \"n_train\": len(X_train2),\n",
    "    \"n_calib\": len(X_calib),\n",
    "    \"n_test\": len(X_test),\n",
    "    \"classifier_model\": str(clf_path),\n",
    "    \"ranker_model\": str(ranker_path),\n",
    "    \"calibrator\": str(calib_path),\n",
    "    \"feature_schema\": str(MODEL_DIR / \"feature_schema.json\")\n",
    "}\n",
    "with (MODEL_DIR / \"train_info.json\").open(\"w\", encoding=\"utf8\") as fh:\n",
    "    json.dump(train_info, fh, indent=2)\n",
    "\n",
    "# SHAP explainability for classifier: sample limited number (to keep compute reasonable)\n",
    "print(\"Computing SHAP summary for classifier (sampleing rows to limit cost)...\")\n",
    "explainer = shap.TreeExplainer(clf)\n",
    "sample_idx = np.random.RandomState(RNG_SEED).choice(len(X_train2), size=min(2000, len(X_train2)), replace=False)\n",
    "shap_values = explainer.shap_values(X_train2[sample_idx])\n",
    "# create simple summary: mean absolute SHAP per feature\n",
    "if isinstance(shap_values, list):\n",
    "    # binary classification can return list (per class); use difference or class 1\n",
    "    shap_arr = np.array(shap_values[1]) if len(shap_values) > 1 else np.array(shap_values[0])\n",
    "else:\n",
    "    shap_arr = np.array(shap_values)\n",
    "mean_abs_shap = np.mean(np.abs(shap_arr), axis=0).tolist()\n",
    "shap_summary = {f: float(v) for f, v in zip(feature_cols, mean_abs_shap)}\n",
    "\n",
    "with (MODEL_DIR / \"shap_summary.json\").open(\"w\", encoding=\"utf8\") as fh:\n",
    "    json.dump(shap_summary, fh, indent=2)\n",
    "print(\"SHAP summary saved.\")\n",
    "\n",
    "print(\"All artifacts saved in model_bundle. Fusion training complete.\")\n",
    "\n",
    "ensemble_info = {\n",
    "    \"classifier_path\": str(clf_path),\n",
    "    \"ranker_path\": str(ranker_path),\n",
    "    \"calibrator_path\": str(calib_path),\n",
    "    \"feature_schema\": feature_schema,\n",
    "    \"combine_formula\": f\"p_raw = sigmoid({CLASSIFIER_WEIGHT} * s_clf + {LAMBDA_RANK_WEIGHT} * s_rank); p_cal = isotonic(p_raw)\"\n",
    "}\n",
    "with (MODEL_DIR / \"ensemble_info.json\").open(\"w\", encoding=\"utf8\") as fh:\n",
    "    json.dump(ensemble_info, fh, indent=2)\n",
    "\n",
    "print(\"Finished prepare_and_train_fusion.py successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81a2282",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, log_loss, brier_score_loss\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "# Deterministic config\n",
    "RNG_SEED = 20251127\n",
    "random.seed(RNG_SEED)\n",
    "np.random.seed(RNG_SEED)\n",
    "\n",
    "# Paths\n",
    "TRAINING_CSV = Path(\"out/fusion/TrainingSetFusion.csv\")\n",
    "MODEL_DIR = Path(\"out/fusion/model_bundle\")\n",
    "CLF_PATH = MODEL_DIR / \"classifier.txt\"\n",
    "RANKER_PATH = MODEL_DIR / \"ranker.txt\"\n",
    "CALIB_PATH = MODEL_DIR / \"calibrator.pkl\"\n",
    "FEATURE_SCHEMA_PATH = MODEL_DIR / \"feature_schema.json\"\n",
    "\n",
    "OUT_DIR = Path(\"out/fusion/eval_basic\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Basic checks\n",
    "def fatal(msg: str):\n",
    "    raise FileNotFoundError(msg)\n",
    "\n",
    "for p in [TRAINING_CSV, CLF_PATH, RANKER_PATH, CALIB_PATH, FEATURE_SCHEMA_PATH]:\n",
    "    if not p.exists():\n",
    "        fatal(f\"Required file missing: {p}\")\n",
    "\n",
    "# Load feature schema\n",
    "schema = json.loads(FEATURE_SCHEMA_PATH.read_text(encoding=\"utf8\"))\n",
    "feature_cols = schema[\"feature_order\"]\n",
    "classifier_weight = float(schema.get(\"classifier_weight\", 0.7))\n",
    "ranker_weight = float(schema.get(\"rank_weight\", 0.3))\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(TRAINING_CSV)\n",
    "if df.shape[0] == 0:\n",
    "    fatal(\"Training CSV empty.\")\n",
    "\n",
    "# Recreate the same deterministic train/test split used in training script\n",
    "from sklearn.model_selection import train_test_split\n",
    "idx_all = np.arange(len(df))\n",
    "test_size = 0.10\n",
    "train_idx, test_idx = train_test_split(idx_all, test_size=test_size, random_state=RNG_SEED, shuffle=True, stratify=None)\n",
    "\n",
    "# Build feature matrix for test set\n",
    "X_test = df.loc[test_idx, feature_cols].astype(float).values\n",
    "y_test = df.loc[test_idx, \"isdirect_label\"].astype(int).values\n",
    "\n",
    "# Load models\n",
    "import lightgbm as lgb\n",
    "clf = lgb.Booster(model_file=str(CLF_PATH))\n",
    "ranker = lgb.Booster(model_file=str(RANKER_PATH))\n",
    "iso = joblib.load(CALIB_PATH)\n",
    "\n",
    "# Predict raw scores and calibrated probabilities\n",
    "s_clf_test = clf.predict(X_test, raw_score=True)\n",
    "s_rank_test = ranker.predict(X_test, raw_score=True)\n",
    "s_combined = classifier_weight * s_clf_test + ranker_weight * s_rank_test\n",
    "p_raw = 1.0 / (1.0 + np.exp(-s_combined))\n",
    "p_cal = iso.transform(p_raw)\n",
    "\n",
    "# Metrics\n",
    "metrics = {}\n",
    "metrics[\"n_test\"] = int(len(y_test))\n",
    "metrics[\"auc_raw\"] = float(roc_auc_score(y_test, p_raw))\n",
    "metrics[\"auc_calibrated\"] = float(roc_auc_score(y_test, p_cal))\n",
    "metrics[\"ap_raw\"] = float(average_precision_score(y_test, p_raw))\n",
    "metrics[\"ap_calibrated\"] = float(average_precision_score(y_test, p_cal))\n",
    "metrics[\"logloss_raw\"] = float(log_loss(y_test, np.clip(p_raw, 1e-12, 1 - 1e-12)))\n",
    "metrics[\"logloss_calibrated\"] = float(log_loss(y_test, np.clip(p_cal, 1e-12, 1 - 1e-12)))\n",
    "metrics[\"brier_raw\"] = float(brier_score_loss(y_test, p_raw))\n",
    "metrics[\"brier_calibrated\"] = float(brier_score_loss(y_test, p_cal))\n",
    "\n",
    "# ECE (histogram binning)\n",
    "def compute_ece(probs, labels, n_bins=10):\n",
    "    probs = np.asarray(probs)\n",
    "    labels = np.asarray(labels)\n",
    "    bins = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "    ece = 0.0\n",
    "    for i in range(n_bins):\n",
    "        lo, hi = bins[i], bins[i+1]\n",
    "        if i < n_bins - 1:\n",
    "            mask = (probs >= lo) & (probs < hi)\n",
    "        else:\n",
    "            mask = (probs >= lo) & (probs <= hi)\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        avg_conf = probs[mask].mean()\n",
    "        avg_acc = labels[mask].mean()\n",
    "        ece += (mask.sum() / len(probs)) * abs(avg_conf - avg_acc)\n",
    "    return float(ece)\n",
    "\n",
    "metrics[\"ece_raw\"] = compute_ece(p_raw, y_test, n_bins=15)\n",
    "metrics[\"ece_calibrated\"] = compute_ece(p_cal, y_test, n_bins=15)\n",
    "\n",
    "# Save metrics JSON\n",
    "summary = {\n",
    "    \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()),\n",
    "    \"metrics\": metrics,\n",
    "    \"model_paths\": {\n",
    "        \"classifier\": str(CLF_PATH),\n",
    "        \"ranker\": str(RANKER_PATH),\n",
    "        \"calibrator\": str(CALIB_PATH),\n",
    "        \"feature_schema\": str(FEATURE_SCHEMA_PATH)\n",
    "    }\n",
    "}\n",
    "(out := OUT_DIR / \"fusion_basic_eval.json\").write_text(json.dumps(summary, indent=2))\n",
    "print(\"Saved metrics to\", out)\n",
    "\n",
    "# Reliability diagram (calibration curve)\n",
    "def reliability_plot(probs, labels, n_bins=15, ax=None, label=\"model\"):\n",
    "    probs = np.asarray(probs)\n",
    "    labels = np.asarray(labels)\n",
    "    bins = np.linspace(0.0, 1.0, n_bins+1)\n",
    "    bin_centers = (bins[:-1] + bins[1:]) / 2.0\n",
    "    acc = []\n",
    "    conf = []\n",
    "    counts = []\n",
    "    for i in range(n_bins):\n",
    "        lo, hi = bins[i], bins[i+1]\n",
    "        if i < n_bins - 1:\n",
    "            mask = (probs >= lo) & (probs < hi)\n",
    "        else:\n",
    "            mask = (probs >= lo) & (probs <= hi)\n",
    "        if mask.sum() == 0:\n",
    "            acc.append(np.nan)\n",
    "            conf.append((lo + hi)/2.0)\n",
    "            counts.append(0)\n",
    "        else:\n",
    "            acc.append(labels[mask].mean())\n",
    "            conf.append(probs[mask].mean())\n",
    "            counts.append(int(mask.sum()))\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(6,6))\n",
    "    ax.plot([0,1], [0,1], \"k--\", linewidth=1)\n",
    "    ax.plot(conf, acc, marker=\"o\", label=label)\n",
    "    for c, a, b in zip(counts, conf, acc):\n",
    "        if c > 0:\n",
    "            ax.text(a, b, str(c), fontsize=8, alpha=0.6)\n",
    "    ax.set_xlabel(\"Confidence (mean prob in bin)\")\n",
    "    ax.set_ylabel(\"Accuracy (empirical)\")\n",
    "    ax.set_title(\"Reliability diagram\")\n",
    "    ax.set_xlim(0,1); ax.set_ylim(0,1)\n",
    "    ax.legend()\n",
    "    return ax\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "ax1 = plt.subplot(1,2,1)\n",
    "reliability_plot(p_raw, y_test, n_bins=15, ax=ax1, label=\"raw\")\n",
    "ax2 = plt.subplot(1,2,2)\n",
    "reliability_plot(p_cal, y_test, n_bins=15, ax=ax2, label=\"calibrated\")\n",
    "plt.tight_layout()\n",
    "fig_path = OUT_DIR / \"reliability_diagrams.png\"\n",
    "plt.savefig(fig_path, dpi=200)\n",
    "plt.close()\n",
    "print(\"Saved reliability diagrams to\", fig_path)\n",
    "\n",
    "print(\"Evaluation summary:\")\n",
    "print(json.dumps(metrics, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889f3cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ndcg_score\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Deterministic config\n",
    "RNG_SEED = 20251127\n",
    "random.seed(RNG_SEED)\n",
    "np.random.seed(RNG_SEED)\n",
    "\n",
    "# Paths \n",
    "TRAINING_CSV = Path(\"out/fusion/TrainingSetFusion.csv\")\n",
    "MODEL_DIR = Path(\"out/fusion/model_bundle\")\n",
    "CLF_PATH = MODEL_DIR / \"classifier.txt\"\n",
    "RANKER_PATH = MODEL_DIR / \"ranker.txt\"\n",
    "CALIB_PATH = MODEL_DIR / \"calibrator.pkl\"\n",
    "FEATURE_SCHEMA_PATH = MODEL_DIR / \"feature_schema.json\"\n",
    "\n",
    "OUT_DIR = Path(\"out/fusion/eval_ranking\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Basic checks\n",
    "def fatal(msg: str):\n",
    "    raise FileNotFoundError(msg)\n",
    "\n",
    "for p in [TRAINING_CSV, CLF_PATH, RANKER_PATH, CALIB_PATH, FEATURE_SCHEMA_PATH]:\n",
    "    if not p.exists():\n",
    "        fatal(f\"Required file missing: {p}\")\n",
    "\n",
    "schema = json.loads(FEATURE_SCHEMA_PATH.read_text(encoding=\"utf8\"))\n",
    "feature_cols = schema[\"feature_order\"]\n",
    "classifier_weight = float(schema.get(\"classifier_weight\", 0.7))\n",
    "ranker_weight = float(schema.get(\"rank_weight\", 0.3))\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(TRAINING_CSV)\n",
    "if df.shape[0] == 0:\n",
    "    fatal(\"Training CSV empty.\")\n",
    "\n",
    "# Recreate same train/test split\n",
    "idx_all = np.arange(len(df))\n",
    "test_size = 0.10\n",
    "train_idx, test_idx = train_test_split(idx_all, test_size=test_size, random_state=RNG_SEED, shuffle=True, stratify=None)\n",
    "\n",
    "# Test set meta & features\n",
    "df_test = df.iloc[test_idx].reset_index(drop=True)\n",
    "X_test = df_test[feature_cols].astype(float).values\n",
    "y_test = df_test[\"isdirect_label\"].astype(int).values\n",
    "meta_test = df_test[[\"i\", \"j\", \"graph_id\", \"record_id\"]].copy()\n",
    "\n",
    "# Load models\n",
    "clf = lgb.Booster(model_file=str(CLF_PATH))\n",
    "ranker = lgb.Booster(model_file=str(RANKER_PATH))\n",
    "iso = joblib.load(CALIB_PATH)\n",
    "\n",
    "# compute raw and calibrated probs\n",
    "s_clf = clf.predict(X_test, raw_score=True)\n",
    "s_rank = ranker.predict(X_test, raw_score=True)\n",
    "s_comb = classifier_weight * s_clf + ranker_weight * s_rank\n",
    "p_raw = 1.0 / (1.0 + np.exp(-s_comb))\n",
    "p_cal = iso.transform(p_raw)\n",
    "\n",
    "# Build grouping by source node (i) within test set\n",
    "groups = {}\n",
    "for idx, row in df_test.iterrows():\n",
    "    src = int(row[\"i\"])\n",
    "    groups.setdefault(src, []).append(idx)\n",
    "\n",
    "# Ranking metrics per group: compute NDCG@k, Recall@k, MRR\n",
    "K_list = [1, 3, 5]\n",
    "ndcg_at_k = {k: [] for k in K_list}\n",
    "recall_at_k = {k: [] for k in K_list}\n",
    "mrrs = []\n",
    "\n",
    "for src, indices in groups.items():\n",
    "    if len(indices) < 1:\n",
    "        continue\n",
    "    inds = np.array(indices)\n",
    "    y_grp = y_test[inds]\n",
    "    if np.sum(y_grp) == 0:\n",
    "        # no positives in group -> skip for recall/ndcg (or count separately)\n",
    "        continue\n",
    "    # rank by p_cal descending\n",
    "    scores = p_cal[inds]\n",
    "    order = np.argsort(-scores)\n",
    "    y_sorted = y_grp[order]\n",
    "    relevance = y_sorted.reshape(1, -1)\n",
    "    # For ndcg@k for each K\n",
    "    for k in K_list:\n",
    "        # ndcg_score expects y_score shape (1, n) and y_true shape (1, n), but supports top_k param\n",
    "        try:\n",
    "            val = ndcg_score([y_grp], [scores], k=k)\n",
    "        except Exception:\n",
    "            # fallback manual ndcg (binary relevance)\n",
    "            val = float(0.0)\n",
    "        ndcg_at_k[k].append(float(val))\n",
    "        # Recall@k: proportion of positives retrieved in top-k relative to total positives\n",
    "        topk = y_sorted[:k]\n",
    "        recall = float(np.sum(topk) / (np.sum(y_grp) + 1e-12))\n",
    "        recall_at_k[k].append(recall)\n",
    "    # MRR: reciprocal rank of first relevant item\n",
    "    ranks = np.where(y_sorted == 1)[0]\n",
    "    if len(ranks) == 0:\n",
    "        mrrs.append(0.0)\n",
    "    else:\n",
    "        mrrs.append(1.0 / (1 + int(ranks[0])))\n",
    "\n",
    "# Aggregate metrics\n",
    "def aggr(vals):\n",
    "    if len(vals) == 0:\n",
    "        return {\"mean\": None, \"median\": None, \"count\": 0}\n",
    "    return {\"mean\": float(np.mean(vals)), \"median\": float(np.median(vals)), \"count\": len(vals)}\n",
    "\n",
    "ranking_summary = {\n",
    "    \"ndcg\": {k: aggr(ndcg_at_k[k]) for k in K_list},\n",
    "    \"recall\": {k: aggr(recall_at_k[k]) for k in K_list},\n",
    "    \"mrr\": aggr(mrrs),\n",
    "    \"n_groups_evaluated\": sum(1 for v in groups.values() if any(df_test.iloc[v][\"isdirect_label\"]==1))\n",
    "}\n",
    "\n",
    "# Save ranking summary\n",
    "ranking_out = OUT_DIR / \"fusion_ranking_eval.json\"\n",
    "with ranking_out.open(\"w\", encoding=\"utf8\") as fh:\n",
    "    json.dump({\n",
    "        \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()),\n",
    "        \"ranking_summary\": ranking_summary,\n",
    "        \"model_paths\": {\n",
    "            \"classifier\": str(CLF_PATH),\n",
    "            \"ranker\": str(RANKER_PATH),\n",
    "            \"calibrator\": str(CALIB_PATH)\n",
    "        },\n",
    "        \"n_test_items\": int(len(df_test))\n",
    "    }, fh, indent=2)\n",
    "print(\"Saved ranking summary to\", ranking_out)\n",
    "\n",
    "# Plot distribution of NDCG@5 across groups (if enough groups)\n",
    "ndcg5_vals = ndcg_at_k[5]\n",
    "if len(ndcg5_vals) > 0:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.histplot(ndcg5_vals, bins=30, kde=False)\n",
    "    plt.xlabel(\"NDCG@5 per source\")\n",
    "    plt.title(\"Distribution of NDCG@5 across source nodes (test set)\")\n",
    "    plt.tight_layout()\n",
    "    pth = OUT_DIR / \"ndcg5_hist.png\"\n",
    "    plt.savefig(pth, dpi=200)\n",
    "    plt.close()\n",
    "    print(\"Saved NDCG@5 distribution to\", pth)\n",
    "else:\n",
    "    print(\"No groups with positives in test set to compute NDCG@5 distribution.\")\n",
    "\n",
    "# Save a small per-source table for manual inspection: top-K ranked candidates per source (K=5)\n",
    "K = 5\n",
    "topk_records = []\n",
    "for src, indices in groups.items():\n",
    "    inds = np.array(indices)\n",
    "    scores = p_cal[inds]\n",
    "    order = np.argsort(-scores)[:K]\n",
    "    for pos_rank, ordinal in enumerate(order, start=1):\n",
    "        idx_glob = inds[ordinal]\n",
    "        topk_records.append({\n",
    "            \"source\": int(src),\n",
    "            \"rank\": int(pos_rank),\n",
    "            \"candidate_j\": int(df_test.iloc[idx_glob][\"j\"]),\n",
    "            \"p_cal\": float(p_cal[idx_glob]),\n",
    "            \"y_true\": int(df_test.iloc[idx_glob][\"isdirect_label\"])\n",
    "        })\n",
    "topk_df = pd.DataFrame(topk_records)\n",
    "topk_path = OUT_DIR / \"topk_per_source.csv\"\n",
    "topk_df.to_csv(topk_path, index=False)\n",
    "print(\"Saved top-K candidates per source to\", topk_path)\n",
    "\n",
    "print(\"Ranking evaluation complete. Summary:\")\n",
    "print(json.dumps(ranking_summary, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296f53ed",
   "metadata": {},
   "source": [
    "### iv. Train $LPA_{model}$ (Learned Path Aggregator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c7b94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ---------------------------\n",
    "# Deterministic configuration\n",
    "# ---------------------------\n",
    "RNG_SEED = 20251127\n",
    "random.seed(RNG_SEED)\n",
    "np.random.seed(RNG_SEED)\n",
    "torch.manual_seed(RNG_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RNG_SEED)\n",
    "\n",
    "# ---------------------------\n",
    "# Paths and file checks\n",
    "# ---------------------------\n",
    "TRAINING_SET_PATH = Path(\"out/dsynth/TrainingSetPath.jsonl\")   # triplets: p_anchor, p_pos, p_hardneg\n",
    "TRAINING_SET_LPA = Path(\"out/dsynth/TrainingSetLPA.jsonl\")     # tuples: { \"paths\": [[n1,...,nL], ...], \n",
    "\n",
    "OUT_DIR = Path(\"out/lpa_model\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not TRAINING_SET_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Required TrainingSetPath file not found: {TRAINING_SET_PATH}\")\n",
    "if not TRAINING_SET_LPA.exists():\n",
    "    raise FileNotFoundError(f\"Required TrainingSetLPA file not found: {TRAINING_SET_LPA}\")\n",
    "\n",
    "# ---------------------------\n",
    "# Hyperparameters (config)\n",
    "# ---------------------------\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE_CONTRAST = 256       # contrastive batch size\n",
    "BATCH_SIZE_LPA = 128            # regression batch size\n",
    "D_MODEL = 256                   # Transformer hidden dim\n",
    "NUM_HEADS = 8\n",
    "NUM_LAYERS = 4\n",
    "D_FF = 512\n",
    "D_PATH = 256                    # final path embedding dim (d_path)\n",
    "MAX_PATH_LENGTH = 32            # maximum nodes per path (truncate or pad)\n",
    "TEMPERATURE = 0.1               # InfoNCE temp\n",
    "QUEUE_SIZE = 65536              # momentum queue size for negatives\n",
    "LR_PRETRAIN = 1e-4\n",
    "LR_AGG = 5e-4\n",
    "WEIGHT_DECAY = 1e-3\n",
    "NUM_EPOCHS_PRETRAIN = 8         # number of epochs Phase A\n",
    "NUM_EPOCHS_AGG_FREEZE = 6      # Phase B1 freeze encoder train aggregator\n",
    "NUM_EPOCHS_JOINT = 6           # Phase B2 joint fine-tune\n",
    "LAMBDA_PATH = 1.0\n",
    "LAMBDA_DIV = 1.0\n",
    "LAMBDA_REGRESS = 10.0\n",
    "VIC_GAMMA = 1.0                # minimum variance threshold in VICReg\n",
    "VIC_LAMBDA = 1.0\n",
    "VIC_MU = 1.0\n",
    "HUBER_DELTA = 0.01\n",
    "MOMENTUM_QUEUE_M = 0.999       # momentum for any momentum encoder (not used here but reserved)\n",
    "GRAD_CLIP = 1.0\n",
    "\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "# ---------------------------\n",
    "# Utility functions\n",
    "# ---------------------------\n",
    "def now_str():\n",
    "    return time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
    "\n",
    "def save_json(obj, path: Path):\n",
    "    with path.open(\"w\", encoding=\"utf8\") as fh:\n",
    "        json.dump(obj, fh, indent=2)\n",
    "\n",
    "# ---------------------------\n",
    "# Datasets\n",
    "# ---------------------------\n",
    "class TrainingSetPathDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Expects TRAINING_SET_PATH JSONL entries of form:\n",
    "    { \"anchor\": [n1, n2, ...], \"positive\": [n1,...], \"hard_neg\": [n1,...], \"path_features_anchor\": {...} }\n",
    "    - The node ids are integers; we'll convert them into indices and fetch node embeddings externally.\n",
    "    - For path encoder pretraining we only need sequences of node identifiers; any per-node features will be ignored here\n",
    "      except that the dataset yields token sequences (node ids).\n",
    "    \"\"\"\n",
    "    def __init__(self, jsonl_path: Path, max_path_len: int = MAX_PATH_LENGTH):\n",
    "        self.max_path_len = max_path_len\n",
    "        self.rows = []\n",
    "        with jsonl_path.open(\"r\", encoding=\"utf8\") as fh:\n",
    "            for ln in fh:\n",
    "                rec = json.loads(ln)\n",
    "                # Accept multiple possible key names for clarity but require anchor and positive\n",
    "                anchor = rec.get(\"panchor\") or rec.get(\"anchor\") or rec.get(\"anchor_path\") or rec.get(\"anchor_path\", rec.get(\"anchor\"))\n",
    "                positive = rec.get(\"ppos\") or rec.get(\"positive\") or rec.get(\"positive_path\") or rec.get(\"positive_path\", rec.get(\"positive\"))\n",
    "                neg = rec.get(\"phardneg\") or rec.get(\"hard_neg\") or rec.get(\"hard_neg_path\") or rec.get(\"neg\") or rec.get(\"neg_path\")\n",
    "                if anchor is None or positive is None:\n",
    "                    continue\n",
    "                self.rows.append({\"anchor\": anchor, \"positive\": positive, \"neg\": neg})\n",
    "        if len(self.rows) == 0:\n",
    "            raise RuntimeError(f\"No valid triplets loaded from {jsonl_path}\")\n",
    "    def __len__(self):\n",
    "        return len(self.rows)\n",
    "    def __getitem__(self, idx):\n",
    "        r = self.rows[idx]\n",
    "        return {\n",
    "            \"anchor\": r[\"anchor\"],\n",
    "            \"positive\": r[\"positive\"],\n",
    "            \"neg\": r[\"neg\"]\n",
    "        }\n",
    "\n",
    "class TrainingSetLPADataset(Dataset):\n",
    "    \"\"\"\n",
    "    Expects TRAINING_SET_LPA JSONL entries of form:\n",
    "    {\n",
    "      \"paths\": [[n1,...,nL], [n1,...], ...],\n",
    "      \"path_features\": [ { ... } , ... ] (optional per path),\n",
    "      \"trueindirectscore\": float in [0,1],\n",
    "      \"i\": source, \"j\": target\n",
    "    }\n",
    "    For each sample we return the list of paths, per-path features (dicts or vectors), and the scalar target.\n",
    "    \"\"\"\n",
    "    def __init__(self, jsonl_path: Path, max_path_len: int = MAX_PATH_LENGTH):\n",
    "        self.max_path_len = max_path_len\n",
    "        self.rows = []\n",
    "        with jsonl_path.open(\"r\", encoding=\"utf8\") as fh:\n",
    "            for ln in fh:\n",
    "                rec = json.loads(ln)\n",
    "                paths = rec.get(\"paths\") or rec.get(\"path_list\") or rec.get(\"path\")\n",
    "                if paths is None:\n",
    "                    continue\n",
    "                target = float(rec.get(\"trueindirectscore\", rec.get(\"trueindirect\", 0.0)))\n",
    "                path_features = rec.get(\"path_features\", None)\n",
    "                self.rows.append({\"paths\": paths, \"path_features\": path_features, \"target\": target, \"meta\": {\"i\": rec.get(\"i\"), \"j\": rec.get(\"j\"), \"graph_id\": rec.get(\"graph_id\")}})\n",
    "        if len(self.rows) == 0:\n",
    "            raise RuntimeError(f\"No valid LPA samples loaded from {jsonl_path}\")\n",
    "    def __len__(self):\n",
    "        return len(self.rows)\n",
    "    def __getitem__(self, idx):\n",
    "        r = self.rows[idx]\n",
    "        return {\n",
    "            \"paths\": r[\"paths\"],\n",
    "            \"path_features\": r[\"path_features\"],\n",
    "            \"target\": r[\"target\"],\n",
    "            \"meta\": r[\"meta\"]\n",
    "        }\n",
    "\n",
    "# ---------------------------\n",
    "# Simple Node -> embedding provider\n",
    "# ---------------------------\n",
    "# LP-A needs per-node vectors. In the paper these are f_embed outputs.\n",
    "NODE_EMB_PATH_JSON = Path(\"out/embeddings/node_embeddings.json\")\n",
    "NODE_EMB_PATH_NPZ = Path(\"out/embeddings/node_embeddings.npz\")\n",
    "\n",
    "if not NODE_EMB_PATH_NPZ.exists() and not NODE_EMB_PATH_JSON.exists():\n",
    "    raise FileNotFoundError(\"Node embeddings required by LP-A not found. Expected out/embeddings/node_embeddings.npz or .json\")\n",
    "\n",
    "# Load node embeddings into a dict mapping 'N{int}' -> numpy array\n",
    "node_emb_dict = {}\n",
    "if NODE_EMB_PATH_NPZ.exists():\n",
    "    npz = np.load(NODE_EMB_PATH_NPZ, allow_pickle=True)\n",
    "    keys = npz[\"keys\"]\n",
    "    embs = npz[\"embs\"]\n",
    "    for k, v in zip(keys.tolist(), embs):\n",
    "        node_emb_dict[str(k)] = np.array(v, dtype=np.float32)\n",
    "else:\n",
    "    j = json.loads(NODE_EMB_PATH_JSON.read_text(encoding=\"utf8\"))\n",
    "    # j expected: { \"N1\": [..], \"N2\": [..], ... }\n",
    "    for k, v in j.items():\n",
    "        node_emb_dict[str(k)] = np.array(v, dtype=np.float32)\n",
    "\n",
    "NODE_EMB_DIM = next(iter(node_emb_dict.values())).shape[0]\n",
    "\n",
    "# Helper: convert node id (int) to key string used in embeddings, supports 'N{int}' or int->string mapping\n",
    "def node_key(n: int) -> str:\n",
    "    k = f\"N{int(n)}\"\n",
    "    if k in node_emb_dict:\n",
    "        return k\n",
    "    # fallback: try str(n)\n",
    "    if str(n) in node_emb_dict:\n",
    "        return str(n)\n",
    "    # last resort: try to find any key that endswith digits equal to n\n",
    "    for key in node_emb_dict.keys():\n",
    "        if key.endswith(str(n)):\n",
    "            return key\n",
    "    raise KeyError(f\"Node embedding not found for node {n}\")\n",
    "\n",
    "# ---------------------------\n",
    "# Collate functions: pad/truncate paths to MAX_PATH_LENGTH, produce node embeddings stack per path\n",
    "# ---------------------------\n",
    "def pad_or_truncate(seq: List[int], max_len: int, pad_value: int = 0) -> List[int]:\n",
    "    if len(seq) >= max_len:\n",
    "        return seq[:max_len]\n",
    "    return seq + [pad_value] * (max_len - len(seq))\n",
    "\n",
    "def paths_to_tensor(paths: List[List[int]], max_len: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Convert list of paths (list of node ints) into tensor [num_paths, max_len, NODE_EMB_DIM]\n",
    "    using node_emb_dict.\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for p in paths:\n",
    "        p_trunc = pad_or_truncate([int(x) for x in p], max_len, pad_value=0)\n",
    "        emb_rows = []\n",
    "        for node in p_trunc:\n",
    "            try:\n",
    "                key = node_key(node)\n",
    "                emb = node_emb_dict[key]\n",
    "            except Exception:\n",
    "                # fallback to zero vector\n",
    "                emb = np.zeros((NODE_EMB_DIM,), dtype=np.float32)\n",
    "            emb_rows.append(emb)\n",
    "        out.append(np.stack(emb_rows, axis=0))  # [max_len, D]\n",
    "    return torch.tensor(np.stack(out, axis=0), dtype=torch.float32)  # [num_paths, max_len, D]\n",
    "\n",
    "# ---------------------------\n",
    "# Model components: Transformer path encoder, attention aggregator, MLP heads\n",
    "# ---------------------------\n",
    "class PathTransformerEncoder(nn.Module):\n",
    "    def __init__(self, node_emb_dim: int, d_model: int = D_MODEL, nhead: int = NUM_HEADS, num_layers: int = NUM_LAYERS, dim_feedforward: int = D_FF, d_path: int = D_PATH, dropout: float = 0.1, max_len: int = MAX_PATH_LENGTH):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(node_emb_dim, d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout, batch_first=True, activation=\"gelu\")\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.max_len = max_len\n",
    "        # learned positional embeddings\n",
    "        self.pos_emb = nn.Embedding(max_len, d_model)\n",
    "        # pooling to d_path dimension\n",
    "        self.pool = nn.Linear(d_model, d_path)\n",
    "        self.norm = nn.LayerNorm(d_path)\n",
    "    def forward(self, x: torch.Tensor, mask: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        # x: [B, L, node_emb_dim]\n",
    "        B, L, _ = x.shape\n",
    "        pos_ids = torch.arange(L, device=x.device).unsqueeze(0).expand(B, -1)  # [B, L]\n",
    "        x = self.input_proj(x) + self.pos_emb(pos_ids)  # [B, L, d_model]\n",
    "        # transformer expects [B, L, d_model] with batch_first=True\n",
    "        x = self.transformer(x, src_key_padding_mask=None)  # [B, L, d_model]\n",
    "        # pool: mean over length dimension (could use CLS but paths may not have CLS)\n",
    "        x_mean = x.mean(dim=1)  # [B, d_model]\n",
    "        h = self.pool(x_mean)   # [B, d_path]\n",
    "        h = self.norm(h)\n",
    "        return h  # [B, d_path]\n",
    "\n",
    "class AttentionAggregator(nn.Module):\n",
    "    \"\"\"\n",
    "    Attention-based aggregator fagg:\n",
    "    - Accepts m path embeddings [m, d_path] and optional per-path features (vector)\n",
    "    - Computes attention weights and returns aggregated vector -> MLP -> scalar in [0,1]\n",
    "    \"\"\"\n",
    "    def __init__(self, d_path: int = D_PATH, path_feat_dim: int = 8, hidden_dim: int = 256):\n",
    "        super().__init__()\n",
    "        self.query = nn.Parameter(torch.randn(d_path))  # learned global query\n",
    "        # small MLP to produce attention logits from concat([h_p, path_feat_proj])\n",
    "        self.path_feat_proj = nn.Linear(path_feat_dim, d_path) if path_feat_dim > 0 else None\n",
    "        self.att_mlp = nn.Sequential(\n",
    "            nn.Linear(d_path * 2 if self.path_feat_proj is not None else d_path, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "        # aggregator head (map aggregated vector + pooled path stats -> scalar)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(d_path + 4, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "    def forward(self, path_embs: torch.Tensor, path_feats: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        # path_embs: [m, d_path] OR [B, m, d_path] depending on call (we will use batch processing)\n",
    "        # path_feats: [m, feat_dim] OR [B, m, feat_dim]\n",
    "        single = False\n",
    "        if path_embs.dim() == 2:\n",
    "            path_embs = path_embs.unsqueeze(0)  # [1, m, d]\n",
    "            if path_feats is not None and path_feats.dim() == 1:\n",
    "                path_feats = path_feats.unsqueeze(0)\n",
    "            single = True\n",
    "        B, m, d = path_embs.shape\n",
    "        # expand query\n",
    "        q = self.query.unsqueeze(0).unsqueeze(1).expand(B, m, -1)  # [B, m, d]\n",
    "        att_inputs = path_embs\n",
    "        if self.path_feat_proj is not None and path_feats is not None:\n",
    "            pf = self.path_feat_proj(path_feats)  # [B, m, d]\n",
    "            att_inputs = torch.cat([path_embs, pf], dim=-1)\n",
    "        else:\n",
    "            # use path_embs alone\n",
    "            pass\n",
    "        logits = self.att_mlp(att_inputs).squeeze(-1)  # [B, m]\n",
    "        att = F.softmax(logits, dim=-1)  # [B, m]\n",
    "        # weighted pooling\n",
    "        agg = (att.unsqueeze(-1) * path_embs).sum(dim=1)  # [B, d]\n",
    "        # compute some pooled path stats: mean length, max length, num_paths, mean path_feat if available\n",
    "        num_paths = torch.tensor([m], device=path_embs.device, dtype=torch.float32).expand(B)\n",
    "        # for generality compute simple stats from path_feats if present\n",
    "        stats = []\n",
    "        stats.append(num_paths.unsqueeze(-1))  # [B,1]\n",
    "        # placeholder stats (0-filled) to make fixed-size; actual path-level features should be passed if available\n",
    "        stats.append(torch.zeros((B,1), device=path_embs.device))\n",
    "        stats.append(torch.zeros((B,1), device=path_embs.device))\n",
    "        stats.append(torch.zeros((B,1), device=path_embs.device))\n",
    "        stats_cat = torch.cat(stats, dim=-1)  # [B,4]\n",
    "        head_in = torch.cat([agg, stats_cat], dim=-1)  # [B, d + 4]\n",
    "        out = self.head(head_in).squeeze(-1)  # [B]\n",
    "        out = torch.sigmoid(out)\n",
    "        if single:\n",
    "            return out.squeeze(0)\n",
    "        return out  # [B]\n",
    "\n",
    "# ---------------------------\n",
    "# Losses\n",
    "# ---------------------------\n",
    "def info_nce_loss(anchor: torch.Tensor, positive: torch.Tensor, negatives: torch.Tensor, temperature: float = TEMPERATURE) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    anchor: [B, d] normalized or not (we will normalize before)\n",
    "    positive: [B, d]\n",
    "    negatives: [B, K, d]  (K negatives per anchor). Could also be [B, Nneg, d]\n",
    "    Returns average InfoNCE loss over batch\n",
    "    \"\"\"\n",
    "    # Normalize\n",
    "    anchor_n = F.normalize(anchor, p=2, dim=-1)\n",
    "    positive_n = F.normalize(positive, p=2, dim=-1)\n",
    "    negs_n = F.normalize(negatives, p=2, dim=-1) if negatives is not None else None\n",
    "\n",
    "    pos_sim = torch.sum(anchor_n * positive_n, dim=-1, keepdim=True)  # [B,1]\n",
    "    if negs_n is None:\n",
    "        # Only positive (degenerate)\n",
    "        logits = pos_sim / temperature\n",
    "        labels = torch.zeros(anchor_n.shape[0], dtype=torch.long, device=anchor.device)\n",
    "        loss = F.cross_entropy(logits, labels)  # will fail shape; better to return zero\n",
    "        return torch.tensor(0.0, device=anchor.device)\n",
    "    # compute sim to negatives: [B, K]\n",
    "    neg_sim = torch.einsum(\"bd,bkd->bk\", anchor_n, negs_n)  # [B,K]\n",
    "    logits = torch.cat([pos_sim, neg_sim], dim=1) / temperature  # [B, 1+K]\n",
    "    labels = torch.zeros(anchor_n.shape[0], dtype=torch.long, device=anchor.device)  # positive at index 0\n",
    "    loss = F.cross_entropy(logits, labels)\n",
    "    return loss\n",
    "\n",
    "def vicreg_loss(embeddings: torch.Tensor, gamma: float = VIC_GAMMA, lambda_v: float = VIC_LAMBDA, mu_cov: float = VIC_MU) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    embeddings: [B, d]\n",
    "    Returns scalar vicreg (variance + covariance) penalty.\n",
    "    \"\"\"\n",
    "    B, d = embeddings.shape\n",
    "    # remove mean\n",
    "    z = embeddings - embeddings.mean(dim=0, keepdim=True)  # [B,d]\n",
    "    # variance per dim\n",
    "    var = z.var(dim=0, unbiased=False)  # [d]\n",
    "    var_term = torch.clamp(gamma - var, min=0.0).mean()  # scalar\n",
    "    # covariance matrix (d x d)\n",
    "    cov = (z.T @ z) / (B - 1)  # [d,d]\n",
    "    # zero out diagonal\n",
    "    diag = torch.diag(cov)\n",
    "    cov_no_diag = cov.clone()\n",
    "    cov_no_diag.fill_diagonal_(0.0)\n",
    "    cov_term = (cov_no_diag ** 2).sum() / (d * d)\n",
    "    loss = lambda_v * var_term + mu_cov * cov_term\n",
    "    return loss\n",
    "\n",
    "def huber_loss(pred: torch.Tensor, target: torch.Tensor, delta: float = HUBER_DELTA) -> torch.Tensor:\n",
    "    err = pred - target\n",
    "    abs_err = torch.abs(err)\n",
    "    mask = (abs_err <= delta).float()\n",
    "    loss = mask * 0.5 * err * err + (1.0 - mask) * (delta * abs_err - 0.5 * delta * delta)\n",
    "    return loss.mean()\n",
    "\n",
    "# ---------------------------\n",
    "# Momentum queue for negatives\n",
    "# ---------------------------\n",
    "class MomentumQueue:\n",
    "    def __init__(self, dim: int, max_size: int = QUEUE_SIZE, device: torch.device = DEVICE):\n",
    "        self.max_size = int(max_size)\n",
    "        self.dim = dim\n",
    "        self.device = device\n",
    "        self.buffer = torch.zeros((0, dim), dtype=torch.float32, device=device)\n",
    "    def push(self, x: torch.Tensor):\n",
    "        # x: [N, d]\n",
    "        x = x.detach().to(self.device)\n",
    "        if self.buffer.numel() == 0:\n",
    "            self.buffer = x.clone()\n",
    "        else:\n",
    "            self.buffer = torch.cat([self.buffer, x], dim=0)\n",
    "        if self.buffer.shape[0] > self.max_size:\n",
    "            # evict oldest\n",
    "            self.buffer = self.buffer[-self.max_size:]\n",
    "    def sample_negatives(self, batch_size: int, k: int) -> torch.Tensor:\n",
    "        # returns [batch_size, k, d]\n",
    "        if self.buffer.shape[0] == 0:\n",
    "            # return random tiny noise to avoid failure\n",
    "            return torch.randn((batch_size, k, self.dim), device=self.device)\n",
    "        idx = torch.randint(0, self.buffer.shape[0], (batch_size * k,), device=self.device)\n",
    "        sampled = self.buffer[idx].reshape(batch_size, k, self.dim)\n",
    "        return sampled\n",
    "\n",
    "# ---------------------------\n",
    "# Training functions\n",
    "# ---------------------------\n",
    "def train_phaseA_contrastive(encoder: PathTransformerEncoder, dataset: TrainingSetPathDataset, out_dir: Path):\n",
    "    \"\"\"\n",
    "    Phase A: pretrain encoder with InfoNCE + VICReg\n",
    "    \"\"\"\n",
    "    encoder.to(DEVICE)\n",
    "    encoder.train()\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE_CONTRAST, shuffle=True, num_workers=NUM_WORKERS, drop_last=True)\n",
    "    optim = torch.optim.AdamW(encoder.parameters(), lr=LR_PRETRAIN, weight_decay=WEIGHT_DECAY)\n",
    "    queue = MomentumQueue(dim=D_PATH, max_size=QUEUE_SIZE, device=DEVICE)\n",
    "    global_step = 0\n",
    "    for epoch in range(NUM_EPOCHS_PRETRAIN):\n",
    "        pbar = tqdm(dataloader, desc=f\"PhaseA Epoch {epoch+1}/{NUM_EPOCHS_PRETRAIN}\")\n",
    "        epoch_loss = 0.0\n",
    "        for batch in pbar:\n",
    "            # batch contains lists of anchors/positives/negs (lists of node id lists)\n",
    "            anchors = batch[\"anchor\"]\n",
    "            positives = batch[\"positive\"]\n",
    "            # convert to tensors [B, L, D_node]\n",
    "            A = paths_to_tensor(anchors, MAX_PATH_LENGTH).to(DEVICE)  # [B,L,D_node]\n",
    "            P = paths_to_tensor(positives, MAX_PATH_LENGTH).to(DEVICE)\n",
    "            # forward\n",
    "            ha = encoder(A)  # [B, d_path]\n",
    "            hp = encoder(P)  # [B, d_path]\n",
    "            # negatives from momentum queue (K chosen as small number)\n",
    "            K = 512 if queue.buffer.shape[0] > 0 else 0\n",
    "            if K > 0:\n",
    "                negs = queue.sample_negatives(BATCH_SIZE_CONTRAST, min(128, K))  # [B, k, d]\n",
    "            else:\n",
    "                negs = None\n",
    "            # contrastive loss\n",
    "            loss_contrast = info_nce_loss(ha, hp, negs, TEMPERATURE) if negs is not None else info_nce_loss(ha, hp, None, TEMPERATURE)\n",
    "            # vicreg diversity loss on batch embeddings (use ha and hp concatenated)\n",
    "            emb_batch = torch.cat([ha, hp], dim=0)  # [2B, d]\n",
    "            loss_div = vicreg_loss(emb_batch, gamma=VIC_GAMMA, lambda_v=VIC_LAMBDA, mu_cov=VIC_MU)\n",
    "            loss = LAMBDA_PATH * loss_contrast + LAMBDA_DIV * loss_div\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(encoder.parameters(), GRAD_CLIP)\n",
    "            optim.step()\n",
    "            # push current embeddings to queue (use ha.detach())\n",
    "            queue.push(torch.cat([ha.detach(), hp.detach()], dim=0))\n",
    "            global_step += 1\n",
    "            epoch_loss += loss.item()\n",
    "            pbar.set_postfix({\"loss\": epoch_loss / (global_step + 1e-12)})\n",
    "        # epoch end: save checkpoint\n",
    "        ckpt = {\"encoder_state\": encoder.state_dict(), \"optimizer_state\": optim.state_dict(), \"epoch\": epoch}\n",
    "        torch.save(ckpt, out_dir / f\"phaseA_encoder_epoch{epoch+1}.pth\")\n",
    "    # final save\n",
    "    torch.save({\"encoder_state\": encoder.state_dict()}, out_dir / \"encoder_pretrained.pth\")\n",
    "    return encoder\n",
    "\n",
    "def train_phaseB_aggregator_and_joint(encoder: PathTransformerEncoder, aggregator: AttentionAggregator, lpa_dataset: TrainingSetLPADataset, out_dir: Path):\n",
    "    \"\"\"\n",
    "    Phase B:\n",
    "      - Stage 1: freeze encoder, train aggregator (regression Huber) on TrainingSetLPA\n",
    "      - Stage 2: unfreeze encoder and fine-tune both with full LLPA = lambda_path * Lpath + lambda_div * Ldiv + lambda_regress * Lregress\n",
    "    \"\"\"\n",
    "    # Create dataloader for LPA dataset\n",
    "    dl = DataLoader(lpa_dataset, batch_size=BATCH_SIZE_LPA, shuffle=True, num_workers=NUM_WORKERS, collate_fn=lambda x: x)\n",
    "    # Stage 1: freeze encoder\n",
    "    encoder.to(DEVICE)\n",
    "    aggregator.to(DEVICE)\n",
    "    encoder.eval()\n",
    "    for p in encoder.parameters():\n",
    "        p.requires_grad = False\n",
    "    # aggregator optimizer\n",
    "    optim_agg = torch.optim.AdamW(aggregator.parameters(), lr=LR_AGG, weight_decay=WEIGHT_DECAY)\n",
    "    # train aggregator\n",
    "    for epoch in range(NUM_EPOCHS_AGG_FREEZE):\n",
    "        pbar = tqdm(dl, desc=f\"PhaseB1 Agg Epoch {epoch+1}/{NUM_EPOCHS_AGG_FREEZE}\")\n",
    "        epoch_loss = 0.0\n",
    "        count = 0\n",
    "        for batch in pbar:\n",
    "            # batch is a list of samples (size up to BATCH_SIZE_LPA)\n",
    "            # For each sample: convert its paths into path_embs via encoder (encoder in eval mode)\n",
    "            batch_path_embs = []\n",
    "            batch_path_feats = []\n",
    "            batch_targets = []\n",
    "            for sample in batch:\n",
    "                paths = sample[\"paths\"]\n",
    "                # convert paths to tensor [m, L, D_node]\n",
    "                t = paths_to_tensor(paths, MAX_PATH_LENGTH).to(DEVICE)  # [m, L, D_node]\n",
    "                with torch.no_grad():\n",
    "                    path_embs = encoder(t)  # [m, d_path]\n",
    "                batch_path_embs.append(path_embs)\n",
    "                # assemble per-path features if available (we will use zero vector fallback)\n",
    "                pf = sample.get(\"path_features\")\n",
    "                if pf is None:\n",
    "                    # zero tensor [m, path_feat_dim] (aggregator expects path_feat_dim default 8; create zeros)\n",
    "                    pf_t = torch.zeros((path_embs.shape[0], 8), device=DEVICE)\n",
    "                else:\n",
    "                    # If path features are given as vectors, convert to tensor; else zero\n",
    "                    try:\n",
    "                        pf_arr = np.array(pf, dtype=np.float32)\n",
    "                        if pf_arr.ndim == 1:\n",
    "                            pf_arr = np.expand_dims(pf_arr, axis=0).repeat(path_embs.shape[0], axis=0)\n",
    "                        pf_t = torch.tensor(pf_arr, device=DEVICE, dtype=torch.float32)\n",
    "                    except Exception:\n",
    "                        pf_t = torch.zeros((path_embs.shape[0], 8), device=DEVICE)\n",
    "                batch_path_feats.append(pf_t)\n",
    "                batch_targets.append(torch.tensor(sample[\"target\"], dtype=torch.float32, device=DEVICE))\n",
    "            # process each sample in the minibatch individually (variable number of paths)\n",
    "            optim_agg.zero_grad()\n",
    "            losses = []\n",
    "            for path_embs, path_feats, target in zip(batch_path_embs, batch_path_feats, batch_targets):\n",
    "                pred = aggregator(path_embs, path_feats)  # scalar\n",
    "                loss_r = huber_loss(pred.unsqueeze(0), target.unsqueeze(0), delta=HUBER_DELTA)\n",
    "                losses.append(loss_r)\n",
    "            loss_batch = torch.stack(losses).mean()\n",
    "            loss_batch.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(aggregator.parameters(), GRAD_CLIP)\n",
    "            optim_agg.step()\n",
    "            epoch_loss += loss_batch.item()\n",
    "            count += 1\n",
    "            pbar.set_postfix({\"loss\": epoch_loss / max(1, count)})\n",
    "        # epoch end save aggregator\n",
    "        torch.save({\"aggregator_state\": aggregator.state_dict(), \"optimizer_state\": optim_agg.state_dict(), \"epoch\": epoch}, out_dir / f\"phaseB1_agg_epoch{epoch+1}.pth\")\n",
    "    # Stage 2: joint fine-tune both components\n",
    "    for p in encoder.parameters():\n",
    "        p.requires_grad = True\n",
    "    encoder.train()\n",
    "    aggregator.train()\n",
    "    optim_joint = torch.optim.AdamW(list(encoder.parameters()) + list(aggregator.parameters()), lr=LR_PRETRAIN/5.0, weight_decay=WEIGHT_DECAY)\n",
    "    # We'll reuse MomentumQueue for negatives using current encoder embeddings\n",
    "    queue = MomentumQueue(dim=D_PATH, max_size=QUEUE_SIZE, device=DEVICE)\n",
    "    for epoch in range(NUM_EPOCHS_JOINT):\n",
    "        pbar = tqdm(dl, desc=f\"PhaseB2 Joint Epoch {epoch+1}/{NUM_EPOCHS_JOINT}\")\n",
    "        epoch_loss = 0.0\n",
    "        count = 0\n",
    "        for batch in pbar:\n",
    "            # For combined loss we need: contrastive term (anchor, pos, negatives), vicreg on batch embeddings, and regression loss on predicted Ilearned\n",
    "            batch_path_embs = []\n",
    "            batch_pos_embs = []\n",
    "            batch_targets = []\n",
    "            batch_path_feats_list = []\n",
    "            # For InfoNCE we will assemble anchor/positive from each sample's first two paths (if available)\n",
    "            for sample in batch:\n",
    "                paths = sample[\"paths\"]\n",
    "                if len(paths) < 2:\n",
    "                    # if less than 2 paths, duplicate the path to make positive (degenerate)\n",
    "                    anchor_paths = [paths[0]]\n",
    "                    positive_paths = [paths[0]]\n",
    "                else:\n",
    "                    anchor_paths = [paths[0]]\n",
    "                    positive_paths = [paths[1]]\n",
    "                # build tensors\n",
    "                t_anchor = paths_to_tensor(anchor_paths, MAX_PATH_LENGTH).to(DEVICE)  # [1,L,Dnode]\n",
    "                t_positive = paths_to_tensor(positive_paths, MAX_PATH_LENGTH).to(DEVICE)\n",
    "                # encode\n",
    "                ha = encoder(t_anchor)  # [1, d]\n",
    "                hp = encoder(t_positive)  # [1, d]\n",
    "                batch_path_embs.append(ha.squeeze(0))\n",
    "                batch_pos_embs.append(hp.squeeze(0))\n",
    "                # full path embeddings for aggregator (all paths)\n",
    "                full_t = paths_to_tensor(paths, MAX_PATH_LENGTH).to(DEVICE)\n",
    "                full_embs = encoder(full_t)  # [m, d]\n",
    "                batch_path_feats_list.append(full_embs)\n",
    "                batch_targets.append(torch.tensor(sample[\"target\"], dtype=torch.float32, device=DEVICE))\n",
    "            # stack anchor/pos into tensors [B, d]\n",
    "            anchors = torch.stack(batch_path_embs, dim=0)  # [B, d]\n",
    "            positives = torch.stack(batch_pos_embs, dim=0)  # [B, d]\n",
    "            # collect negatives from queue\n",
    "            if queue.buffer.shape[0] >= 1:\n",
    "                negs = queue.sample_negatives(anchors.shape[0], min(128, queue.buffer.shape[0])).to(DEVICE)  # [B, k, d]\n",
    "            else:\n",
    "                negs = None\n",
    "            # compute losses\n",
    "            optim_joint.zero_grad()\n",
    "            # InfoNCE\n",
    "            loss_path = info_nce_loss(anchors, positives, negs, TEMPERATURE)\n",
    "            # VICReg on combined embeddings (anchors + positives)\n",
    "            emb_for_vic = torch.cat([anchors, positives], dim=0)\n",
    "            loss_div = vicreg_loss(emb_for_vic, gamma=VIC_GAMMA, lambda_v=VIC_LAMBDA, mu_cov=VIC_MU)\n",
    "            # Regression via aggregator on each sample using its full set of path embeddings\n",
    "            reg_losses = []\n",
    "            preds = []\n",
    "            for full_embs, target in zip(batch_path_feats_list, batch_targets):\n",
    "                # full_embs: [m, d]\n",
    "                # for path_feats pass None (aggregator handles)\n",
    "                pred = aggregator(full_embs, None)  # scalar\n",
    "                preds.append(pred)\n",
    "                lr = huber_loss(pred.unsqueeze(0), target.unsqueeze(0), delta=HUBER_DELTA)\n",
    "                reg_losses.append(lr)\n",
    "            loss_regress = torch.stack(reg_losses).mean()\n",
    "            loss_total = LAMBDA_PATH * loss_path + LAMBDA_DIV * loss_div + LAMBDA_REGRESS * loss_regress\n",
    "            loss_total.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(list(encoder.parameters()) + list(aggregator.parameters()), GRAD_CLIP)\n",
    "            optim_joint.step()\n",
    "            # push embeddings to queue: anchors & positives\n",
    "            queue.push(torch.cat([anchors.detach(), positives.detach()], dim=0))\n",
    "            epoch_loss += loss_total.item()\n",
    "            count += 1\n",
    "            pbar.set_postfix({\"loss\": epoch_loss / max(1, count)})\n",
    "        # epoch end save joint checkpoint\n",
    "        torch.save({\"encoder_state\": encoder.state_dict(), \"aggregator_state\": aggregator.state_dict(), \"optimizer_state\": optim_joint.state_dict(), \"epoch\": epoch}, out_dir / f\"phaseB2_joint_epoch{epoch+1}.pth\")\n",
    "    # final save\n",
    "    torch.save({\"encoder_state\": encoder.state_dict()}, out_dir / \"encoder_finetuned.pth\")\n",
    "    torch.save({\"aggregator_state\": aggregator.state_dict()}, out_dir / \"aggregator_finetuned.pth\")\n",
    "    return encoder, aggregator\n",
    "\n",
    "# ---------------------------\n",
    "# Main runner\n",
    "# ---------------------------\n",
    "def main():\n",
    "    t0 = time.time()\n",
    "    print(\"LP-A training start:\", now_str())\n",
    "    # instantiate datasets\n",
    "    ds_path = TrainingSetPathDataset(TRAINING_SET_PATH, max_path_len=MAX_PATH_LENGTH)\n",
    "    ds_lpa = TrainingSetLPADataset(TRAINING_SET_LPA, max_path_len=MAX_PATH_LENGTH)\n",
    "    print(f\"Loaded datasets: PathTriplets={len(ds_path)}  LPA_samples={len(ds_lpa)}\")\n",
    "    # instantiate models\n",
    "    encoder = PathTransformerEncoder(node_emb_dim=NODE_EMB_DIM, d_model=D_MODEL, nhead=NUM_HEADS, num_layers=NUM_LAYERS, dim_feedforward=D_FF, d_path=D_PATH, max_len=MAX_PATH_LENGTH)\n",
    "    aggregator = AttentionAggregator(d_path=D_PATH, path_feat_dim=8, hidden_dim=256)\n",
    "    # Phase A pretraining\n",
    "    print(\"Phase A: Contrastive pretraining (InfoNCE + VICReg)\")\n",
    "    encoder = train_phaseA_contrastive(encoder, ds_path, OUT_DIR)\n",
    "    # Phase B aggregator training and joint fine-tune\n",
    "    print(\"Phase B: Aggregator training (freeze encoder) and joint fine-tuning\")\n",
    "    encoder, aggregator = train_phaseB_aggregator_and_joint(encoder, aggregator, ds_lpa, OUT_DIR)\n",
    "    bundle = {\n",
    "        \"encoder_path\": str((OUT_DIR / \"encoder_finetuned.pth\").resolve()),\n",
    "        \"aggregator_path\": str((OUT_DIR / \"aggregator_finetuned.pth\").resolve()),\n",
    "        \"node_emb_source\": str(NODE_EMB_PATH_NPZ if NODE_EMB_PATH_NPZ.exists() else NODE_EMB_PATH_JSON),\n",
    "        \"config\": {\n",
    "            \"D_PATH\": D_PATH,\n",
    "            \"MAX_PATH_LENGTH\": MAX_PATH_LENGTH,\n",
    "            \"TEMPERATURE\": TEMPERATURE,\n",
    "            \"QUEUE_SIZE\": QUEUE_SIZE,\n",
    "            \"NUM_EPOCHS_PRETRAIN\": NUM_EPOCHS_PRETRAIN,\n",
    "            \"NUM_EPOCHS_AGG_FREEZE\": NUM_EPOCHS_AGG_FREEZE,\n",
    "            \"NUM_EPOCHS_JOINT\": NUM_EPOCHS_JOINT,\n",
    "        },\n",
    "        \"trained_at\": now_str()\n",
    "    }\n",
    "    save_json(bundle, OUT_DIR / \"lpa_model_bundle.json\")\n",
    "    print(\"LP-A training finished. Artifacts written to:\", OUT_DIR)\n",
    "    print(\"Elapsed (s):\", time.time() - t0)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb78c2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "# ---------------------------\n",
    "# Deterministic setup\n",
    "# ---------------------------\n",
    "RNG_SEED = 20251127\n",
    "random.seed(RNG_SEED)\n",
    "np.random.seed(RNG_SEED)\n",
    "torch.manual_seed(RNG_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RNG_SEED)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ---------------------------\n",
    "# Paths\n",
    "# ---------------------------\n",
    "BASE_OUT = Path(\"out/lpa_model\")\n",
    "MODEL_BUNDLE = BASE_OUT / \"lpa_model_bundle.json\"\n",
    "ENC_DECODE_PTH = BASE_OUT / \"encoder_finetuned.pth\"\n",
    "AGG_PTH = BASE_OUT / \"aggregator_finetuned.pth\"\n",
    "TRAINING_SET_PATH = Path(\"out/dsynth/TrainingSetPath.jsonl\")\n",
    "TRAINING_SET_LPA = Path(\"out/dsynth/TrainingSetLPA.jsonl\")\n",
    "NODE_EMB_NPZ = Path(\"out/embeddings/node_embeddings.npz\")\n",
    "NODE_EMB_JSON = Path(\"out/embeddings/node_embeddings.json\")\n",
    "\n",
    "EVAL_OUT_DIR = BASE_OUT / f\"eval_{time.strftime('%Y%m%d_%H%M%S')}\"\n",
    "EVAL_OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "required = [\n",
    "    MODEL_BUNDLE, ENC_DECODE_PTH, AGG_PTH, TRAINING_SET_PATH, TRAINING_SET_LPA\n",
    "]\n",
    "if not (NODE_EMB_NPZ.exists() or NODE_EMB_JSON.exists()):\n",
    "    raise FileNotFoundError(\"Node embeddings missing: expected out/embeddings/node_embeddings.npz or .json\")\n",
    "\n",
    "for p in required:\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"Required file missing: {p}\")\n",
    "\n",
    "# ---------------------------\n",
    "# Utilities \n",
    "# ---------------------------\n",
    "import torch.nn as nn\n",
    "\n",
    "# Load node embeddings\n",
    "node_emb_dict = {}\n",
    "if NODE_EMB_NPZ.exists():\n",
    "    npz = np.load(NODE_EMB_NPZ, allow_pickle=True)\n",
    "    keys = npz[\"keys\"]\n",
    "    embs = npz[\"embs\"]\n",
    "    for k, v in zip(keys.tolist(), embs):\n",
    "        node_emb_dict[str(k)] = np.array(v, dtype=np.float32)\n",
    "else:\n",
    "    j = json.loads(NODE_EMB_JSON.read_text(encoding=\"utf8\"))\n",
    "    for k, v in j.items():\n",
    "        node_emb_dict[str(k)] = np.array(v, dtype=np.float32)\n",
    "NODE_EMB_DIM = next(iter(node_emb_dict.values())).shape[0]\n",
    "\n",
    "def node_key(n: int) -> str:\n",
    "    k = f\"N{int(n)}\"\n",
    "    if k in node_emb_dict:\n",
    "        return k\n",
    "    if str(n) in node_emb_dict:\n",
    "        return str(n)\n",
    "    for key in node_emb_dict.keys():\n",
    "        if key.endswith(str(n)):\n",
    "            return key\n",
    "    raise KeyError(f\"Node embedding not found for node {n}\")\n",
    "\n",
    "def pad_or_truncate(seq: List[int], max_len: int, pad_value: int = 0) -> List[int]:\n",
    "    if len(seq) >= max_len:\n",
    "        return seq[:max_len]\n",
    "    return seq + [pad_value] * (max_len - len(seq))\n",
    "def paths_to_tensor(paths: List[List[int]], max_len: int, node_dim: int):\n",
    "    out = []\n",
    "    for p in paths:\n",
    "        p_trunc = pad_or_truncate([int(x) for x in p], max_len, pad_value=0)\n",
    "        rows = []\n",
    "        for node in p_trunc:\n",
    "            try:\n",
    "                key = node_key(node)\n",
    "                emb = node_emb_dict[key]\n",
    "            except Exception:\n",
    "                emb = np.zeros((node_dim,), dtype=np.float32)\n",
    "            rows.append(emb)\n",
    "        out.append(np.stack(rows, axis=0))\n",
    "    return torch.tensor(np.stack(out, axis=0), dtype=torch.float32)  # [num_paths, max_len, node_dim]\n",
    "\n",
    "# Model class skeletons \n",
    "class PathTransformerEncoder(nn.Module):\n",
    "    def __init__(self, node_emb_dim: int, d_model: int = 256, nhead: int = 8, num_layers: int = 4, dim_feedforward: int = 512, d_path: int = 256, max_len: int = 32):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(node_emb_dim, d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward, batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.pos_emb = nn.Embedding(max_len, d_model)\n",
    "        self.pool = nn.Linear(d_model, d_path)\n",
    "        self.norm = nn.LayerNorm(d_path)\n",
    "        self.max_len = max_len\n",
    "    def forward(self, x):\n",
    "        # x: [B, L, node_dim]\n",
    "        B, L, _ = x.shape\n",
    "        pos_ids = torch.arange(L, device=x.device).unsqueeze(0).expand(B, -1)\n",
    "        x = self.input_proj(x) + self.pos_emb(pos_ids)\n",
    "        x = self.transformer(x)\n",
    "        x_mean = x.mean(dim=1)\n",
    "        h = self.pool(x_mean)\n",
    "        h = self.norm(h)\n",
    "        return h\n",
    "\n",
    "class AttentionAggregator(nn.Module):\n",
    "    def __init__(self, d_path: int = 256, path_feat_dim: int = 8, hidden_dim: int = 256):\n",
    "        super().__init__()\n",
    "        self.query = nn.Parameter(torch.randn(d_path))\n",
    "        self.path_feat_proj = nn.Linear(path_feat_dim, d_path) if path_feat_dim>0 else None\n",
    "        self.att_mlp = nn.Sequential(nn.Linear(d_path*2 if self.path_feat_proj is not None else d_path, hidden_dim), nn.GELU(), nn.Linear(hidden_dim,1))\n",
    "        self.head = nn.Sequential(nn.Linear(d_path+4, hidden_dim), nn.GELU(), nn.Linear(hidden_dim,1))\n",
    "    def forward(self, path_embs, path_feats=None):\n",
    "        single=False\n",
    "        if path_embs.dim()==2:\n",
    "            path_embs = path_embs.unsqueeze(0)\n",
    "            single=True\n",
    "        B,m,d = path_embs.shape\n",
    "        if self.path_feat_proj is not None and path_feats is not None:\n",
    "            pf = self.path_feat_proj(path_feats)\n",
    "            att_in = torch.cat([path_embs, pf], dim=-1)\n",
    "        else:\n",
    "            att_in = path_embs\n",
    "        logits = self.att_mlp(att_in).squeeze(-1)\n",
    "        att = F.softmax(logits, dim=-1)\n",
    "        agg = (att.unsqueeze(-1) * path_embs).sum(dim=1)\n",
    "        num_paths = torch.tensor([m], device=path_embs.device, dtype=torch.float32).expand(B).unsqueeze(-1)\n",
    "        stats_cat = torch.cat([num_paths, torch.zeros((B,3), device=path_embs.device)], dim=-1)\n",
    "        head_in = torch.cat([agg, stats_cat], dim=-1)\n",
    "        out = torch.sigmoid(self.head(head_in).squeeze(-1))\n",
    "        if single:\n",
    "            return out.squeeze(0)\n",
    "        return out\n",
    "\n",
    "# load saved model samples\n",
    "bundle = json.loads(MODEL_BUNDLE.read_text(encoding=\"utf8\"))\n",
    "cfg = bundle.get(\"config\", {})\n",
    "MAX_PATH_LENGTH = int(cfg.get(\"MAX_PATH_LENGTH\", 32))\n",
    "D_PATH = int(cfg.get(\"D_PATH\", 256))\n",
    "\n",
    "# instantiate models and load checkpoints\n",
    "encoder = PathTransformerEncoder(node_emb_dim=NODE_EMB_DIM, d_path=D_PATH, max_len=MAX_PATH_LENGTH)\n",
    "aggregator = AttentionAggregator(d_path=D_PATH, path_feat_dim=8, hidden_dim=256)\n",
    "encoder_ckpt = torch.load(ENC_DECODE_PTH, map_location=\"cpu\")\n",
    "if \"encoder_state\" in encoder_ckpt:\n",
    "    encoder.load_state_dict(encoder_ckpt[\"encoder_state\"])\n",
    "else:\n",
    "    encoder.load_state_dict(encoder_ckpt) \n",
    "aggregator_ckpt = torch.load(AGG_PTH, map_location=\"cpu\")\n",
    "if \"aggregator_state\" in aggregator_ckpt:\n",
    "    aggregator.load_state_dict(aggregator_ckpt[\"aggregator_state\"])\n",
    "else:\n",
    "    aggregator.load_state_dict(aggregator_ckpt)\n",
    "encoder = encoder.to(DEVICE).eval()\n",
    "aggregator = aggregator.to(DEVICE).eval()\n",
    "\n",
    "# ---------------------------\n",
    "# Dataset loaders for evaluation\n",
    "# ---------------------------\n",
    "def load_jsonl(path: Path):\n",
    "    rows=[]\n",
    "    with path.open(\"r\", encoding=\"utf8\") as fh:\n",
    "        for ln in fh:\n",
    "            rows.append(json.loads(ln))\n",
    "    return rows\n",
    "\n",
    "print(\"Loading datasets...\")\n",
    "triplets = load_jsonl(TRAINING_SET_PATH)  # entries must contain anchor/positive keys\n",
    "lpa_rows = load_jsonl(TRAINING_SET_LPA)\n",
    "print(f\"Triplets: {len(triplets)}  LPA samples: {len(lpa_rows)}\")\n",
    "\n",
    "# Normalize potential key names in triplets\n",
    "triplet_records=[]\n",
    "for rec in triplets:\n",
    "    anchor = rec.get(\"panchor\") or rec.get(\"anchor\") or rec.get(\"anchor_path\") or rec.get(\"anchor_path\", rec.get(\"anchor\"))\n",
    "    positive = rec.get(\"ppos\") or rec.get(\"positive\") or rec.get(\"positive_path\") or rec.get(\"positive_path\", rec.get(\"positive\"))\n",
    "    neg = rec.get(\"phardneg\") or rec.get(\"hard_neg\") or rec.get(\"neg\") or rec.get(\"neg_path\")\n",
    "    if anchor is None or positive is None:\n",
    "        continue\n",
    "    triplet_records.append({\"anchor\": anchor, \"positive\": positive, \"neg\": neg})\n",
    "if len(triplet_records)==0:\n",
    "    raise RuntimeError(\"No valid triplets found in TrainingSetPath.jsonl\")\n",
    "\n",
    "# ---------------------------\n",
    "# 1) Contrastive / embedding evaluation\n",
    "# ---------------------------\n",
    "print(\"Running contrastive embedding evaluation...\")\n",
    "\n",
    "unique_paths = []\n",
    "path_to_idx = {}\n",
    "for rec in triplet_records:\n",
    "    for p in (rec[\"anchor\"], rec[\"positive\"]):\n",
    "        # represent a path as tuple of ints for uniqueness\n",
    "        key = tuple(int(x) for x in p)\n",
    "        if key not in path_to_idx:\n",
    "            path_to_idx[key] = len(unique_paths)\n",
    "            unique_paths.append(list(key))\n",
    "Npool = len(unique_paths)\n",
    "print(f\"Unique path pool size: {Npool}\")\n",
    "\n",
    "# compute embeddings in batches\n",
    "BATCH = 256\n",
    "pool_embs = []\n",
    "for i in tqdm(range(0, Npool, BATCH), desc=\"encoding pool paths\"):\n",
    "    batch_paths = unique_paths[i:i+BATCH]\n",
    "    t = paths_to_tensor(batch_paths, MAX_PATH_LENGTH, NODE_EMB_DIM).to(DEVICE)  # [b, L, Dnode]\n",
    "    with torch.no_grad():\n",
    "        he = encoder(t)  # [b, d_path]\n",
    "    pool_embs.append(he.cpu().numpy())\n",
    "pool_embs = np.vstack(pool_embs)  # [Npool, d_path]\n",
    "# normalize\n",
    "pool_embs_norm = pool_embs / (np.linalg.norm(pool_embs, axis=1, keepdims=True) + 1e-12)\n",
    "\n",
    "# Build index mapping for quick lookup\n",
    "def path_idx(path_list):\n",
    "    return path_to_idx[tuple(int(x) for x in path_list)]\n",
    "\n",
    "recalls_at = {1:0,3:0,5:0,10:0}\n",
    "mrr_list = []\n",
    "ap_list = []\n",
    "ranks = []\n",
    "for rec in tqdm(triplet_records, desc=\"ranking triplets\"):\n",
    "    anchor = rec[\"anchor\"]\n",
    "    positive = rec[\"positive\"]\n",
    "    idx_anchor = path_idx(anchor)\n",
    "    idx_positive = path_idx(positive)\n",
    "    # compute similarity of anchor to all pool items\n",
    "    sim = pool_embs_norm[idx_anchor:idx_anchor+1] @ pool_embs_norm.T  # [1, Npool]\n",
    "    sim = sim.ravel()\n",
    "    order = np.argsort(-sim)  # descending\n",
    "    # find rank (0-based)\n",
    "    rank_pos = int(np.where(order == idx_positive)[0][0])\n",
    "    ranks.append(rank_pos+1)\n",
    "    # Recall@k\n",
    "    for k in recalls_at.keys():\n",
    "        if rank_pos < k:\n",
    "            recalls_at[k] += 1\n",
    "    # MRR\n",
    "    mrr = 1.0 / (rank_pos + 1)\n",
    "    mrr_list.append(mrr)\n",
    "    ap = 1.0 if rank_pos < len(order) else 0.0\n",
    "    ap_list.append(ap)\n",
    "\n",
    "n_q = len(triplet_records)\n",
    "recall_at_k = {k: recalls_at[k] / n_q for k in recalls_at}\n",
    "mrr_mean = float(np.mean(mrr_list))\n",
    "map_score = float(np.mean(ap_list))\n",
    "\n",
    "# VICReg diagnostics on pool embeddings\n",
    "emb_tensor = torch.tensor(pool_embs, dtype=torch.float32)\n",
    "emb_mean = emb_tensor.mean(dim=0)\n",
    "var = emb_tensor.var(dim=0, unbiased=False).numpy()\n",
    "var_stats = {\"mean_var\": float(var.mean()), \"min_var\": float(var.min()), \"max_var\": float(var.max())}\n",
    "cov = np.cov(pool_embs, rowvar=False)\n",
    "cov_no_diag = cov.copy()\n",
    "np.fill_diagonal(cov_no_diag, 0.0)\n",
    "cov_offdiag_mean = float(np.mean(np.abs(cov_no_diag)))\n",
    "cov_offdiag_max = float(np.max(np.abs(cov_no_diag)))\n",
    "\n",
    "nn_records = []\n",
    "num_examples = min(200, n_q)\n",
    "for i, rec in enumerate(triplet_records[:num_examples]):\n",
    "    a_idx = path_idx(rec[\"anchor\"])\n",
    "    sims = pool_embs_norm[a_idx] @ pool_embs_norm.T\n",
    "    ords = np.argsort(-sims)[:10]\n",
    "    for rank, cand in enumerate(ords[:5], start=1):\n",
    "        nn_records.append({\n",
    "            \"anchor_idx\": a_idx,\n",
    "            \"anchor_path\": unique_paths[a_idx],\n",
    "            \"rank\": rank,\n",
    "            \"candidate_idx\": int(cand),\n",
    "            \"candidate_path\": unique_paths[int(cand)],\n",
    "            \"sim\": float(sims[int(cand)]),\n",
    "            \"is_positive\": int(int(cand) == path_idx(rec[\"positive\"]))\n",
    "        })\n",
    "nn_df = pd.DataFrame(nn_records)\n",
    "nn_df.to_csv(EVAL_OUT_DIR / \"nearest_neighbors_sample.csv\", index=False)\n",
    "\n",
    "embedding_eval = {\n",
    "    \"n_queries\": n_q,\n",
    "    \"pool_size\": Npool,\n",
    "    \"recall_at_k\": recall_at_k,\n",
    "    \"mrr_mean\": mrr_mean,\n",
    "    \"map_one_positive\": map_score,\n",
    "    \"vicreg\": {\"var_stats\": var_stats, \"cov_offdiag_mean\": cov_offdiag_mean, \"cov_offdiag_max\": cov_offdiag_max}\n",
    "}\n",
    "(EVAL_OUT_DIR / \"embedding_eval_summary.json\").write_text(json.dumps(embedding_eval, indent=2))\n",
    "print(\"Saved embedding evaluation summary.\")\n",
    "\n",
    "# Save simple histogram of ranks\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(ranks, bins=50)\n",
    "plt.xlabel(\"Rank of true positive (1 = top)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of ranks for positive among pool\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(EVAL_OUT_DIR / \"rank_distribution.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "# ---------------------------\n",
    "# 2) Regression / aggregator evaluation\n",
    "# ---------------------------\n",
    "print(\"Running regression aggregator evaluation...\")\n",
    "\n",
    "true_vals = []\n",
    "pred_vals = []\n",
    "meta_rows = []\n",
    "\n",
    "BATCH = 64\n",
    "for rec in tqdm(lpa_rows, desc=\"encoding LPA samples\"):\n",
    "    paths = rec.get(\"paths\") or rec.get(\"path_list\") or rec.get(\"path\")\n",
    "    if paths is None or len(paths)==0:\n",
    "        continue\n",
    "    t = paths_to_tensor(paths, MAX_PATH_LENGTH, NODE_EMB_DIM).to(DEVICE)  # [m, L, Dnode]\n",
    "    with torch.no_grad():\n",
    "        p_embs = encoder(t)  # [m, d_path]\n",
    "        # aggregator expects tensor [m, d_path] (it supports single sample)\n",
    "        pred = aggregator(p_embs, None)\n",
    "    pred_val = float(pred.cpu().numpy().item())\n",
    "    true_val = float(rec.get(\"trueindirectscore\", rec.get(\"target\", 0.0)))\n",
    "    pred_vals.append(pred_val)\n",
    "    true_vals.append(true_val)\n",
    "    meta_rows.append({\"i\": rec.get(\"i\"), \"j\": rec.get(\"j\"), \"graph_id\": rec.get(\"graph_id\"), \"pred\": pred_val, \"true\": true_val})\n",
    "\n",
    "pred_vals = np.array(pred_vals)\n",
    "true_vals = np.array(true_vals)\n",
    "\n",
    "mse = mean_squared_error(true_vals, pred_vals)\n",
    "mae = mean_absolute_error(true_vals, pred_vals)\n",
    "# Huber approx: use delta = 0.01 default\n",
    "delta = 0.01\n",
    "abs_err = np.abs(pred_vals - true_vals)\n",
    "huber = np.where(abs_err <= delta, 0.5 * abs_err**2, delta * abs_err - 0.5 * delta**2).mean()\n",
    "# correlations\n",
    "pearson_r = pearsonr(true_vals, pred_vals)[0] if len(true_vals)>1 else None\n",
    "spearman_r = spearmanr(true_vals, pred_vals).correlation if len(true_vals)>1 else None\n",
    "\n",
    "# calibration: reliability bins\n",
    "def compute_reliability(probs, labels, n_bins=15):\n",
    "    bins = np.linspace(0.0,1.0,n_bins+1)\n",
    "    centers=[]\n",
    "    accs=[]\n",
    "    counts=[]\n",
    "    for i in range(n_bins):\n",
    "        lo, hi = bins[i], bins[i+1]\n",
    "        if i < n_bins-1:\n",
    "            mask = (probs>=lo)&(probs<hi)\n",
    "        else:\n",
    "            mask = (probs>=lo)&(probs<=hi)\n",
    "        if mask.sum()==0:\n",
    "            centers.append((lo+hi)/2)\n",
    "            accs.append(np.nan)\n",
    "            counts.append(0)\n",
    "        else:\n",
    "            centers.append(probs[mask].mean())\n",
    "            accs.append(labels[mask].mean())\n",
    "            counts.append(int(mask.sum()))\n",
    "    return {\"centers\": centers, \"accs\": accs, \"counts\": counts}\n",
    "\n",
    "reliability = compute_reliability(pred_vals, true_vals, n_bins=15)\n",
    "\n",
    "regression_eval = {\n",
    "    \"n_samples\": int(len(true_vals)),\n",
    "    \"mse\": float(mse),\n",
    "    \"mae\": float(mae),\n",
    "    \"huber\": float(huber),\n",
    "    \"pearson_r\": None if pearson_r is None else float(pearson_r),\n",
    "    \"spearman_r\": None if spearman_r is None else float(spearman_r),\n",
    "    \"reliability\": reliability\n",
    "}\n",
    "(EVAL_OUT_DIR / \"regression_eval_summary.json\").write_text(json.dumps(regression_eval, indent=2))\n",
    "print(\"Saved regression evaluation summary.\")\n",
    "\n",
    "# scatter plot pred vs true\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(true_vals, pred_vals, alpha=0.4, s=8)\n",
    "mn = min(true_vals.min(), pred_vals.min())\n",
    "mx = max(true_vals.max(), pred_vals.max())\n",
    "plt.plot([mn, mx], [mn, mx], 'k--')\n",
    "plt.xlabel(\"True indirect score\")\n",
    "plt.ylabel(\"Predicted indirect score\")\n",
    "plt.title(\"Aggregator: predicted vs true\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(EVAL_OUT_DIR / \"pred_vs_true_scatter.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "# reliability diagram (binned)\n",
    "centers = reliability[\"centers\"]\n",
    "accs = reliability[\"accs\"]\n",
    "counts = reliability[\"counts\"]\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.plot(centers, accs, marker='o')\n",
    "for c, x, y in zip(counts, centers, accs):\n",
    "    if c>0:\n",
    "        plt.text(x, y, str(c), fontsize=8, alpha=0.6)\n",
    "plt.xlabel(\"Predicted (bin mean)\")\n",
    "plt.ylabel(\"True (bin mean)\")\n",
    "plt.title(\"Reliability diagram (aggregator predictions)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(EVAL_OUT_DIR / \"reliability_aggregator.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "# save per-sample predictions csv\n",
    "meta_df = pd.DataFrame(meta_rows)\n",
    "meta_df.to_csv(EVAL_OUT_DIR / \"aggregator_predictions.csv\", index=False)\n",
    "\n",
    "# Save combined summary\n",
    "summary = {\n",
    "    \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()),\n",
    "    \"embedding_eval\": embedding_eval,\n",
    "    \"regression_eval\": regression_eval,\n",
    "    \"paths_pool_size\": Npool,\n",
    "    \"n_triplets\": n_q\n",
    "}\n",
    "(EVAL_OUT_DIR / \"lpa_full_eval_summary.json\").write_text(json.dumps(summary, indent=2))\n",
    "print(\"Saved overall evaluation summary to\", EVAL_OUT_DIR / \"lpa_full_eval_summary.json\")\n",
    "\n",
    "print(\"Evaluation finished. Outputs directory:\", EVAL_OUT_DIR.resolve())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
