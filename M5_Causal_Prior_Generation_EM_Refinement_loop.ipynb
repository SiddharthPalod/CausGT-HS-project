{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9745952",
   "metadata": {},
   "source": [
    "## (c). EM-Refinement loop (The continuation of thea earlier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488b1534",
   "metadata": {},
   "source": [
    "### A. E-step (Expectation / Pseudo-Label Estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461146ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "GLOBAL_SEED = 20251127\n",
    "random.seed(GLOBAL_SEED)\n",
    "np.random.seed(GLOBAL_SEED)\n",
    "torch.manual_seed(GLOBAL_SEED)\n",
    "\n",
    "REAL_CORPUS_DIR = Path(\"real_corpus\")        \n",
    "E_PRIOR_PATH = Path(\"e_prior.jsonl\")           \n",
    "DCORPUS_DIR = Path(\"d_corpus_output\")        \n",
    "G_TRUE_PATH = Path(\"graphs/G_true.gpickle\")     # ground-truth graph\n",
    "OUT_DIR = Path(\"out/e_step\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Fusion artifacts (from earlier training)\n",
    "FUSION_MODEL_DIR = Path(\"out/fusion/model_bundle\")\n",
    "CLASSIFIER_PATH = FUSION_MODEL_DIR / \"classifier.txt\"\n",
    "RANKER_PATH = FUSION_MODEL_DIR / \"ranker.txt\"\n",
    "CALIBRATOR_PATH = FUSION_MODEL_DIR / \"calibrator.pkl\"\n",
    "FEATURE_SCHEMA_PATH = FUSION_MODEL_DIR / \"feature_schema.json\"\n",
    "\n",
    "# LPA artifacts\n",
    "LPA_MODEL_DIR = Path(\"out/lpa_model\")\n",
    "LPA_ENCODER_PTH = LPA_MODEL_DIR / \"encoder_finetuned.pth\"\n",
    "LPA_AGG_PTH = LPA_MODEL_DIR / \"aggregator_finetuned.pth\"\n",
    "LPA_BUNDLE_JSON = LPA_MODEL_DIR / \"lpa_model_bundle.json\"\n",
    "\n",
    "# fembed artifacts\n",
    "FEMBED_DIR = Path(\"models/fembed_sota\")\n",
    "\n",
    "# Gemini LLM wrapper config\n",
    "USE_GEMINI = True\n",
    "MODEL_CANDIDATES = [\n",
    "    \"gemini-2.5-flash-lite\",\n",
    "    \"gemini-2.5-flash\",\n",
    "    \"gemini-2.0-flash-lite\",\n",
    "]\n",
    "LLM_DELAY = 15.0\n",
    "MAX_LLM_ATTEMPTS_PER_MODEL = 2\n",
    "\n",
    "# E-step parameters\n",
    "MAX_PATH_CUTOFF = 4\n",
    "NULL_SAMPLES_PER_PAIR = 200\n",
    "P_VALUE_SEED_OFFSET = 1000000\n",
    "W_MIN = 0.01\n",
    "\n",
    "# Output files\n",
    "C_PRIOR_OUTPUT = OUT_DIR / \"C_prior_round_1.jsonl\"\n",
    "DDISTILL_OUTPUT = OUT_DIR / \"Ddistill_round1.jsonl\"\n",
    "SUMMARY_OUTPUT = OUT_DIR / \"E_step_round_1_summary.json\"\n",
    "\n",
    "# ----------------------------\n",
    "# Validations\n",
    "# ----------------------------\n",
    "required_paths = [\n",
    "    E_PRIOR_PATH,\n",
    "    DCORPUS_DIR,\n",
    "    G_TRUE_PATH,\n",
    "    CLASSIFIER_PATH,\n",
    "    RANKER_PATH,\n",
    "    CALIBRATOR_PATH,\n",
    "    FEATURE_SCHEMA_PATH,\n",
    "    LPA_ENCODER_PTH,\n",
    "    LPA_AGG_PTH,\n",
    "    LPA_BUNDLE_JSON,\n",
    "    FEMBED_DIR,\n",
    "]\n",
    "for p in required_paths:\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"Required path missing: {p}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Gemini wrapper\n",
    "# ----------------------------\n",
    "try:\n",
    "    import google.generativeai as genai\n",
    "except Exception:\n",
    "    genai = None\n",
    "\n",
    "class GeminiClientStrict:\n",
    "    def __init__(self, models: List[str], attempts_per_model: int = 2, llm_delay: float = 15.0):\n",
    "        if genai is None:\n",
    "            raise ImportError(\"google.generativeai not available\")\n",
    "        self.models = models\n",
    "        self.attempts = attempts_per_model\n",
    "        self.delay = llm_delay\n",
    "\n",
    "    def _sleep(self):\n",
    "        time.sleep(self.delay)\n",
    "\n",
    "    def _try_model_call(self, model: str, prompt: str, temperature: float = 0.0, max_tokens: int = 128) -> Optional[str]:\n",
    "        attempts = 0\n",
    "        while attempts < self.attempts:\n",
    "            attempts += 1\n",
    "            self._sleep()\n",
    "            try:\n",
    "                resp = genai.generate_text(model=model, prompt=prompt, temperature=temperature, max_output_tokens=max_tokens)\n",
    "                if resp is None:\n",
    "                    continue\n",
    "                if isinstance(resp, dict):\n",
    "                    cands = resp.get(\"candidates\", [])\n",
    "                    if cands:\n",
    "                        content = cands[0].get(\"content\")\n",
    "                        if content:\n",
    "                            return str(content).strip()\n",
    "                else:\n",
    "                    cands = getattr(resp, \"candidates\", None)\n",
    "                    if isinstance(cands, list) and len(cands) > 0:\n",
    "                        content = cands[0].get(\"content\") if isinstance(cands[0], dict) else getattr(cands[0], \"content\", None)\n",
    "                        if content:\n",
    "                            return str(content).strip()\n",
    "            except Exception:\n",
    "                time.sleep(0.5 * attempts)\n",
    "                continue\n",
    "        return None\n",
    "\n",
    "    def generate_text(self, prompt: str, temperature: float = 0.0, max_tokens: int = 128) -> str:\n",
    "        for m in self.models:\n",
    "            out = self._try_model_call(m, prompt, temperature=temperature, max_tokens=max_tokens)\n",
    "            if out is not None:\n",
    "                return out\n",
    "        raise RuntimeError(\"All Gemini models failed\")\n",
    "\n",
    "# ----------------------------\n",
    "# Load models & artifacts\n",
    "# ----------------------------\n",
    "clf = lgb.Booster(model_file=str(CLASSIFIER_PATH))\n",
    "ranker = lgb.Booster(model_file=str(RANKER_PATH))\n",
    "calibrator = joblib.load(CALIBRATOR_PATH)\n",
    "feature_schema = json.loads(FEATURE_SCHEMA_PATH.read_text(encoding=\"utf8\"))\n",
    "feature_cols = feature_schema[\"feature_order\"]\n",
    "\n",
    "# f_embed loader (backbone only)\n",
    "fembed_cfg = json.loads((FEMBED_DIR / \"config.json\").read_text(encoding=\"utf8\"))\n",
    "backbone_name = fembed_cfg.get(\"backbone\", \"all-MiniLM-L6-v2\")\n",
    "fembed = SentenceTransformer(backbone_name)\n",
    "fembed.max_seq_length = 256\n",
    "\n",
    "# LPA model definitions \n",
    "class PathTransformerEncoder(nn.Module):\n",
    "    def __init__(self, node_emb_dim: int, d_model: int = 256, nhead: int = 8, num_layers: int = 4, dim_feedforward: int = 512, d_path: int = 256, max_len: int = 32):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(node_emb_dim, d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward, batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.pos_emb = nn.Embedding(max_len, d_model)\n",
    "        self.pool = nn.Linear(d_model, d_path)\n",
    "        self.norm = nn.LayerNorm(d_path)\n",
    "        self.max_len = max_len\n",
    "    def forward(self, x):\n",
    "        B, L, _ = x.shape\n",
    "        pos_ids = torch.arange(L, device=x.device).unsqueeze(0).expand(B, -1)\n",
    "        x = self.input_proj(x) + self.pos_emb(pos_ids)\n",
    "        x = self.transformer(x)\n",
    "        x_mean = x.mean(dim=1)\n",
    "        h = self.pool(x_mean)\n",
    "        h = self.norm(h)\n",
    "        return h\n",
    "\n",
    "class AttentionAggregator(nn.Module):\n",
    "    def __init__(self, d_path: int = 256, path_feat_dim: int = 8, hidden_dim: int = 256):\n",
    "        super().__init__()\n",
    "        self.path_feat_proj = nn.Linear(path_feat_dim, d_path) if path_feat_dim>0 else None\n",
    "        self.att_mlp = nn.Sequential(nn.Linear(d_path*2 if self.path_feat_proj is not None else d_path, hidden_dim), nn.GELU(), nn.Linear(hidden_dim,1))\n",
    "        self.head = nn.Sequential(nn.Linear(d_path+4, hidden_dim), nn.GELU(), nn.Linear(hidden_dim,1))\n",
    "    def forward(self, path_embs, path_feats=None):\n",
    "        single=False\n",
    "        if path_embs.dim()==2:\n",
    "            path_embs = path_embs.unsqueeze(0); single=True\n",
    "        B,m,d = path_embs.shape\n",
    "        if self.path_feat_proj is not None and path_feats is not None:\n",
    "            pf = self.path_feat_proj(path_feats)\n",
    "            att_in = torch.cat([path_embs, pf], dim=-1)\n",
    "        else:\n",
    "            att_in = path_embs\n",
    "        logits = self.att_mlp(att_in).squeeze(-1)\n",
    "        att = torch.softmax(logits, dim=-1)\n",
    "        agg = (att.unsqueeze(-1) * path_embs).sum(dim=1)\n",
    "        num_paths = torch.tensor([m], device=path_embs.device, dtype=torch.float32).expand(B).unsqueeze(-1)\n",
    "        stats_cat = torch.cat([num_paths, torch.zeros((B,3), device=path_embs.device)], dim=-1)\n",
    "        head_in = torch.cat([agg, stats_cat], dim=-1)\n",
    "        out = torch.sigmoid(self.head(head_in).squeeze(-1))\n",
    "        if single:\n",
    "            return out.squeeze(0)\n",
    "        return out\n",
    "\n",
    "lpa_bundle = json.loads(LPA_BUNDLE_JSON.read_text(encoding=\"utf8\"))\n",
    "MAX_PATH_LENGTH = int(lpa_bundle.get(\"config\", {}).get(\"MAX_PATH_LENGTH\", 32))\n",
    "D_PATH = int(lpa_bundle.get(\"config\", {}).get(\"D_PATH\", 256))\n",
    "NODE_EMB_DIM = int(lpa_bundle.get(\"config\", {}).get(\"NODE_EMB_DIM\", 768))\n",
    "\n",
    "encoder = PathTransformerEncoder(node_emb_dim=NODE_EMB_DIM, d_path=D_PATH, max_len=MAX_PATH_LENGTH)\n",
    "aggregator = AttentionAggregator(d_path=D_PATH, path_feat_dim=8, hidden_dim=256)\n",
    "enc_ckpt = torch.load(LPA_ENCODER_PTH, map_location=\"cpu\")\n",
    "if \"encoder_state\" in enc_ckpt:\n",
    "    encoder.load_state_dict(enc_ckpt[\"encoder_state\"])\n",
    "else:\n",
    "    encoder.load_state_dict(enc_ckpt)\n",
    "agg_ckpt = torch.load(LPA_AGG_PTH, map_location=\"cpu\")\n",
    "if \"aggregator_state\" in agg_ckpt:\n",
    "    aggregator.load_state_dict(agg_ckpt[\"aggregator_state\"])\n",
    "else:\n",
    "    aggregator.load_state_dict(agg_ckpt)\n",
    "encoder.eval()\n",
    "aggregator.eval()\n",
    "\n",
    "# ----------------------------\n",
    "# Helpers\n",
    "# ----------------------------\n",
    "def safe_jsonl_writer(p: Path):\n",
    "    return open(p, \"w\", encoding=\"utf8\")\n",
    "\n",
    "def node_identifier(n: int) -> str:\n",
    "    return f\"N{int(n)}\"\n",
    "\n",
    "def load_d_corpus_entities(dcorpus_dir: Path) -> Dict[str, Dict[int, Dict[str,Any]]]:\n",
    "    ent_map: Dict[str, Dict[int,Dict[str,Any]]] = {}\n",
    "    files = sorted(dcorpus_dir.glob(\"*.jsonl\"))\n",
    "    for f in files:\n",
    "        with f.open(\"r\", encoding=\"utf8\") as fh:\n",
    "            for ln in fh:\n",
    "                rec = json.loads(ln)\n",
    "                ents = rec.get(\"entities\", {})\n",
    "                gid = rec.get(\"graph_id\", \"unknown\")\n",
    "                if gid not in ent_map:\n",
    "                    ent_map[gid] = {}\n",
    "                for k, v in ents.items():\n",
    "                    try:\n",
    "                        if k.startswith(\"N\"):\n",
    "                            nid = int(k[1:])\n",
    "                        else:\n",
    "                            nid = int(k)\n",
    "                    except Exception:\n",
    "                        continue\n",
    "                    if nid not in ent_map[gid]:\n",
    "                        ent_map[gid][nid] = v\n",
    "    return ent_map\n",
    "\n",
    "def compute_structural_features(G: nx.DiGraph, i: int, j: int, max_hops: int = MAX_PATH_CUTOFF) -> Dict[str,Any]:\n",
    "    features = {}\n",
    "    features[\"isdirect\"] = 1 if G.has_edge(i, j) else 0\n",
    "    features[\"deg_i\"] = int(G.degree(i))\n",
    "    features[\"deg_j\"] = int(G.degree(j))\n",
    "    features[\"in_deg_i\"] = int(G.in_degree(i))\n",
    "    features[\"out_deg_i\"] = int(G.out_degree(i))\n",
    "    features[\"in_deg_j\"] = int(G.in_degree(j))\n",
    "    features[\"out_deg_j\"] = int(G.out_degree(j))\n",
    "    try:\n",
    "        paths = list(nx.all_simple_paths(G, source=i, target=j, cutoff=max_hops))\n",
    "    except Exception:\n",
    "        paths = []\n",
    "    features[\"num_paths_upto_k\"] = len(paths)\n",
    "    if len(paths) > 0:\n",
    "        lengths = [len(p)-1 for p in paths]\n",
    "        features[\"avg_path_len\"] = float(sum(lengths)/len(lengths))\n",
    "    else:\n",
    "        features[\"avg_path_len\"] = 0.0\n",
    "    features[\"avg_path_internal_deg\"] = 0.0\n",
    "    try:\n",
    "        gen = nx.algorithms.connectivity.disjoint_paths.node_disjoint_paths(G, i, j)\n",
    "        count = 0\n",
    "        for _ in gen:\n",
    "            count += 1\n",
    "            if count >= 4:\n",
    "                break\n",
    "        features[\"k_node_disjoint_paths\"] = int(count)\n",
    "    except Exception:\n",
    "        features[\"k_node_disjoint_paths\"] = 0\n",
    "    return features\n",
    "\n",
    "def assemble_vij_from_struct(i:int, j:int, G: nx.DiGraph, rec_meta: Dict[str,Any], pos_score: float, neg_score: float, path_nodes: List[int]) -> Dict[str,Any]:\n",
    "    structural = compute_structural_features(G, i, j)\n",
    "    mu_LLM = float(pos_score)\n",
    "    var_LLM = float((pos_score - neg_score)**2)\n",
    "    mu_LLM_cond = mu_LLM\n",
    "    var_LLM_cond = var_LLM\n",
    "    p_plaus = float(rec_meta.get(\"p_plaus\", 0.0))\n",
    "    p_temp = float(rec_meta.get(\"p_temp\", 0.0))\n",
    "    p_mech = float(rec_meta.get(\"p_mech\", 0.0))\n",
    "    if path_nodes:\n",
    "        unique_nodes = list(set(path_nodes))\n",
    "        degs = [G.degree(n) for n in unique_nodes]\n",
    "        sgae = float(np.mean(degs)) if degs else 0.0\n",
    "    else:\n",
    "        sgae = 0.0\n",
    "    feat = {\n",
    "        \"deg_i\": structural[\"deg_i\"],\n",
    "        \"deg_j\": structural[\"deg_j\"],\n",
    "        \"in_deg_i\": structural[\"in_deg_i\"],\n",
    "        \"out_deg_i\": structural[\"out_deg_i\"],\n",
    "        \"in_deg_j\": structural[\"in_deg_j\"],\n",
    "        \"out_deg_j\": structural[\"out_deg_j\"],\n",
    "        \"num_paths_upto_k\": structural[\"num_paths_upto_k\"],\n",
    "        \"avg_path_len\": structural[\"avg_path_len\"],\n",
    "        \"avg_path_internal_deg\": structural[\"avg_path_internal_deg\"],\n",
    "        \"kdisjoint\": structural[\"k_node_disjoint_paths\"],\n",
    "        \"mu_LLM\": mu_LLM,\n",
    "        \"var_LLM\": var_LLM,\n",
    "        \"mu_LLM_cond\": mu_LLM_cond,\n",
    "        \"var_LLM_cond\": var_LLM_cond,\n",
    "        \"p_plaus\": p_plaus,\n",
    "        \"p_temp\": p_temp,\n",
    "        \"p_mech\": p_mech,\n",
    "        \"SGAE\": sgae,\n",
    "        \"path_node_count\": len(path_nodes),\n",
    "        \"pos_neg_diff\": pos_score - neg_score\n",
    "    }\n",
    "    # ensure ordering consistent\n",
    "    ordered = {c: float(feat.get(c, 0.0)) for c in feature_cols}\n",
    "    return ordered\n",
    "\n",
    "def paths_to_node_embeddings(paths: List[List[int]], node_entity_map: Dict[int,Dict[str,Any]], batch_size:int=64):\n",
    "    path_vecs = []\n",
    "    for p in paths:\n",
    "        texts = []\n",
    "        for n in p:\n",
    "            ent = node_entity_map.get(int(n))\n",
    "            if ent is not None:\n",
    "                texts.append(ent.get(\"description\",\"\") or ent.get(\"name\",\"\"))\n",
    "            else:\n",
    "                texts.append(\"\")\n",
    "        if len(texts) == 0:\n",
    "            arr = np.zeros((MAX_PATH_LENGTH, NODE_EMB_DIM), dtype=np.float32)\n",
    "            path_vecs.append(arr)\n",
    "            continue\n",
    "        texts = texts[:MAX_PATH_LENGTH]\n",
    "        if len(texts) < MAX_PATH_LENGTH:\n",
    "            texts = texts + [\"\"] * (MAX_PATH_LENGTH - len(texts))\n",
    "        embs = fembed.encode(texts, convert_to_numpy=True, show_progress_bar=False)\n",
    "        if embs.shape[1] != NODE_EMB_DIM:\n",
    "            if embs.shape[1] < NODE_EMB_DIM:\n",
    "                padw = NODE_EMB_DIM - embs.shape[1]\n",
    "                embs = np.pad(embs, ((0,0),(0,padw)))\n",
    "            else:\n",
    "                embs = embs[:,:NODE_EMB_DIM]\n",
    "        path_vecs.append(embs.astype(np.float32))\n",
    "    return np.stack(path_vecs, axis=0)  # [num_paths, L, node_dim]\n",
    "\n",
    "def encode_paths_with_lpa(paths: List[List[int]], node_entity_map: Dict[int,Dict[str,Any]]):\n",
    "    arr = paths_to_node_embeddings(paths, node_entity_map)\n",
    "    t = torch.tensor(arr, dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        h = encoder(t)  # [num_paths, d_path]\n",
    "    return h.cpu().numpy().tolist()\n",
    "\n",
    "def compute_fusion_score_from_models(v_ordered: Dict[str, float]):\n",
    "    x = np.array([v_ordered[c] for c in feature_cols], dtype=float).reshape(1, -1)\n",
    "    raw_clf = float(clf.predict(x, raw_score=True))\n",
    "    raw_rank = float(ranker.predict(x, raw_score=True))\n",
    "    classifier_weight = float(feature_schema.get(\"classifier_weight\", 0.7))\n",
    "    rank_weight = float(feature_schema.get(\"rank_weight\", 0.3))\n",
    "    combined_raw = classifier_weight * raw_clf + rank_weight * raw_rank\n",
    "    p_raw = 1.0 / (1.0 + math.exp(-combined_raw))\n",
    "    p_cal = float(calibrator.transform([p_raw])[0]) if isinstance(calibrator, IsotonicRegression) else p_raw\n",
    "    return {\"raw_clf\": raw_clf, \"raw_rank\": raw_rank, \"p_raw\": p_raw, \"p_cal\": p_cal}\n",
    "\n",
    "def empirical_p_value_for_pair(i:int, j:int, G: nx.DiGraph, node_entity_map: Dict[int,Dict[str,Any]], rec_meta: Dict[str,Any], pos_score: float, neg_score: float, null_B: int, seed_base:int):\n",
    "    rng = random.Random(seed_base + (i * 1315423911) ^ (j * 2654435761))\n",
    "    T_obs = compute_fusion_score_from_models(assemble_vij_from_struct(i,j,G,rec_meta,pos_score,neg_score, []))[\"p_cal\"]\n",
    "    nulls = []\n",
    "    nodes = list(G.nodes())\n",
    "    degs = {n:int(G.degree(n)) for n in nodes}\n",
    "    all_degs = sorted(set(degs.values()))\n",
    "    deg = degs.get(j, 0)\n",
    "    # find bucket\n",
    "    buckets = {d: [n for n in nodes if degs[n]==d] for d in all_degs}\n",
    "    # if exact bucket empty, sample uniformly\n",
    "    for b in range(null_B):\n",
    "        bucket = buckets.get(deg)\n",
    "        if bucket:\n",
    "            jb = rng.choice(bucket)\n",
    "        else:\n",
    "            jb = rng.choice(nodes)\n",
    "        vj = assemble_vij_from_struct(i, jb, G, rec_meta, pos_score, neg_score, [])\n",
    "        s = compute_fusion_score_from_models(vj)[\"p_cal\"]\n",
    "        nulls.append(s)\n",
    "    p_val = (1.0 + sum(1 for t in nulls if t >= T_obs)) / (1.0 + len(nulls))\n",
    "    return p_val\n",
    "\n",
    "# ----------------------------\n",
    "# Load inputs: E_prior & node entity maps & G_true\n",
    "# ----------------------------\n",
    "G_true = nx.read_gpickle(G_TRUE_PATH)\n",
    "d_entities = load_d_corpus_entities(DCORPUS_DIR)\n",
    "with E_PRIOR_PATH.open(\"r\", encoding=\"utf8\") as fh:\n",
    "    e_prior = [json.loads(ln) for ln in fh if ln.strip()]\n",
    "\n",
    "# ----------------------------\n",
    "# E-step loop (round 1)\n",
    "# ----------------------------\n",
    "if USE_GEMINI:\n",
    "    gemini = GeminiClientStrict(models=MODEL_CANDIDATES, attempts_per_model=MAX_LLM_ATTEMPTS_PER_MODEL, llm_delay=LLM_DELAY)\n",
    "\n",
    "out_fh = safe_jsonl_writer(C_PRIOR_OUTPUT)\n",
    "ddistill_fh = safe_jsonl_writer(DDISTILL_OUTPUT)\n",
    "\n",
    "summary = {\"n_pairs\": 0, \"n_high_conf\": 0, \"p_hist\": []}\n",
    "pair_count = 0\n",
    "\n",
    "for rec in e_prior:\n",
    "    pair_count += 1\n",
    "    i = int(rec[\"i\"]); j = int(rec[\"j\"])\n",
    "    graph_id = rec.get(\"graph_id\", \"G_true\")\n",
    "    node_map = d_entities.get(graph_id, {})\n",
    "    # paths\n",
    "    try:\n",
    "        paths = list(nx.all_simple_paths(G_true, source=i, target=j, cutoff=MAX_PATH_CUTOFF))\n",
    "    except Exception:\n",
    "        paths = []\n",
    "    # path nodes flatten\n",
    "    path_nodes_flat = []\n",
    "    for p in paths:\n",
    "        for n in p:\n",
    "            path_nodes_flat.append(int(n))\n",
    "    # create rec_meta baseline from D_corpus if available\n",
    "    rec_meta = {}\n",
    "    # assemble v_ij\n",
    "    v_ordered = assemble_vij_from_struct(i, j, G_true, rec_meta, pos_score=0.5, neg_score=0.0, path_nodes=path_nodes_flat)\n",
    "    # compute path embeddings\n",
    "    if len(paths) == 0:\n",
    "        path_embeddings = []\n",
    "    else:\n",
    "        path_embeddings = encode_paths_with_lpa(paths, node_map)\n",
    "    # fusion score\n",
    "    fusion_scores = compute_fusion_score_from_models(v_ordered)\n",
    "    finalscore = fusion_scores[\"p_cal\"]\n",
    "    # compute p-value empirically\n",
    "    p_val = empirical_p_value_for_pair(i, j, G_true, node_map, rec_meta, pos_score=0.5, neg_score=0.0, null_B=NULL_SAMPLES_PER_PAIR, seed_base=P_VALUE_SEED_OFFSET)\n",
    "    # round 1: call Gemini for ÂµLLMcond\n",
    "    llm_cond_score = None\n",
    "    if USE_GEMINI:\n",
    "        prompt = (\n",
    "            \"Given a fusion feature vector and short metadata, return ONLY a JSON object \"\n",
    "            \"{\\\"score\\\":<float 0..1>, \\\"reason\\\":\\\"short\\\"} estimating how likely the pair \"\n",
    "            \"represents a causal direct relation. Feature dict:\\n\"\n",
    "            + json.dumps(v_ordered)\n",
    "        )\n",
    "        raw = gemini.generate_text(prompt, temperature=0.0, max_tokens=40)\n",
    "        start = raw.find(\"{\"); end = raw.rfind(\"}\")\n",
    "        if start != -1 and end != -1 and end>start:\n",
    "            try:\n",
    "                jj = json.loads(raw[start:end+1])\n",
    "                llm_cond_score = float(jj.get(\"score\", 0.0))\n",
    "            except Exception:\n",
    "                llm_cond_score = None\n",
    "        else:\n",
    "            raise RuntimeError(\"Gemini returned unparsable output for pair {} {}\".format(i,j))\n",
    "        # distillation pair\n",
    "        ddistill_fh.write(json.dumps({\"v\": v_ordered, \"t\": llm_cond_score}) + \"\\n\")\n",
    "    # C_prior record\n",
    "    c_record = {\n",
    "        \"i\": int(i),\n",
    "        \"j\": int(j),\n",
    "        \"graph_id\": graph_id,\n",
    "        \"domain\": rec.get(\"domain\", \"unknown\"),\n",
    "        \"finalscore\": float(finalscore),\n",
    "        \"p_value\": float(p_val),\n",
    "        \"v_ij\": v_ordered,\n",
    "        \"path_embeddings\": path_embeddings,\n",
    "        \"path_stats\": {\"num_paths\": len(paths), \"avg_path_len\": v_ordered.get(\"avg_path_len\",0.0)},\n",
    "        \"cpc\": {\"plaus\": v_ordered.get(\"p_plaus\", 0.0), \"temp\": v_ordered.get(\"p_temp\",0.0), \"mech\": v_ordered.get(\"p_mech\",0.0)},\n",
    "        \"meta\": {\"round\": 1, \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())}\n",
    "    }\n",
    "    if llm_cond_score is not None:\n",
    "        c_record[\"llm_conditional_score\"] = float(llm_cond_score)\n",
    "    out_fh.write(json.dumps(c_record) + \"\\n\")\n",
    "    summary[\"n_pairs\"] += 1\n",
    "    summary[\"p_hist\"].append(float(p_val))\n",
    "    if p_val < 0.05 and finalscore > 0.5:\n",
    "        summary[\"n_high_conf\"] += 1\n",
    "\n",
    "out_fh.close()\n",
    "ddistill_fh.close()\n",
    "SUMMARY_OUTPUT.write_text(json.dumps(summary, indent=2))\n",
    "print(\"E-step finished. Outputs:\")\n",
    "print(\"  C_prior:\", C_PRIOR_OUTPUT.resolve())\n",
    "print(\"  Ddistill:\", DDISTILL_OUTPUT.resolve())\n",
    "print(\"  summary:\", SUMMARY_OUTPUT.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84db39d7",
   "metadata": {},
   "source": [
    "### B. M-step (Maximisation / Student Update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8ff4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import json, math, random, time, os\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "import numpy as np\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "import joblib\n",
    "\n",
    "# -------------------- config --------------------\n",
    "GLOBAL_SEED = 20251127\n",
    "random.seed(GLOBAL_SEED); np.random.seed(GLOBAL_SEED); torch.manual_seed(GLOBAL_SEED)\n",
    "\n",
    "IN_DIR = Path(\"out/e_step\")\n",
    "C_PRIOR = IN_DIR / \"C_prior_round_1.jsonl\"\n",
    "DDISTILL = IN_DIR / \"Ddistill_round1.jsonl\"\n",
    "FEATURE_SCHEMA = Path(\"out/fusion/model_bundle/feature_schema.json\")\n",
    "LPA_BUNDLE_JSON = Path(\"out/lpa_model/lpa_model_bundle.json\")\n",
    "LPA_ENCODER_PTH = Path(\"out/lpa_model/encoder_finetuned.pth\")\n",
    "LPA_AGG_PTH = Path(\"out/lpa_model/aggregator_finetuned.pth\")\n",
    "\n",
    "OUT_DIR = Path(\"out/em_refinement\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TEACHER_OUT = OUT_DIR / \"teacher_models\"\n",
    "TEACHER_OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# hyperparams \n",
    "BATCH_SIZE = 512\n",
    "EPOCHS_FUSION = 5\n",
    "EPOCHS_LPA = 5\n",
    "EPOCHS_FSTUDENT = 10\n",
    "LR_FUSION = 3e-4\n",
    "LR_LPA = 1e-4\n",
    "LR_FSTUDENT = 1e-4\n",
    "LAMBDA_CONSIST = 0.1\n",
    "W_MIN = 0.01\n",
    "EMA_ALPHA = 0.999\n",
    "GRAD_CLIP = 1.0\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# -------------------- checks --------------------\n",
    "for p in [C_PRIOR, DDISTILL, FEATURE_SCHEMA, LPA_BUNDLE_JSON, LPA_ENCODER_PTH, LPA_AGG_PTH]:\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"Required file missing: {p}\")\n",
    "\n",
    "# -------------------- load feature schema --------------------\n",
    "feature_schema = json.loads(FEATURE_SCHEMA.read_text(encoding=\"utf8\"))\n",
    "FEATURE_COLS: List[str] = feature_schema[\"feature_order\"]\n",
    "D_IN = len(FEATURE_COLS)\n",
    "\n",
    "# -------------------- model definitions --------------------\n",
    "class FusionStudent(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden: int = 1024, out_dim: int = 1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden),\n",
    "            nn.GELU(),\n",
    "            nn.LayerNorm(hidden),\n",
    "            nn.Linear(hidden, hidden//2),\n",
    "            nn.GELU(),\n",
    "            nn.LayerNorm(hidden//2),\n",
    "            nn.Linear(hidden//2, out_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.net(x).squeeze(-1))\n",
    "\n",
    "class FStudentRegressor(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden1: int = 512, hidden2: int = 256):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden1),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden1, hidden2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden2, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(-1)\n",
    "\n",
    "# LPA encoder/aggregator must match the definitions used in E-step.\n",
    "class PathTransformerEncoder(nn.Module):\n",
    "    def __init__(self, node_emb_dim: int, d_model: int = 256, nhead: int = 8, num_layers: int = 4, dim_feedforward: int = 512, d_path: int = 256, max_len: int = 32):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(node_emb_dim, d_model)\n",
    "        enc_layer = nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward, batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(enc_layer, num_layers=num_layers)\n",
    "        self.pos_emb = nn.Embedding(max_len, d_model)\n",
    "        self.pool = nn.Linear(d_model, d_path)\n",
    "        self.norm = nn.LayerNorm(d_path)\n",
    "        self.max_len = max_len\n",
    "    def forward(self, x):\n",
    "        B,L,_ = x.shape\n",
    "        pos = torch.arange(L, device=x.device).unsqueeze(0).expand(B,-1)\n",
    "        x = self.input_proj(x) + self.pos_emb(pos)\n",
    "        x = self.transformer(x)\n",
    "        x_mean = x.mean(dim=1)\n",
    "        h = self.pool(x_mean)\n",
    "        h = self.norm(h)\n",
    "        return h\n",
    "\n",
    "class AttentionAggregator(nn.Module):\n",
    "    def __init__(self, d_path: int = 256, path_feat_dim: int = 8, hidden: int = 256):\n",
    "        super().__init__()\n",
    "        self.path_proj = nn.Linear(path_feat_dim, d_path) if path_feat_dim>0 else None\n",
    "        in_dim = d_path*2 if self.path_proj is not None else d_path\n",
    "        self.att_mlp = nn.Sequential(nn.Linear(in_dim, hidden), nn.GELU(), nn.Linear(hidden,1))\n",
    "        self.head = nn.Sequential(nn.Linear(d_path+4, hidden), nn.GELU(), nn.Linear(hidden,1))\n",
    "    def forward(self, path_embs, path_feats=None):\n",
    "        single=False\n",
    "        if path_embs.dim()==2:\n",
    "            path_embs = path_embs.unsqueeze(0); single=True\n",
    "        B,m,d = path_embs.shape\n",
    "        if self.path_proj is not None and path_feats is not None:\n",
    "            pf = self.path_proj(path_feats)\n",
    "            att_in = torch.cat([path_embs, pf], dim=-1)\n",
    "        else:\n",
    "            att_in = path_embs\n",
    "        logits = self.att_mlp(att_in).squeeze(-1)\n",
    "        att = torch.softmax(logits, dim=-1)\n",
    "        agg = (att.unsqueeze(-1) * path_embs).sum(dim=1)\n",
    "        num_paths = torch.tensor([m], device=path_embs.device, dtype=torch.float32).expand(B).unsqueeze(-1)\n",
    "        stats_cat = torch.cat([num_paths, torch.zeros((B,3), device=path_embs.device)], dim=-1)\n",
    "        head_in = torch.cat([agg, stats_cat], dim=-1)\n",
    "        out = torch.sigmoid(self.head(head_in).squeeze(-1))\n",
    "        if single:\n",
    "            return out.squeeze(0)\n",
    "        return out\n",
    "\n",
    "# -------------------- load LPA teacher -> student initializations --------------------\n",
    "lpa_bundle = json.loads(LPA_BUNDLE_JSON.read_text(encoding=\"utf8\"))\n",
    "NODE_EMB_DIM = int(lpa_bundle[\"config\"][\"NODE_EMB_DIM\"])\n",
    "D_PATH = int(lpa_bundle[\"config\"][\"D_PATH\"])\n",
    "MAX_PATH_LEN = int(lpa_bundle[\"config\"][\"MAX_PATH_LENGTH\"])\n",
    "\n",
    "lpa_teacher_encoder = PathTransformerEncoder(node_emb_dim=NODE_EMB_DIM, d_path=D_PATH, max_len=MAX_PATH_LEN).to(DEVICE)\n",
    "lpa_teacher_agg = AttentionAggregator(d_path=D_PATH, path_feat_dim=8, hidden=256).to(DEVICE)\n",
    "enc_ckpt = torch.load(LPA_ENCODER_PTH, map_location=\"cpu\")\n",
    "if \"encoder_state\" in enc_ckpt:\n",
    "    lpa_teacher_encoder.load_state_dict(enc_ckpt[\"encoder_state\"])\n",
    "else:\n",
    "    lpa_teacher_encoder.load_state_dict(enc_ckpt)\n",
    "agg_ckpt = torch.load(LPA_AGG_PTH, map_location=\"cpu\")\n",
    "if \"aggregator_state\" in agg_ckpt:\n",
    "    lpa_teacher_agg.load_state_dict(agg_ckpt[\"aggregator_state\"])\n",
    "else:\n",
    "    lpa_teacher_agg.load_state_dict(agg_ckpt)\n",
    "lpa_teacher_encoder.eval(); lpa_teacher_agg.eval()\n",
    "\n",
    "# create student copies\n",
    "lpa_student_encoder = PathTransformerEncoder(node_emb_dim=NODE_EMB_DIM, d_path=D_PATH, max_len=MAX_PATH_LEN).to(DEVICE)\n",
    "lpa_student_agg = AttentionAggregator(d_path=D_PATH, path_feat_dim=8, hidden=256).to(DEVICE)\n",
    "lpa_student_encoder.load_state_dict(lpa_teacher_encoder.state_dict())\n",
    "lpa_student_agg.load_state_dict(lpa_teacher_agg.state_dict())\n",
    "\n",
    "# fusion: create student and teacher networks (neural)\n",
    "fusion_teacher = FusionStudent(input_dim=D_IN).to(DEVICE)\n",
    "fusion_student = FusionStudent(input_dim=D_IN).to(DEVICE)\n",
    "# init teachers to students identical initially (teacher will be EMA-updated)\n",
    "fusion_teacher.load_state_dict(fusion_student.state_dict())\n",
    "\n",
    "# fstudent regressor\n",
    "fstudent = FStudentRegressor(input_dim=D_IN).to(DEVICE)\n",
    "fstudent_teacher = FStudentRegressor(input_dim=D_IN).to(DEVICE)\n",
    "fstudent_teacher.load_state_dict(fstudent.state_dict())\n",
    "\n",
    "# optimizers\n",
    "opt_fusion = optim.AdamW(fusion_student.parameters(), lr=LR_FUSION, weight_decay=1e-5)\n",
    "opt_lpa = optim.AdamW(list(lpa_student_encoder.parameters()) + list(lpa_student_agg.parameters()), lr=LR_LPA, weight_decay=1e-5)\n",
    "opt_fst = optim.AdamW(fstudent.parameters(), lr=LR_FSTUDENT, weight_decay=1e-5)\n",
    "\n",
    "bce_loss = nn.BCELoss(reduction=\"none\")\n",
    "mse_loss = nn.MSELoss(reduction=\"mean\")\n",
    "\n",
    "# -------------------- load C_prior --------------------\n",
    "records = []\n",
    "with C_PRIOR.open(\"r\", encoding=\"utf8\") as fh:\n",
    "    for ln in fh:\n",
    "        if not ln.strip(): continue\n",
    "        records.append(json.loads(ln))\n",
    "\n",
    "if len(records) == 0:\n",
    "    raise RuntimeError(\"No C_prior records found\")\n",
    "\n",
    "# assemble feature matrix, labels, weights, path data\n",
    "X_list = []\n",
    "y_soft = []\n",
    "y_bin = []\n",
    "w_list = []\n",
    "domains = []\n",
    "paths_list = []  \n",
    "for rec in records:\n",
    "    v = rec[\"v_ij\"]\n",
    "    x = np.array([float(v.get(c, 0.0)) for c in FEATURE_COLS], dtype=np.float32)\n",
    "    X_list.append(x)\n",
    "    fs = float(rec.get(\"finalscore\", 0.0))\n",
    "    p = float(rec.get(\"p_value\", 1.0))\n",
    "    w = max(W_MIN, 1.0 - p)\n",
    "    X_list[-1] = x\n",
    "    y_soft.append(np.float32(fs))\n",
    "    y_bin.append(np.float32(1.0 if fs > 0.0 else 0.0))\n",
    "    w_list.append(np.float32(w))\n",
    "    domains.append(rec.get(\"domain\",\"unknown\"))\n",
    "    pe = rec.get(\"path_embeddings\", [])\n",
    "    if pe and isinstance(pe, list):\n",
    "        pe_arr = [np.array(pv, dtype=np.float32) for pv in pe]\n",
    "    else:\n",
    "        pe_arr = []\n",
    "    paths_list.append(pe_arr)\n",
    "\n",
    "X = np.stack(X_list, axis=0)\n",
    "y_soft = np.array(y_soft, dtype=np.float32)\n",
    "y_bin = np.array(y_bin, dtype=np.float32)\n",
    "w_arr = np.array(w_list, dtype=np.float32)\n",
    "\n",
    "from collections import defaultdict\n",
    "idx_by_domain = defaultdict(list)\n",
    "for idx, dom in enumerate(domains):\n",
    "    idx_by_domain[dom].append(idx)\n",
    "domain_keys = sorted(idx_by_domain.keys())\n",
    "def domain_balanced_batches(batch_size, seed=GLOBAL_SEED):\n",
    "    rng = random.Random(seed)\n",
    "    all_idxs = list(range(len(X)))\n",
    "    cursors = {d:0 for d in domain_keys}\n",
    "    lens = {d: len(idx_by_domain[d]) for d in domain_keys}\n",
    "    domain_shuffled = {}\n",
    "    for d in domain_keys:\n",
    "        arr = idx_by_domain[d][:]\n",
    "        rng.shuffle(arr)\n",
    "        domain_shuffled[d] = arr\n",
    "    # round-robin sampling\n",
    "    batch = []\n",
    "    while True:\n",
    "        for d in domain_keys:\n",
    "            if len(batch) >= batch_size:\n",
    "                yield batch\n",
    "                batch = []\n",
    "            if lens[d]==0: continue\n",
    "            cur = cursors[d]\n",
    "            batch.append(domain_shuffled[d][cur % lens[d]])\n",
    "            cursors[d] = cur + 1\n",
    "        if len(batch) > 0:\n",
    "            yield batch\n",
    "            batch = []\n",
    "\n",
    "# -------------------- augmentation function --------------------\n",
    "def augment_batch_features(x_batch: np.ndarray, seed_offset: int = 0):\n",
    "    rng = np.random.RandomState(GLOBAL_SEED + seed_offset)\n",
    "    x_aug = x_batch.copy()\n",
    "    B, D = x_aug.shape\n",
    "    # dropout 10% of features per sample\n",
    "    drop_p = 0.1\n",
    "    mask = rng.rand(B, D) > drop_p\n",
    "    x_aug = x_aug * mask\n",
    "    # add small gaussian noise scaled to mean absolute feature\n",
    "    scale = 1e-2\n",
    "    noise = rng.normal(loc=0.0, scale=scale, size=x_aug.shape).astype(np.float32)\n",
    "    x_aug = x_aug + noise\n",
    "    return x_aug\n",
    "\n",
    "# -------------------- training fusion student --------------------\n",
    "fusion_student.train()\n",
    "n = len(X)\n",
    "bgen = domain_balanced_batches(BATCH_SIZE, seed=GLOBAL_SEED + 1)\n",
    "steps_per_epoch = math.ceil(n / BATCH_SIZE)\n",
    "for epoch in range(EPOCHS_FUSION):\n",
    "    total_loss = 0.0\n",
    "    for step in range(steps_per_epoch):\n",
    "        batch_idxs = next(bgen)\n",
    "        xb = torch.tensor(X[batch_idxs], dtype=torch.float32, device=DEVICE)\n",
    "        ys = torch.tensor(y_soft[batch_idxs], dtype=torch.float32, device=DEVICE)\n",
    "        ww = torch.tensor(w_arr[batch_idxs], dtype=torch.float32, device=DEVICE)\n",
    "        # augmentations\n",
    "        x_aug1 = torch.tensor(augment_batch_features(X[batch_idxs], seed_offset=epoch*1000 + step), dtype=torch.float32, device=DEVICE)\n",
    "        x_aug2 = torch.tensor(augment_batch_features(X[batch_idxs], seed_offset=epoch*2000 + step), dtype=torch.float32, device=DEVICE)\n",
    "        opt_fusion.zero_grad()\n",
    "        p = fusion_student(xb)\n",
    "        p1 = fusion_student(x_aug1)\n",
    "        p2 = fusion_student(x_aug2)\n",
    "        loss_pseudo = bce_loss(p, ys)  # per-element\n",
    "        loss_pseudo = (loss_pseudo * ww).mean()\n",
    "        loss_consist = ((p1 - p2)**2).mean()\n",
    "        loss = loss_pseudo + LAMBDA_CONSIST * loss_consist\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(fusion_student.parameters(), GRAD_CLIP)\n",
    "        opt_fusion.step()\n",
    "        total_loss += float(loss.detach().cpu().item())\n",
    "    print(f\"[fusion] epoch {epoch+1}/{EPOCHS_FUSION} loss {total_loss/steps_per_epoch:.6f}\")\n",
    "\n",
    "# -------------------- training LPA student --------------------\n",
    "lpa_student_encoder.train(); lpa_student_agg.train()\n",
    "# prepare path batches: we will batch by indices; pad to max_paths_in_batch and pad each path to MAX_PATH_LEN x NODE_EMB_DIM\n",
    "def collate_paths(batch_indices: List[int]):\n",
    "    batch_paths = [paths_list[i] for i in batch_indices]\n",
    "    # determine max number of paths\n",
    "    m = max((len(p) for p in batch_paths), default=0)\n",
    "    if m == 0:\n",
    "        arr = np.zeros((len(batch_indices),1, NODE_EMB_DIM), dtype=np.float32)\n",
    "        path_counts = np.zeros((len(batch_indices),), dtype=np.int32)\n",
    "        return arr, path_counts\n",
    "    # pad per path to MAX_PATH_LEN and per example to m\n",
    "    arrs = []\n",
    "    path_counts = []\n",
    "    for pvecs in batch_paths:\n",
    "        path_counts.append(len(pvecs))\n",
    "        # build array shape (m, MAX_PATH_LEN, NODE_EMB_DIM)\n",
    "        example = np.zeros((m, MAX_PATH_LEN, NODE_EMB_DIM), dtype=np.float32)\n",
    "        for pi, pv in enumerate(pvecs):\n",
    "            vec = pv\n",
    "            if vec.shape[0] != NODE_EMB_DIM:\n",
    "                # if different dim, pad or truncate\n",
    "                if vec.shape[0] < NODE_EMB_DIM:\n",
    "                    padw = NODE_EMB_DIM - vec.shape[0]\n",
    "                    vec = np.pad(vec, (0,padw)).astype(np.float32)\n",
    "                else:\n",
    "                    vec = vec[:NODE_EMB_DIM].astype(np.float32)\n",
    "            # repeat vec across MAX_PATH_LEN\n",
    "            example[pi, :, :] = np.tile(vec.reshape(1, -1), (MAX_PATH_LEN,1))\n",
    "        arrs.append(example)\n",
    "    return np.stack(arrs, axis=0), np.array(path_counts, dtype=np.int32)\n",
    "\n",
    "# training loop\n",
    "indices = list(range(len(X)))\n",
    "rng = random.Random(GLOBAL_SEED+2)\n",
    "for epoch in range(EPOCHS_LPA):\n",
    "    rng.shuffle(indices)\n",
    "    total_loss = 0.0\n",
    "    for s in range(0, len(indices), BATCH_SIZE):\n",
    "        batch_idxs = indices[s:s+BATCH_SIZE]\n",
    "        arr, counts = collate_paths(batch_idxs)\n",
    "        arr_t = torch.tensor(arr, dtype=torch.float32, device=DEVICE)  # [B, m, L, node_dim]\n",
    "        B_, m, L, node_dim = arr_t.shape\n",
    "        # collapse to [B*m, L, node_dim] and run encoder to get path embeddings (we'll average across m later)\n",
    "        arr_flat = arr_t.reshape(B_*m, L, node_dim)\n",
    "        with torch.no_grad():\n",
    "            # teacher may have been used to produce path embeddings earlier; here we re-encode via student\n",
    "            pass\n",
    "        # For memory reasons, encode in small batches, we're poor you see\n",
    "        batch_embs = []\n",
    "        batch_size_small = 64\n",
    "        for start in range(0, arr_flat.shape[0], batch_size_small):\n",
    "            chunk = arr_flat[start:start+batch_size_small]\n",
    "            he = lpa_student_encoder(chunk)  # [chunk, d_path]\n",
    "            batch_embs.append(he)\n",
    "        he_all = torch.cat(batch_embs, dim=0)\n",
    "        he_all = he_all.reshape(B_, m, -1)  # [B, m, d_path]\n",
    "        path_feats = torch.zeros((B_, m, 8), device=DEVICE)\n",
    "        preds = lpa_student_agg(he_all, path_feats)  # [B]\n",
    "        ys = torch.tensor(y_bin[batch_idxs], dtype=torch.float32, device=DEVICE)\n",
    "        ww = torch.tensor(w_arr[batch_idxs], dtype=torch.float32, device=DEVICE)\n",
    "        loss_pseudo = bce_loss(preds, ys)\n",
    "        loss_pseudo = (loss_pseudo * ww).mean()\n",
    "        drop_p = 0.2\n",
    "        rand = np.random.RandomState(GLOBAL_SEED + epoch)\n",
    "        mask = rand.rand(B_, m) > drop_p\n",
    "        he_aug1 = he_all.clone()\n",
    "        he_aug2 = he_all.clone()\n",
    "        he_aug1 = he_aug1 * torch.tensor(mask.astype(np.float32), device=DEVICE).unsqueeze(-1)\n",
    "        mask2 = rand.rand(B_, m) > drop_p\n",
    "        he_aug2 = he_aug2 * torch.tensor(mask2.astype(np.float32), device=DEVICE).unsqueeze(-1)\n",
    "        p1 = lpa_student_agg(he_aug1, path_feats)\n",
    "        p2 = lpa_student_agg(he_aug2, path_feats)\n",
    "        loss_cons = ((p1 - p2)**2).mean()\n",
    "        loss = loss_pseudo + LAMBDA_CONSIST * loss_cons\n",
    "        opt_lpa.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(list(lpa_student_encoder.parameters()) + list(lpa_student_agg.parameters()), GRAD_CLIP)\n",
    "        opt_lpa.step()\n",
    "        total_loss += float(loss.detach().cpu().item())\n",
    "    print(f\"[LPA] epoch {epoch+1}/{EPOCHS_LPA} loss {total_loss/ (max(1, math.ceil(len(indices)/BATCH_SIZE))):.6f}\")\n",
    "\n",
    "# -------------------- training fstudent (distillation) --------------------\n",
    "# load distill pairs\n",
    "d_pairs = []\n",
    "with DDISTILL.open(\"r\", encoding=\"utf8\") as fh:\n",
    "    for ln in fh:\n",
    "        if not ln.strip(): continue\n",
    "        d_pairs.append(json.loads(ln))\n",
    "if len(d_pairs) == 0:\n",
    "    print(\"No Ddistill data found; skipping fstudent training\")\n",
    "else:\n",
    "    Xd = []\n",
    "    yd = []\n",
    "    for d in d_pairs:\n",
    "        v = d[\"v\"]\n",
    "        x = np.array([float(v.get(c,0.0)) for c in FEATURE_COLS], dtype=np.float32)\n",
    "        Xd.append(x)\n",
    "        yd.append(float(d[\"t\"]))\n",
    "    Xd = np.stack(Xd, axis=0)\n",
    "    yd = np.array(yd, dtype=np.float32)\n",
    "    fstudent.train()\n",
    "    n_d = len(Xd)\n",
    "    idxs = list(range(n_d))\n",
    "    rng = random.Random(GLOBAL_SEED+3)\n",
    "    for epoch in range(EPOCHS_FSTUDENT):\n",
    "        rng.shuffle(idxs)\n",
    "        total_loss = 0.0\n",
    "        for s in range(0, n_d, BATCH_SIZE):\n",
    "            batch = idxs[s:s+BATCH_SIZE]\n",
    "            xb = torch.tensor(Xd[batch], dtype=torch.float32, device=DEVICE)\n",
    "            yb = torch.tensor(yd[batch], dtype=torch.float32, device=DEVICE)\n",
    "            opt_fst.zero_grad()\n",
    "            pred = fstudent(xb)\n",
    "            loss = mse_loss(pred, yb)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(fstudent.parameters(), GRAD_CLIP)\n",
    "            opt_fst.step()\n",
    "            total_loss += float(loss.detach().cpu().item())\n",
    "        print(f\"[fstudent] epoch {epoch+1}/{EPOCHS_FSTUDENT} loss {total_loss / max(1, math.ceil(n_d/BATCH_SIZE)):.6f}\")\n",
    "\n",
    "# -------------------- EMA teacher updates --------------------\n",
    "@torch.no_grad()\n",
    "def ema_update(teacher: nn.Module, student: nn.Module, alpha: float):\n",
    "    for tp, sp in zip(teacher.parameters(), student.parameters()):\n",
    "        tp.data.mul_(alpha).add_(sp.data * (1.0 - alpha))\n",
    "\n",
    "ema_update(fusion_teacher, fusion_student, EMA_ALPHA)\n",
    "ema_update(lpa_teacher_encoder, lpa_student_encoder, EMA_ALPHA)\n",
    "ema_update(lpa_teacher_agg, lpa_student_agg, EMA_ALPHA)\n",
    "ema_update(fstudent_teacher, fstudent, EMA_ALPHA)\n",
    "\n",
    "# -------------------- save teacher models --------------------\n",
    "torch.save(fusion_teacher.state_dict(), TEACHER_OUT / \"fusion_teacher.pth\")\n",
    "torch.save(lpa_teacher_encoder.state_dict(), TEACHER_OUT / \"lpa_teacher_encoder.pth\")\n",
    "torch.save(lpa_teacher_agg.state_dict(), TEACHER_OUT / \"lpa_teacher_agg.pth\")\n",
    "torch.save(fstudent_teacher.state_dict(), TEACHER_OUT / \"fstudent_teacher.pth\")\n",
    "meta = {\n",
    "    \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()),\n",
    "    \"n_records\": len(X),\n",
    "    \"epochs_fusion\": EPOCHS_FUSION,\n",
    "    \"epochs_lpa\": EPOCHS_LPA,\n",
    "    \"epochs_fstudent\": EPOCHS_FSTUDENT,\n",
    "    \"lambda_consist\": LAMBDA_CONSIST,\n",
    "    \"ema_alpha\": EMA_ALPHA\n",
    "}\n",
    "(TEACHER_OUT / \"mstep_meta.json\").write_text(json.dumps(meta, indent=2))\n",
    "print(\"M-step complete. Teacher models written to:\", TEACHER_OUT.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03229af8",
   "metadata": {},
   "source": [
    "### C. Teacher Update (EMA) and D. Stopping Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8010dba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import argparse, json, os, time\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, Set, Tuple, List\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# -------------------- Defaults & hyperparams --------------------\n",
    "DEFAULT_ALPHA = 0.999\n",
    "W_THRESHOLD = 0.9         # high-confidence weight threshold\n",
    "SCORE_THRESHOLD = 0.5     # finalscore threshold for high-confidence\n",
    "JACCARD_STOP = 0.99\n",
    "VAL_PATIENCE = 3\n",
    "VAL_EPS = 1e-4\n",
    "\n",
    "# -------------------- Utilities --------------------\n",
    "def load_jsonl(path: Path) -> List[Dict[str, Any]]:\n",
    "    out = []\n",
    "    with path.open(\"r\", encoding=\"utf8\") as fh:\n",
    "        for ln in fh:\n",
    "            s = ln.strip()\n",
    "            if not s:\n",
    "                continue\n",
    "            out.append(json.loads(s))\n",
    "    return out\n",
    "\n",
    "def save_jsonl(objects: List[Dict[str, Any]], path: Path):\n",
    "    with path.open(\"w\", encoding=\"utf8\") as fh:\n",
    "        for obj in objects:\n",
    "            fh.write(json.dumps(obj, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "def make_pair_key(i: int, j: int) -> str:\n",
    "    return f\"{int(i)}::{int(j)}\"\n",
    "\n",
    "def jaccard_from_sets(A: Set[str], B: Set[str]) -> float:\n",
    "    if not A and not B:\n",
    "        return 1.0\n",
    "    inter = A.intersection(B)\n",
    "    union = A.union(B)\n",
    "    if not union:\n",
    "        return 0.0\n",
    "    return float(len(inter)) / float(len(union))\n",
    "\n",
    "\n",
    "def ema_update_state_dict(teacher_sd: Dict[str, torch.Tensor], student_sd: Dict[str, torch.Tensor], alpha: float):\n",
    "    t_keys = set(teacher_sd.keys())\n",
    "    s_keys = set(student_sd.keys())\n",
    "    if t_keys != s_keys:\n",
    "        missing_in_t = sorted(list(s_keys - t_keys))\n",
    "        missing_in_s = sorted(list(t_keys - s_keys))\n",
    "        raise RuntimeError(f\"State-dict key mismatch between teacher and student.\\nMissing in teacher: {missing_in_t}\\nMissing in student: {missing_in_s}\")\n",
    "    for k in teacher_sd.keys():\n",
    "        t = teacher_sd[k]\n",
    "        s = student_sd[k]\n",
    "        if not isinstance(t, torch.Tensor) or not isinstance(s, torch.Tensor):\n",
    "            continue\n",
    "        if t.dtype != s.dtype:\n",
    "            s = s.to(dtype=t.dtype)\n",
    "        teacher_sd[k] = (alpha * t + (1.0 - alpha) * s).clone()\n",
    "\n",
    "# -------------------- Main pipeline --------------------\n",
    "def main():\n",
    "    p = argparse.ArgumentParser()\n",
    "    p.add_argument(\"--round\", type=int, required=True)\n",
    "    p.add_argument(\"--student-checks\", type=Path, required=True,\n",
    "                   help=\"Directory with student checkpoints named: fusion_student.pth, lpa_encoder_student.pth, lpa_agg_student.pth, fstudent_student.pth (exact names)\")\n",
    "    p.add_argument(\"--teacher-prev\", type=Path, required=True,\n",
    "                   help=\"Directory containing previous teacher checkpoints with matching names: fusion_teacher.pth, lpa_encoder_teacher.pth, lpa_agg_teacher.pth, fstudent_teacher.pth\")\n",
    "    p.add_argument(\"--c-prior\", type=Path, required=True, help=\"C_prior JSONL for current round\")\n",
    "    p.add_argument(\"--h-prev\", type=Path, default=None, help=\"Optional previous H(r-1) JSONL to compute Jaccard\")\n",
    "    p.add_argument(\"--val-history\", type=Path, default=None, help=\"Optional validation history JSON file (list of {round:int, val_score:float})\")\n",
    "    p.add_argument(\"--alpha\", type=float, default=DEFAULT_ALPHA)\n",
    "    p.add_argument(\"--out\", type=Path, required=True, help=\"Directory to write updated teacher checkpoints and artifacts\")\n",
    "    args = p.parse_args()\n",
    "\n",
    "    # checks\n",
    "    stud_dir: Path = args.student_checks\n",
    "    teach_prev_dir: Path = args.teacher_prev\n",
    "    c_prior_path: Path = args.c_prior\n",
    "    out_dir: Path = args.out\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    required_student_files = {\n",
    "        \"fusion\": stud_dir / \"fusion_student.pth\",\n",
    "        \"lpa_encoder\": stud_dir / \"lpa_encoder_student.pth\",\n",
    "        \"lpa_agg\": stud_dir / \"lpa_agg_student.pth\",\n",
    "        \"fstudent\": stud_dir / \"fstudent_student.pth\"\n",
    "    }\n",
    "    required_teacher_files = {\n",
    "        \"fusion\": teach_prev_dir / \"fusion_teacher.pth\",\n",
    "        \"lpa_encoder\": teach_prev_dir / \"lpa_encoder_teacher.pth\",\n",
    "        \"lpa_agg\": teach_prev_dir / \"lpa_agg_teacher.pth\",\n",
    "        \"fstudent\": teach_prev_dir / \"fstudent_teacher.pth\"\n",
    "    }\n",
    "\n",
    "    for k,v in required_student_files.items():\n",
    "        if not v.exists():\n",
    "            raise FileNotFoundError(f\"Missing student checkpoint {k}: {v}\")\n",
    "    for k,v in required_teacher_files.items():\n",
    "        if not v.exists():\n",
    "            raise FileNotFoundError(f\"Missing previous teacher checkpoint {k}: {v}\")\n",
    "    if not c_prior_path.exists():\n",
    "        raise FileNotFoundError(f\"C_prior file not found: {c_prior_path}\")\n",
    "\n",
    "    # load current C_prior\n",
    "    c_records = load_jsonl(c_prior_path)\n",
    "\n",
    "    # build high-confidence set H_r\n",
    "    H_r = set()\n",
    "    H_r_list = []\n",
    "    for rec in c_records:\n",
    "        i = rec.get(\"i\") or rec.get(\"node_pair\", [None, None])[0] or (rec.get(\"path\",[None])[0] if rec.get(\"path\") else None)\n",
    "        j = rec.get(\"j\") or rec.get(\"node_pair\", [None, None])[1] or (rec.get(\"path\",[])[-1] if rec.get(\"path\") else None)\n",
    "        if i is None or j is None:\n",
    "            # try other fields\n",
    "            continue\n",
    "        finalscore = float(rec.get(\"finalscore\", rec.get(\"pos_score\", 0.0) or 0.0))\n",
    "        pval = float(rec.get(\"p_value\", rec.get(\"p\", 1.0)))\n",
    "        w = max(0.0, min(1.0, 1.0 - pval))\n",
    "        if w >= W_THRESHOLD and finalscore >= SCORE_THRESHOLD:\n",
    "            key = make_pair_key(i,j)\n",
    "            H_r.add(key)\n",
    "            H_r_list.append({\"i\": int(i), \"j\": int(j), \"finalscore\": float(finalscore), \"p_value\": float(pval), \"w\": float(w)})\n",
    "\n",
    "    # write H_r deterministically (sorted)\n",
    "    H_r_path = out_dir / f\"H_round_{args.round}.jsonl\"\n",
    "    H_r_list_sorted = sorted(H_r_list, key=lambda x: (x[\"i\"], x[\"j\"]))\n",
    "    save_jsonl(H_r_list_sorted, H_r_path)\n",
    "\n",
    "    # compute Jaccard vs previous H \n",
    "    J_r = None\n",
    "    if args.h_prev:\n",
    "        hprev_path = Path(args.h_prev)\n",
    "        if not hprev_path.exists():\n",
    "            raise FileNotFoundError(f\"Provided h-prev file does not exist: {hprev_path}\")\n",
    "        hprev = load_jsonl(hprev_path)\n",
    "        H_prev = set(make_pair_key(item[\"i\"], item[\"j\"]) for item in hprev)\n",
    "        J_r = jaccard_from_sets(H_r, H_prev)\n",
    "    else:\n",
    "        # if no previous, set J_r = None\n",
    "        J_r = None\n",
    "\n",
    "    # perform EMA update per model\n",
    "    alpha = float(args.alpha)\n",
    "    saved_teacher_paths = {}\n",
    "    for model_key in [\"fusion\", \"lpa_encoder\", \"lpa_agg\", \"fstudent\"]:\n",
    "        stud_path = required_student_files[model_key]\n",
    "        teach_prev_path = required_teacher_files[model_key]\n",
    "        stud_sd = torch.load(stud_path, map_location=\"cpu\")\n",
    "        teach_sd = torch.load(teach_prev_path, map_location=\"cpu\")\n",
    "\n",
    "        if isinstance(stud_sd, dict) and \"state_dict\" in stud_sd and isinstance(stud_sd[\"state_dict\"], dict):\n",
    "            stud_state = stud_sd[\"state_dict\"]\n",
    "        elif isinstance(stud_sd, dict) and \"model_state\" in stud_sd and isinstance(stud_sd[\"model_state\"], dict):\n",
    "            stud_state = stud_sd[\"model_state\"]\n",
    "        else:\n",
    "            stud_state = stud_sd\n",
    "\n",
    "        if isinstance(teach_sd, dict) and \"state_dict\" in teach_sd and isinstance(teach_sd[\"state_dict\"], dict):\n",
    "            teach_state = teach_sd[\"state_dict\"]\n",
    "        elif isinstance(teach_sd, dict) and \"model_state\" in teach_sd and isinstance(teach_sd[\"model_state\"], dict):\n",
    "            teach_state = teach_sd[\"model_state\"]\n",
    "        else:\n",
    "            teach_state = teach_sd\n",
    "\n",
    "        for k in list(stud_state.keys()):\n",
    "            if not isinstance(stud_state[k], torch.Tensor):\n",
    "                try:\n",
    "                    stud_state[k] = torch.tensor(stud_state[k])\n",
    "                except Exception:\n",
    "                    pass\n",
    "        for k in list(teach_state.keys()):\n",
    "            if not isinstance(teach_state[k], torch.Tensor):\n",
    "                try:\n",
    "                    teach_state[k] = torch.tensor(teach_state[k])\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "        # compute EMA in-place on teach_state\n",
    "        try:\n",
    "            ema_update_state_dict(teach_state, stud_state, alpha)\n",
    "        except RuntimeError as e:\n",
    "            raise RuntimeError(f\"EMA update failed for model {model_key}: {e}\")\n",
    "\n",
    "        out_sd = teach_state\n",
    "        # save to out dir\n",
    "        ts = time.strftime(\"%Y%m%dT%H%M%S\", time.gmtime())\n",
    "        out_path = out_dir / f\"{model_key}_teacher_round{args.round}_{ts}.pth\"\n",
    "        torch.save(out_sd, out_path)\n",
    "        saved_teacher_paths[model_key] = str(out_path)\n",
    "\n",
    "    stop_by_val = False\n",
    "    val_info = None\n",
    "    if args.val_history:\n",
    "        val_path = Path(args.val_history)\n",
    "        if not val_path.exists():\n",
    "            raise FileNotFoundError(f\"val_history file not found: {val_path}\")\n",
    "        val_hist = json.loads(val_path.read_text(encoding=\"utf8\"))\n",
    "        scores = [float(x[\"val_score\"]) for x in val_hist if \"val_score\" in x]\n",
    "        rounds = [int(x[\"round\"]) for x in val_hist if \"val_score\" in x]\n",
    "        if len(scores) > 0:\n",
    "            best_score = max(scores)\n",
    "            last_score = scores[-1]\n",
    "            last_best_idx = max(i for i,s in enumerate(scores) if s >= best_score - 1e-12)\n",
    "            rounds_since_best = len(scores) - 1 - last_best_idx\n",
    "            if rounds_since_best >= VAL_PATIENCE:\n",
    "                stop_by_val = True\n",
    "            val_info = {\"best_score\": float(best_score), \"last_score\": float(last_score), \"rounds_since_best\": int(rounds_since_best)}\n",
    "        else:\n",
    "            val_info = {\"info\": \"no scores in val_history\"}\n",
    "    else:\n",
    "        val_info = {\"info\": \"val_history not provided\"}\n",
    "\n",
    "    stop_flag = False\n",
    "    if J_r is not None:\n",
    "        if J_r >= JACCARD_STOP:\n",
    "            stop_flag = True\n",
    "    if stop_by_val:\n",
    "        stop_flag = True\n",
    "\n",
    "    summary = {\n",
    "        \"round\": int(args.round),\n",
    "        \"timestamp_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
    "        \"alpha\": float(alpha),\n",
    "        \"w_threshold\": float(W_THRESHOLD),\n",
    "        \"score_threshold\": float(SCORE_THRESHOLD),\n",
    "        \"J_r\": (float(J_r) if J_r is not None else None),\n",
    "        \"J_threshold\": float(JACCARD_STOP),\n",
    "        \"stop_by_jaccard\": (bool(J_r is not None and J_r >= JACCARD_STOP)),\n",
    "        \"stop_by_val\": bool(stop_by_val),\n",
    "        \"val_info\": val_info,\n",
    "        \"saved_teacher_checkpoints\": saved_teacher_paths,\n",
    "        \"H_r_path\": str(H_r_path),\n",
    "        \"n_H_r\": len(H_r_list_sorted),\n",
    "        \"stop\": bool(stop_flag)\n",
    "    }\n",
    "    summary_path = out_dir / f\"teacher_update_summary_round{args.round}.json\"\n",
    "    summary_path.write_text(json.dumps(summary, indent=2))\n",
    "    print(\"Wrote summary:\", summary_path)\n",
    "    if stop_flag:\n",
    "        print(\"STOP condition met (stop=True). Final teacher snapshots written to:\", out_dir)\n",
    "    else:\n",
    "        print(\"STOP condition not met. Updated teacher snapshots written to:\", out_dir)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978ed947",
   "metadata": {},
   "source": [
    "### Evaluating the produced $C_{prior}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8fee6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import json, time\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, precision_score, recall_score, f1_score, brier_score_loss\n",
    "\n",
    "C_PRIOR_PATH = Path(\"out/e_step/C_prior_round_1.jsonl\")\n",
    "ENTITIES_PATH = Path(\"out/d_corpus/entities.json\")   \n",
    "G_TRUE_PATH = Path(\"graphs/G_true.gpickle\")\n",
    "OUT_DIR = Path(\"out/eval_cprior\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# === Helper functions ===\n",
    "def load_jsonl(p: Path):\n",
    "    out=[]\n",
    "    with p.open(\"r\", encoding=\"utf8\") as fh:\n",
    "        for ln in fh:\n",
    "            s = ln.strip()\n",
    "            if not s: continue\n",
    "            out.append(json.loads(s))\n",
    "    return out\n",
    "\n",
    "def load_entities_map(p: Path):\n",
    "    txt = p.read_text(encoding=\"utf8\").strip()\n",
    "    if not txt:\n",
    "        return {}\n",
    "    try:\n",
    "        parsed = json.loads(txt)\n",
    "        if isinstance(parsed, list):\n",
    "            return {e[\"id\"]: e for e in parsed}\n",
    "        if isinstance(parsed, dict):\n",
    "            return parsed\n",
    "    except Exception:\n",
    "        out={}\n",
    "        for ln in txt.splitlines():\n",
    "            if not ln.strip(): continue\n",
    "            obj = json.loads(ln)\n",
    "            out[obj[\"id\"]] = obj\n",
    "        return out\n",
    "\n",
    "def normalize_node(n):\n",
    "    if isinstance(n, str) and n.startswith(\"N\"):\n",
    "        try:\n",
    "            return int(n[1:])\n",
    "        except Exception:\n",
    "            return n\n",
    "    return int(n)\n",
    "\n",
    "def build_df(records: List[Dict[str,Any]], entities_map: Dict[str,Any]):\n",
    "    rows=[]\n",
    "    for rec in records:\n",
    "        i = rec.get(\"i\"); j = rec.get(\"j\")\n",
    "        if i is None or j is None:\n",
    "            npair = rec.get(\"node_pair\")\n",
    "            if isinstance(npair, list) and len(npair)>=2:\n",
    "                i,j = npair[0], npair[1]\n",
    "            else:\n",
    "                path = rec.get(\"path\")\n",
    "                if isinstance(path, list) and len(path)>=2:\n",
    "                    i,j = path[0], path[-1]\n",
    "        if i is None or j is None:\n",
    "            continue\n",
    "        try:\n",
    "            inum = normalize_node(i)\n",
    "            jnum = normalize_node(j)\n",
    "        except Exception:\n",
    "            inum = i; jnum = j\n",
    "        finalscore = float(rec.get(\"finalscore\", rec.get(\"pos_score\", 0.0) or 0.0))\n",
    "        pval = float(rec.get(\"p_value\", rec.get(\"p\", 1.0)))\n",
    "        w = max(0.0, min(1.0, 1.0 - pval))\n",
    "        domain = rec.get(\"domain\", \"unknown\")\n",
    "        graph_id = rec.get(\"graph_id\", \"unknown\")\n",
    "        key_i = f\"N{int(inum)}\" if isinstance(inum,int) else str(inum)\n",
    "        key_j = f\"N{int(jnum)}\" if isinstance(jnum,int) else str(jnum)\n",
    "        name_i = entities_map.get(key_i, {}).get(\"name\") if key_i in entities_map else None\n",
    "        name_j = entities_map.get(key_j, {}).get(\"name\") if key_j in entities_map else None\n",
    "        rows.append({\n",
    "            \"i\": inum, \"j\": jnum, \"i_key\": key_i, \"j_key\": key_j,\n",
    "            \"i_name\": name_i, \"j_name\": name_j,\n",
    "            \"finalscore\": finalscore, \"p_value\": pval, \"w\": w,\n",
    "            \"domain\": domain, \"graph_id\": graph_id, \"raw\": rec\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def expected_calibration_error(y_true, probs, n_bins=10):\n",
    "    bins = np.linspace(0.0,1.0,n_bins+1)\n",
    "    bin_indices = np.digitize(probs, bins) - 1\n",
    "    ece = 0.0\n",
    "    info=[]\n",
    "    for b in range(n_bins):\n",
    "        mask = bin_indices == b\n",
    "        if mask.sum()==0:\n",
    "            info.append({\"bin\":b,\"count\":0,\"avg_prob\":None,\"avg_true\":None,\"abs_err\":None})\n",
    "            continue\n",
    "        avg_prob = float(probs[mask].mean())\n",
    "        avg_true = float(y_true[mask].mean())\n",
    "        abs_err = abs(avg_prob - avg_true)\n",
    "        ece += (mask.sum()/len(probs))*abs_err\n",
    "        info.append({\"bin\":b,\"count\":int(mask.sum()),\"avg_prob\":avg_prob,\"avg_true\":avg_true,\"abs_err\":abs_err})\n",
    "    return float(ece), info\n",
    "\n",
    "def topk_precision(df, k_list=[1,5,10,20,50], score_col=\"finalscore\", gt_edges=set()):\n",
    "    df_sorted = df.sort_values(score_col, ascending=False).reset_index(drop=True)\n",
    "    out=[]\n",
    "    for k in k_list:\n",
    "        topk = df_sorted.head(k)\n",
    "        if len(topk)==0:\n",
    "            out.append({\"k\":k,\"precision\":None,\"num\":0})\n",
    "            continue\n",
    "        correct = 0\n",
    "        for _, row in topk.iterrows():\n",
    "            if (int(row[\"i\"]), int(row[\"j\"])) in gt_edges:\n",
    "                correct += 1\n",
    "        out.append({\"k\":k, \"precision\": float(correct/len(topk)), \"num\": int(len(topk))})\n",
    "    return out\n",
    "\n",
    "if not C_PRIOR_PATH.exists():\n",
    "    raise FileNotFoundError(f\"C_prior not found: {C_PRIOR_PATH}\")\n",
    "if not ENTITIES_PATH.exists():\n",
    "    raise FileNotFoundError(f\"entities file not found: {ENTITIES_PATH}\")\n",
    "if not G_TRUE_PATH.exists():\n",
    "    raise FileNotFoundError(f\"G_true not found: {G_TRUE_PATH}\")\n",
    "\n",
    "c_records = load_jsonl(C_PRIOR_PATH)\n",
    "entities_map = load_entities_map(ENTITIES_PATH)\n",
    "G_true = nx.read_gpickle(G_TRUE_PATH)\n",
    "if not isinstance(G_true, nx.DiGraph):\n",
    "    G_true = nx.DiGraph(G_true)\n",
    "\n",
    "df = build_df(c_records, entities_map)\n",
    "n_records = len(df)\n",
    "print(f\"Loaded {n_records} C_prior records\")\n",
    "\n",
    "# build ground-truth edge set\n",
    "gt_edges = set()\n",
    "for u,v in G_true.edges():\n",
    "    try:\n",
    "        uu = int(u)\n",
    "        vv = int(v)\n",
    "    except Exception:\n",
    "        if isinstance(u,str) and u.startswith(\"N\"):\n",
    "            try: uu=int(u[1:]); vv=int(v[1:])\n",
    "            except Exception: continue\n",
    "        else:\n",
    "            continue\n",
    "    gt_edges.add((uu,vv))\n",
    "\n",
    "# labels and scores\n",
    "y_true = np.array([(1 if (int(r[\"i\"]), int(r[\"j\"])) in gt_edges else 0) for _,r in df.iterrows()], dtype=int)\n",
    "scores = np.array([float(r[\"finalscore\"]) for _,r in df.iterrows()], dtype=float)\n",
    "weights = np.array([float(r[\"w\"]) for _,r in df.iterrows()], dtype=float)\n",
    "domains = np.array([r[\"domain\"] for _,r in df.iterrows()], dtype=object)\n",
    "\n",
    "# metrics\n",
    "results = {}\n",
    "if len(scores)>0 and len(np.unique(y_true))>1:\n",
    "    try:\n",
    "        results[\"roc_auc\"] = float(roc_auc_score(y_true, scores))\n",
    "    except Exception:\n",
    "        results[\"roc_auc\"] = None\n",
    "    try:\n",
    "        results[\"average_precision\"] = float(average_precision_score(y_true, scores))\n",
    "    except Exception:\n",
    "        results[\"average_precision\"] = None\n",
    "else:\n",
    "    results[\"roc_auc\"] = None\n",
    "    results[\"average_precision\"] = None\n",
    "\n",
    "# threshold metrics\n",
    "thresholds = [0.5, 0.7, 0.9]\n",
    "thr_metrics = {}\n",
    "for t in thresholds:\n",
    "    preds = (scores >= t).astype(int)\n",
    "    if len(np.unique(preds))==1 and len(np.unique(y_true))==1:\n",
    "        prec = recall = f1 = None\n",
    "    else:\n",
    "        prec = float(precision_score(y_true, preds, zero_division=0))\n",
    "        recall = float(recall_score(y_true, preds, zero_division=0))\n",
    "        f1 = float(f1_score(y_true, preds, zero_division=0))\n",
    "    thr_metrics[t] = {\"precision\": prec, \"recall\": recall, \"f1\": f1}\n",
    "results[\"threshold_metrics\"] = thr_metrics\n",
    "\n",
    "# calibration\n",
    "try:\n",
    "    results[\"brier_score\"] = float(brier_score_loss(y_true, scores))\n",
    "except Exception:\n",
    "    results[\"brier_score\"] = None\n",
    "ece, calib_info = expected_calibration_error(y_true, scores, n_bins=10)\n",
    "results[\"ece\"] = ece\n",
    "pd.DataFrame(calib_info).to_csv(OUT_DIR / \"calibration.csv\", index=False)\n",
    "\n",
    "# top-k\n",
    "tk = topk_precision(df, k_list=[1,5,10,20,50], score_col=\"finalscore\", gt_edges=gt_edges)\n",
    "pd.DataFrame(tk).to_csv(OUT_DIR / \"topk.csv\", index=False)\n",
    "results[\"topk\"] = tk\n",
    "\n",
    "# per-domain\n",
    "per_domain = []\n",
    "for dom in sorted(set(domains)):\n",
    "    mask = domains == dom\n",
    "    if mask.sum()==0: continue\n",
    "    y_d = y_true[mask]; s_d = scores[mask]\n",
    "    entry = {\"domain\": dom, \"n\": int(mask.sum())}\n",
    "    if len(np.unique(y_d))>1:\n",
    "        try:\n",
    "            entry[\"roc_auc\"] = float(roc_auc_score(y_d, s_d))\n",
    "        except Exception:\n",
    "            entry[\"roc_auc\"] = None\n",
    "        try:\n",
    "            entry[\"average_precision\"] = float(average_precision_score(y_d, s_d))\n",
    "        except Exception:\n",
    "            entry[\"average_precision\"] = None\n",
    "    else:\n",
    "        entry[\"roc_auc\"] = None; entry[\"average_precision\"] = None\n",
    "    preds = (s_d >= 0.5).astype(int)\n",
    "    entry[\"precision_0.5\"] = float(precision_score(y_d, preds, zero_division=0))\n",
    "    entry[\"recall_0.5\"] = float(recall_score(y_d, preds, zero_division=0))\n",
    "    entry[\"f1_0.5\"] = float(f1_score(y_d, preds, zero_division=0))\n",
    "    per_domain.append(entry)\n",
    "pd.DataFrame(per_domain).to_csv(OUT_DIR / \"per_domain.csv\", index=False)\n",
    "results[\"per_domain\"] = per_domain\n",
    "\n",
    "# confidence vs correctness\n",
    "correctness = (y_true == 1).astype(float)\n",
    "corr = None\n",
    "if len(correctness)>1:\n",
    "    corr = float(np.corrcoef(weights, correctness)[0,1])\n",
    "results[\"confidence_correctness_corr\"] = corr\n",
    "\n",
    "# high-confidence set summary\n",
    "hc_mask = weights >= 0.9\n",
    "hc_n = int(hc_mask.sum())\n",
    "hc_prec = float(correctness[hc_mask].mean()) if hc_n>0 else None\n",
    "results[\"high_conf\"] = {\"n\": hc_n, \"precision\": hc_prec}\n",
    "\n",
    "prev_h = OUT_DIR / \"H_round_prev.jsonl\"\n",
    "jaccard_vs_prev = None\n",
    "if prev_h.exists():\n",
    "    prev_list = load_jsonl(prev_h)\n",
    "    H_prev = set(f\"{int(x['i'])}::{int(x['j'])}\" for x in prev_list)\n",
    "    H_cur = set(f\"{int(r['i'])}::{int(r['j'])}\" for r in df[df['w']>=0.9].to_dict(\"records\"))\n",
    "    if len(H_cur | H_prev) == 0:\n",
    "        jaccard_vs_prev = 1.0\n",
    "    else:\n",
    "        jaccard_vs_prev = float(len(H_cur & H_prev) / len(H_cur | H_prev))\n",
    "results[\"jaccard_vs_prev_high_conf\"] = jaccard_vs_prev\n",
    "\n",
    "# summary\n",
    "summary = {\n",
    "    \"timestamp\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
    "    \"n_records\": int(n_records),\n",
    "    \"n_positive_gt_in_records\": int(int((df.apply(lambda r: (int(r['i']),int(r['j'])) in gt_edges, axis=1)).sum())),\n",
    "    \"metrics\": results\n",
    "}\n",
    "(OUT_DIR / \"eval_summary.json\").write_text(json.dumps(summary, indent=2))\n",
    "print(\"EVALUATION SUMMARY\")\n",
    "print(json.dumps(summary, indent=2))\n",
    "print(\"Artifacts written to:\", OUT_DIR.resolve())\n",
    "print(\"Calibration CSV:\", OUT_DIR / \"calibration.csv\")\n",
    "print(\"Per-domain CSV:\", OUT_DIR / \"per_domain.csv\")\n",
    "print(\"Top-K CSV:\", OUT_DIR / \"topk.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b54c6d",
   "metadata": {},
   "source": [
    "Comparing $C_{prior}$ against a few causal baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386499d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "import json, math, time, os, random\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "# ML / causal libs \n",
    "try:\n",
    "    from causallearn.search.ConstraintBased.PC import pc  # causal-learn PC entrypoint\n",
    "    from causallearn.utils.GraphUtils import GraphUtils\n",
    "    HAS_CAUSALLEARN = True\n",
    "except Exception:\n",
    "    HAS_CAUSALLEARN = False\n",
    "\n",
    "try:\n",
    "    import lingam\n",
    "    HAS_LINGAM = True\n",
    "except Exception:\n",
    "    HAS_LINGAM = False\n",
    "\n",
    "try:\n",
    "    import causalnex.structure.notears as cn_notears\n",
    "    HAS_CAUSALNEX = True\n",
    "except Exception:\n",
    "    HAS_CAUSALNEX = False\n",
    "\n",
    "try:\n",
    "    import statsmodels.api as sm\n",
    "    from statsmodels.tsa.stattools import grangercausalitytests\n",
    "    HAS_STATSMODELS = True\n",
    "except Exception:\n",
    "    HAS_STATSMODELS = False\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "    HAS_TRANSFORMERS = True\n",
    "except Exception:\n",
    "    HAS_TRANSFORMERS = False\n",
    "\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    HAS_SBERT = True\n",
    "except Exception:\n",
    "    HAS_SBERT = False\n",
    "\n",
    "try:\n",
    "    import cdt\n",
    "    HAS_CDT = True\n",
    "except Exception:\n",
    "    HAS_CDT = False\n",
    "\n",
    "try:\n",
    "    import sklearn\n",
    "    from sklearn.metrics import roc_auc_score, average_precision_score, precision_score, recall_score, f1_score, brier_score_loss\n",
    "    from sklearn.metrics import ndcg_score\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    HAS_SKLEARN = True\n",
    "except Exception:\n",
    "    HAS_SKLEARN = False\n",
    "\n",
    "# Gemini wrapper for LLM baselines \n",
    "try:\n",
    "    import google.generativeai as genai\n",
    "    HAS_GEMINI = True\n",
    "except Exception:\n",
    "    HAS_GEMINI = False\n",
    "\n",
    "# -------------------- Configuration --------------------\n",
    "DCORPUS_DIR = Path(\"d_corpus_output\")       # directory with D_corpus JSONL files\n",
    "G_TRUE_PATH = Path(\"graphs/G_true.gpickle\") # ground-truth graph\n",
    "C_PRIOR_PATH = Path(\"out/e_step/C_prior_round_1.jsonl\")  \n",
    "OUT_DIR = Path(\"out/baseline_eval\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODEL_SBERT = \"all-MiniLM-L6-v2\"  # for entity/document embeddings\n",
    "\n",
    "# Top-K list\n",
    "TOPK_LIST = [1,5,10,20,50,100]\n",
    "\n",
    "# -------------------- Utilities --------------------\n",
    "def load_jsonl(path: Path) -> List[Dict[str,Any]]:\n",
    "    if not path.exists():\n",
    "        return []\n",
    "    out=[]\n",
    "    with path.open(\"r\", encoding=\"utf8\") as fh:\n",
    "        for ln in fh:\n",
    "            s=ln.strip()\n",
    "            if not s: continue\n",
    "            out.append(json.loads(s))\n",
    "    return out\n",
    "\n",
    "def load_d_corpus_records(dcorpus_dir: Path) -> List[Dict[str,Any]]:\n",
    "    recs=[]\n",
    "    if not dcorpus_dir.exists():\n",
    "        raise FileNotFoundError(f\"D_corpus dir {dcorpus_dir} not found.\")\n",
    "    for p in sorted(dcorpus_dir.glob(\"*.jsonl\")):\n",
    "        recs += load_jsonl(p)\n",
    "    return recs\n",
    "\n",
    "def build_pair_df_from_records(records: List[Dict[str,Any]], entities_map: Dict[str,Any], require_unique_pairs=False) -> pd.DataFrame:\n",
    "    rows=[]\n",
    "    for rec in records:\n",
    "        # determine i,j\n",
    "        if \"node_pair\" in rec and isinstance(rec[\"node_pair\"], (list,tuple)) and len(rec[\"node_pair\"])>=2:\n",
    "            i,j = rec[\"node_pair\"][0], rec[\"node_pair\"][1]\n",
    "        elif \"path\" in rec and isinstance(rec[\"path\"], list) and len(rec[\"path\"])>=2:\n",
    "            path = rec[\"path\"]\n",
    "            if isinstance(path[0], list):  # sometimes paths is list of paths\n",
    "                path = path[0]\n",
    "            i,j = path[0], path[-1]\n",
    "        else:\n",
    "            continue\n",
    "        try:\n",
    "            i_int = int(str(i).lstrip(\"N\"))\n",
    "            j_int = int(str(j).lstrip(\"N\"))\n",
    "        except Exception:\n",
    "            continue\n",
    "        finalscore = float(rec.get(\"finalscore\", rec.get(\"pos_score\", 0.0) or 0.0))\n",
    "        pval = float(rec.get(\"p_value\", rec.get(\"p\", 1.0)))\n",
    "        rows.append({\n",
    "            \"i\": i_int, \"j\": j_int, \"finalscore\": finalscore, \"p_value\": pval,\n",
    "            \"domain\": rec.get(\"domain\",\"unknown\"), \"graph_id\": rec.get(\"graph_id\",\"unknown\"),\n",
    "            \"pos_snippet\": rec.get(\"pos_snippet\",\"\"), \"neg_snippet\": rec.get(\"neg_snippet\",\"\"),\n",
    "            \"raw\": rec\n",
    "        })\n",
    "    df = pd.DataFrame(rows)\n",
    "    if require_unique_pairs:\n",
    "        df = df.drop_duplicates(subset=[\"i\",\"j\"])\n",
    "    return df\n",
    "\n",
    "def load_entities(path: Path) -> Dict[str,Any]:\n",
    "    if not path.exists():\n",
    "        return {}\n",
    "    txt = path.read_text(encoding=\"utf8\").strip()\n",
    "    if not txt:\n",
    "        return {}\n",
    "    try:\n",
    "        obj = json.loads(txt)\n",
    "        if isinstance(obj, dict):\n",
    "            return obj\n",
    "        if isinstance(obj, list):\n",
    "            return {e[\"id\"]: e for e in obj}\n",
    "    except Exception:\n",
    "        # fallback to jsonl per-line\n",
    "        out={}\n",
    "        for ln in txt.splitlines():\n",
    "            if not ln.strip(): continue\n",
    "            e = json.loads(ln)\n",
    "            out[e[\"id\"]] = e\n",
    "        return out\n",
    "\n",
    "def evaluate_scores(df_pairs: pd.DataFrame, score_col: str, gt_edges:set, out_prefix: Path):\n",
    "    y_true = np.array([1 if (int(r.i),int(r.j)) in gt_edges else 0 for r in df_pairs.itertuples()])\n",
    "    scores = np.array([float(getattr(r, score_col)) for r in df_pairs.itertuples()])\n",
    "    res = {}\n",
    "    if len(np.unique(y_true))>1:\n",
    "        res[\"auc\"] = float(roc_auc_score(y_true, scores))\n",
    "        res[\"ap\"] = float(average_precision_score(y_true, scores))\n",
    "    else:\n",
    "        res[\"auc\"] = None; res[\"ap\"]=None\n",
    "    # thresholds\n",
    "    thr_metrics = {}\n",
    "    for thr in (0.5, 0.7, 0.9):\n",
    "        preds = (scores>=thr).astype(int)\n",
    "        thr_metrics[thr] = {\n",
    "            \"precision\": float(precision_score(y_true, preds, zero_division=0)),\n",
    "            \"recall\": float(recall_score(y_true, preds, zero_division=0)),\n",
    "            \"f1\": float(f1_score(y_true, preds, zero_division=0))\n",
    "        }\n",
    "    res[\"thresholds\"] = thr_metrics\n",
    "    # top-k precision\n",
    "    df_sorted = df_pairs.copy().sort_values(score_col, ascending=False).reset_index(drop=True)\n",
    "    topk_res=[]\n",
    "    for k in TOPK_LIST:\n",
    "        topk = df_sorted.head(k)\n",
    "        if len(topk)==0:\n",
    "            topk_res.append({\"k\":k,\"precision\":None})\n",
    "            continue\n",
    "        npos = sum(1 for _,r in topk.iterrows() if (int(r.i),int(r.j)) in gt_edges)\n",
    "        topk_res.append({\"k\":k,\"precision\":float(npos/len(topk))})\n",
    "    res[\"topk\"] = topk_res\n",
    "    # calibration (ECE deciles)\n",
    "    try:\n",
    "        bins = np.linspace(0.0,1.0,11)\n",
    "        bin_idx = np.digitize(scores, bins) - 1\n",
    "        ece = 0.0\n",
    "        calib_table=[]\n",
    "        for b in range(10):\n",
    "            mask = bin_idx==b\n",
    "            if mask.sum()==0:\n",
    "                calib_table.append({\"bin\":b,\"count\":0,\"avg_prob\":None,\"avg_true\":None})\n",
    "                continue\n",
    "            avg_prob = float(scores[mask].mean())\n",
    "            avg_true = float(y_true[mask].mean())\n",
    "            ece += (mask.sum()/len(scores))*abs(avg_prob-avg_true)\n",
    "            calib_table.append({\"bin\":b,\"count\":int(mask.sum()),\"avg_prob\":avg_prob,\"avg_true\":avg_true})\n",
    "        res[\"ece\"]=float(ece)\n",
    "        res[\"calibration_table\"]=calib_table\n",
    "    except Exception:\n",
    "        res[\"ece\"]=None; res[\"calibration_table\"]=[]\n",
    "    # save\n",
    "    (out_prefix.with_suffix(\"\") ).parent.mkdir(parents=True, exist_ok=True)\n",
    "    json_path = out_prefix.with_suffix(\".json\")\n",
    "    json_path.write_text(json.dumps(res, indent=2))\n",
    "    return res\n",
    "\n",
    "# -------------------- Load inputs --------------------\n",
    "if not DCORPUS_DIR.exists():\n",
    "    raise FileNotFoundError(f\"D_corpus dir not found: {DCORPUS_DIR}\")\n",
    "d_records = load_d_corpus_records(DCORPUS_DIR)\n",
    "if len(d_records)==0:\n",
    "    raise RuntimeError(\"No d_corpus records found in \" + str(DCORPUS_DIR))\n",
    "\n",
    "entities_path = DCORPUS_DIR / \"entities.json\"\n",
    "entities_map = load_entities(entities_path) if entities_path.exists() else {}\n",
    "\n",
    "G_true = None\n",
    "if G_TRUE_PATH.exists():\n",
    "    G_true = nx.read_gpickle(G_TRUE_PATH)\n",
    "    if not isinstance(G_true, nx.DiGraph):\n",
    "        G_true = nx.DiGraph(G_true)\n",
    "else:\n",
    "    raise FileNotFoundError(f\"G_true not found at {G_TRUE_PATH}\")\n",
    "\n",
    "# Build canonical pair dataframe (unique pairs)\n",
    "df_pairs = build_pair_df_from_records(d_records, entities_map, require_unique_pairs=True)\n",
    "if df_pairs.empty:\n",
    "    raise RuntimeError(\"No pairs parsed from D_corpus records.\")\n",
    "\n",
    "gt_edges = set((int(u),int(v)) for u,v in G_true.edges())\n",
    "\n",
    "# -------------------- Embedding utilities --------------------\n",
    "if not HAS_SBERT:\n",
    "    raise ImportError(\"Please install sentence-transformers (pip install sentence-transformers) for embeddings baseline.\")\n",
    "embedder = SentenceTransformer(MODEL_SBERT)\n",
    "\n",
    "def compute_entity_embeddings(entities_map: Dict[str,Any]) -> Dict[str, np.ndarray]:\n",
    "    out={}\n",
    "    items = list(entities_map.items())\n",
    "    if len(items)==0:\n",
    "        return {}\n",
    "    names = [v.get(\"name\",\"\") + \" . \" + (v.get(\"description\",\"\") or \"\") for k,v in items]\n",
    "    embs = embedder.encode(names, convert_to_numpy=True, show_progress_bar=False)\n",
    "    for (k,_), e in zip(items, embs):\n",
    "        out[k] = e\n",
    "    return out\n",
    "\n",
    "entity_emb_map = compute_entity_embeddings(entities_map)\n",
    "\n",
    "def pair_to_feature_vector(i:int, j:int, df_pairs_row:Dict[str,Any]) -> np.ndarray:\n",
    "    key_i = f\"N{i}\"\n",
    "    key_j = f\"N{j}\"\n",
    "    if key_i in entity_emb_map and key_j in entity_emb_map:\n",
    "        return np.concatenate([entity_emb_map[key_i], entity_emb_map[key_j]])\n",
    "    txt = df_pairs_row.get(\"pos_snippet\",\"\") or \"\"\n",
    "    vec = embedder.encode([txt], convert_to_numpy=True, show_progress_bar=False)[0]\n",
    "    return np.concatenate([vec, vec])\n",
    "\n",
    "# Build feature matrix for all pairs (for structure-based baselines)\n",
    "feat_dim = None\n",
    "pair_X = []\n",
    "pair_keys = []\n",
    "for _, r in df_pairs.iterrows():\n",
    "    fv = pair_to_feature_vector(int(r.i), int(r.j), r)\n",
    "    pair_X.append(fv)\n",
    "    pair_keys.append((int(r.i), int(r.j)))\n",
    "pair_X = np.vstack(pair_X)\n",
    "feat_dim = pair_X.shape[1]\n",
    "\n",
    "# -------------------- Baseline 1: PC algorithm (causal-learn) --------------------\n",
    "def baseline_pc(X: np.ndarray, pair_keys: List[Tuple[int,int]], variable_names: List[str]=None):\n",
    "    if not HAS_CAUSALLEARN:\n",
    "        raise ImportError(\"Install 'causal-learn' (pip install causal-learn) to run PC baseline.\")\n",
    "    data = X  # shape [n_samples, n_features]\n",
    "    # causal-learn expects samples x variables; we'll transpose to variables x samples? causal-learn API accepts data as numpy array (samples x variables)\n",
    "    try:\n",
    "        cg = pc(data, alpha=0.01, indep_test='fisherz')  # default\n",
    "    except Exception as e:\n",
    "        # fallback: try without indep_test arg\n",
    "        cg = pc(data, alpha=0.01)\n",
    "    # cg.G is adjacency for variables; we need to map back to entity pairs -> use similarity: for each pair (i,j) compute score =\n",
    "    # number of variable-variable edges that strongly connect features of i and j. We'll compute coarse score via dot-product between rows of adjacency matrix.\n",
    "    adj = cg.G.graph  # may be complicated object\n",
    "    # best-effort: produce heuristic score: cosine similarity between pair feature vectors as baseline proxy\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    sims = cosine_similarity(X)  # NxN, heavy for large N\n",
    "    # For pair (i_idx) record its average similarity to other positive examples - but simpler: use self-sim (diagonal) not helpful\n",
    "    # We'll produce score = mean similarity of this pair's feature vector with all others\n",
    "    score_vec = sims.mean(axis=1)\n",
    "    # normalize to [0,1]\n",
    "    score_min, score_max = score_vec.min(), score_vec.max()\n",
    "    if score_max - score_min > 0:\n",
    "        score_norm = (score_vec - score_min) / (score_max - score_min)\n",
    "    else:\n",
    "        score_norm = np.zeros_like(score_vec)\n",
    "    df_out = df_pairs.copy()\n",
    "    df_out[\"pc_score\"] = score_norm.tolist()\n",
    "    return df_out\n",
    "\n",
    "# -------------------- Baseline 2: GES (causal-learn) --------------------\n",
    "def baseline_ges(X: np.ndarray):\n",
    "    if not HAS_CAUSALLEARN:\n",
    "        raise ImportError(\"Install 'causal-learn' to run GES baseline.\")\n",
    "    # causal-learn has GES implementation; to keep API stable we will call generic interface via causal-learn docs.\n",
    "    from causallearn.search.ScoreBased.GES import ges\n",
    "    cg = ges(X)\n",
    "    # As above, create a heuristic score via cosine similarity\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    sims = cosine_similarity(X)\n",
    "    score_vec = sims.mean(axis=1)\n",
    "    # normalize\n",
    "    score_norm = (score_vec - score_vec.min()) / (score_vec.max() - score_vec.min() + 1e-12)\n",
    "    df_out = df_pairs.copy()\n",
    "    df_out[\"ges_score\"] = score_norm.tolist()\n",
    "    return df_out\n",
    "\n",
    "# -------------------- Baseline 3: NOTEARS (causalnex) --------------------\n",
    "def baseline_notears(pd_df_features: pd.DataFrame):\n",
    "    if not HAS_CAUSALNEX:\n",
    "        raise ImportError(\"Install 'causalnex' (pip install causalnex) to run NOTEARS baseline.\")\n",
    "    # causalnex expects a pandas DataFrame with variables as columns; our pair_X columns are continuous features -> convert to DataFrame\n",
    "    Xdf = pd.DataFrame(pair_X, columns=[f\"f_{k}\" for k in range(pair_X.shape[1])])\n",
    "    # use causalnex.notears.from_pandas to obtain adjacency matrix\n",
    "    smodel = cn_notears.from_pandas(Xdf, max_iter=100, w_threshold=0.0)\n",
    "    W = smodel.structure  # DataFrame adjacency\n",
    "    # score heuristic: for each sample (pair) compute sum of absolute outgoing weights for the variables present in its feature vector, as proxy\n",
    "    # simpler: compute row-wise L2 norm of feature vector multiplied by sum of absolute column weights\n",
    "    col_weight = np.abs(W.values).sum(axis=0)\n",
    "    scores = np.abs(pair_X) @ col_weight\n",
    "    score_norm = (scores - scores.min()) / (scores.max()-scores.min()+1e-12)\n",
    "    df_out = df_pairs.copy()\n",
    "    df_out[\"notears_score\"] = score_norm.tolist()\n",
    "    return df_out\n",
    "\n",
    "# -------------------- Baseline 4: LiNGAM --------------------\n",
    "def baseline_lingam(X: np.ndarray):\n",
    "    if not HAS_LINGAM:\n",
    "        raise ImportError(\"Install 'lingam' (pip install lingam) to run LiNGAM baseline.\")\n",
    "    # LiNGAM expects variables; same pragmatic mapping as NOTEARS\n",
    "    model = lingam.DirectLiNGAM()\n",
    "    model.fit(X)\n",
    "    adj = model.adjacency_matrix_  # shape features x features\n",
    "    # heuristic: project to pair scores\n",
    "    col_weight = np.abs(adj).sum(axis=0)\n",
    "    scores = np.abs(X) @ col_weight\n",
    "    score_norm = (scores - scores.min()) / (scores.max()-scores.min()+1e-12)\n",
    "    df_out = df_pairs.copy()\n",
    "    df_out[\"lingam_score\"] = score_norm.tolist()\n",
    "    return df_out\n",
    "\n",
    "# -------------------- Baseline 5: Granger (requires timeseries) --------------------\n",
    "def baseline_granger_from_time_series(entity_time_series: Dict[int, np.ndarray], maxlag:int=3):\n",
    "    if not HAS_STATSMODELS:\n",
    "        raise ImportError(\"Install statsmodels to run Granger baseline.\")\n",
    "    # entity_time_series: mapping node_id -> 1D time series of same length T\n",
    "    # produce pair score = min p-value across lags (converted to 1 - p)\n",
    "    nodes = sorted(entity_time_series.keys())\n",
    "    T = len(next(iter(entity_time_series.values())))\n",
    "    # assemble DataFrame of time series\n",
    "    df_ts = pd.DataFrame({f\"N{n}\": entity_time_series[n] for n in nodes})\n",
    "    results_scores = []\n",
    "    pair_list = []\n",
    "    for (i,j) in zip(df_pairs[\"i\"], df_pairs[\"j\"]):\n",
    "        col_j = f\"N{j}\"\n",
    "        col_i = f\"N{i}\"\n",
    "        if col_i not in df_ts.columns or col_j not in df_ts.columns:\n",
    "            results_scores.append(0.0); pair_list.append((i,j)); continue\n",
    "        try:\n",
    "            res = grangercausalitytests(df_ts[[col_j,col_i]], maxlag=maxlag, verbose=False)\n",
    "            # collect p-values of F-test for each lag\n",
    "            pvals = [res[l][0][\"ssr_ftest\"][1] for l in res.keys()]\n",
    "            minp = min(pvals)\n",
    "            results_scores.append(1.0 - float(minp))\n",
    "        except Exception:\n",
    "            results_scores.append(0.0)\n",
    "        pair_list.append((i,j))\n",
    "    df_out = df_pairs.copy()\n",
    "    df_out[\"granger_score\"] = results_scores\n",
    "    return df_out\n",
    "\n",
    "# -------------------- Baseline 6: LLM Zero-shot & Chain-of-Thought (Gemini) --------------------\n",
    "def llm_score_pairs_gemini(df_pairs: pd.DataFrame, model_name: str=\"gemini-2.5-flash-lite\", prompt_template: str=None, sleep_between_calls: float=0.0):\n",
    "    if not HAS_GEMINI:\n",
    "        raise ImportError(\"Install/Configure Google Gemini SDK 'google.generativeai' and set credentials.\")\n",
    "    genai.configure()  \n",
    "    scores=[]\n",
    "    for _, r in df_pairs.iterrows():\n",
    "        a = r.pos_snippet or \"\"\n",
    "        # simple prompt that asks for a score 0-1\n",
    "        if prompt_template is None:\n",
    "            prompt = (\n",
    "                f\"Given the short evidence sentence:\\n\\n{a}\\n\\n\"\n",
    "                f\"Question: On a scale 0.0 to 1.0, how strongly does this sentence support that node {r.i} causes node {r.j}? \"\n",
    "                \"Return only a JSON: {\\\"score\\\": <float>}.\"\n",
    "            )\n",
    "        else:\n",
    "            prompt = prompt_template.format(i=r.i, j=r.j, snippet=a)\n",
    "        if sleep_between_calls>0:\n",
    "            time.sleep(sleep_between_calls)\n",
    "        resp = genai.generate_text(model=model_name, prompt=prompt, max_output_tokens=80, temperature=0.0)\n",
    "        txt = None\n",
    "        if isinstance(resp, dict):\n",
    "            cands = resp.get(\"candidates\", [])\n",
    "            if cands:\n",
    "                txt = cands[0].get(\"content\",\"\")\n",
    "        else:\n",
    "            txt = getattr(resp, \"candidates\", [{}])[0].get(\"content\",\"\")\n",
    "        if not txt:\n",
    "            scores.append(0.0); continue\n",
    "        # parse JSON\n",
    "        start = txt.find(\"{\")\n",
    "        end = txt.rfind(\"}\")\n",
    "        try:\n",
    "            jtxt = txt[start:end+1]\n",
    "            jj = json.loads(jtxt)\n",
    "            s = float(jj.get(\"score\",0.0))\n",
    "            s = max(0.0,min(1.0,s))\n",
    "        except Exception:\n",
    "            import re\n",
    "            m = re.search(r\"([0-1]?\\.\\d+|0|1)\", txt)\n",
    "            s = float(m.group(1)) if m else 0.0\n",
    "        scores.append(s)\n",
    "    df_out = df_pairs.copy()\n",
    "    df_out[\"llm_gemini_score\"] = scores\n",
    "    return df_out\n",
    "\n",
    "# -------------------- Baseline 7: LLM Self-Consistency (multiple samples mean) --------------------\n",
    "def llm_self_consistency(df_pairs: pd.DataFrame, model_name=\"gemini-2.5-flash-lite\", samples:int=8):\n",
    "    if not HAS_GEMINI:\n",
    "        raise ImportError(\"Install/Configure Google Gemini SDK 'google.generativeai' and set credentials.\")\n",
    "    agg_scores=[]\n",
    "    for _, r in df_pairs.iterrows():\n",
    "        scores=[]\n",
    "        for _ in range(samples):\n",
    "            resp = genai.generate_text(model=model_name, prompt=f\"Does {r.pos_snippet} indicate {r.i} causes {r.j}? Give score 0-1.\", temperature=0.7, max_output_tokens=40)\n",
    "            txt = None\n",
    "            if isinstance(resp, dict):\n",
    "                cands = resp.get(\"candidates\", [])\n",
    "                if cands:\n",
    "                    txt = cands[0].get(\"content\",\"\")\n",
    "            else:\n",
    "                txt = getattr(resp, \"candidates\", [{}])[0].get(\"content\",\"\")\n",
    "            if not txt:\n",
    "                continue\n",
    "            import re\n",
    "            m = re.search(r\"([0-1]?\\.\\d+|0|1)\", txt)\n",
    "            if m:\n",
    "                scores.append(float(m.group(1)))\n",
    "        if scores:\n",
    "            agg_scores.append(float(np.mean(scores)))\n",
    "        else:\n",
    "            agg_scores.append(0.0)\n",
    "    df_out = df_pairs.copy()\n",
    "    df_out[\"llm_selfconsistency\"] = agg_scores\n",
    "    return df_out\n",
    "\n",
    "# -------------------- Baseline 8: CausalBERT / Fine-tuned transformer classifier --------------------\n",
    "def train_causalbert_classifier(training_df: pd.DataFrame, val_df: pd.DataFrame, model_name_or_path=\"distilbert-base-uncased\", out_dir:Path=Path(\"out/causalbert_model\"), epochs:int=2, batch_size:int=16):\n",
    "    if not HAS_TRANSFORMERS:\n",
    "        raise ImportError(\"Install transformers and torch to train classifier.\")\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    tok = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path, num_labels=1)  # single logit -> sigmoid\n",
    "    # Prepare datasets\n",
    "    def df_to_hf_dataset(df):\n",
    "        texts = (df[\"pos_snippet\"].fillna(\"\") + \" ||| \" + df[\"domain\"].fillna(\"\")).tolist()\n",
    "        labels = df[\"label\"].astype(float).tolist()\n",
    "        enc = tok(texts, padding=True, truncation=True, max_length=256)\n",
    "        import torch\n",
    "        dataset = torch.utils.data.TensorDataset(\n",
    "            torch.tensor(enc[\"input_ids\"], dtype=torch.long),\n",
    "            torch.tensor(enc[\"attention_mask\"], dtype=torch.long),\n",
    "            torch.tensor(labels, dtype=torch.float32),\n",
    "        )\n",
    "        return dataset\n",
    "    # add label column from ground truth membership\n",
    "    if \"label\" not in training_df.columns:\n",
    "        training_df[\"label\"] = training_df.apply(lambda r: 1 if (int(r.i),int(r.j)) in gt_edges else 0, axis=1)\n",
    "    if \"label\" not in val_df.columns:\n",
    "        val_df[\"label\"] = val_df.apply(lambda r: 1 if (int(r.i),int(r.j)) in gt_edges else 0, axis=1)\n",
    "    train_dataset = df_to_hf_dataset(training_df)\n",
    "    val_dataset = df_to_hf_dataset(val_df)\n",
    "    def collate_fn(batch):\n",
    "        import torch\n",
    "        ids = torch.stack([b[0] for b in batch])\n",
    "        masks = torch.stack([b[1] for b in batch])\n",
    "        labels = torch.stack([b[2] for b in batch])\n",
    "        return {\"input_ids\": ids, \"attention_mask\": masks, \"labels\": labels}\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=str(out_dir),\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        num_train_epochs=epochs,\n",
    "        save_total_limit=1,\n",
    "        seed=42,\n",
    "        logging_steps=50,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "    )\n",
    "    def compute_metrics(p):\n",
    "        logits = p.predictions\n",
    "        preds = 1/(1+np.exp(-logits.reshape(-1)))\n",
    "        labels = p.label_ids\n",
    "        return {\"roc_auc\": float(roc_auc_score(labels, preds)) if len(np.unique(labels))>1 else 0.0}\n",
    "    trainer = Trainer(model=model, args=training_args, train_dataset=train_dataset, eval_dataset=val_dataset, tokenizer=tok, data_collator=collate_fn, compute_metrics=compute_metrics)\n",
    "    trainer.train()\n",
    "    trainer.save_model(str(out_dir))\n",
    "    return out_dir\n",
    "\n",
    "def predict_causalbert_scores(model_dir: Path, df_pairs: pd.DataFrame, model_name_or_path=\"distilbert-base-uncased\"):\n",
    "    if not HAS_TRANSFORMERS:\n",
    "        raise ImportError(\"Install transformers and torch to run prediction.\")\n",
    "    tok = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(str(model_dir))\n",
    "    texts = (df_pairs[\"pos_snippet\"].fillna(\"\") + \" ||| \" + df_pairs[\"domain\"].fillna(\"\")).tolist()\n",
    "    enc = tok(texts, padding=True, truncation=True, max_length=256, return_tensors=\"pt\")\n",
    "    import torch\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(**enc)\n",
    "        logits = out.logits.cpu().numpy().reshape(-1)\n",
    "        probs = 1.0/(1.0+np.exp(-logits))\n",
    "    df_out = df_pairs.copy()\n",
    "    df_out[\"causalbert_score\"] = probs.tolist()\n",
    "    return df_out\n",
    "\n",
    "# -------------------- Baseline 9: Neural Causation Coefficient (NCC) using CDT --------------------\n",
    "def baseline_ncc(df_pairs: pd.DataFrame, pair_X: np.ndarray):\n",
    "    if not HAS_CDT:\n",
    "        raise ImportError(\"Install cdt (pip install cdt) which includes NCC implementation.\")\n",
    "    # cdt provides NCC in cdt.causality.pairwise\n",
    "    from cdt.causality.pairwise import NCC\n",
    "    ncc = NCC()\n",
    "    scores = []\n",
    "    for idx in range(pair_X.shape[0]):\n",
    "        # NCC expects two 1D arrays; we will split pair feature vector in half\n",
    "        vec = pair_X[idx]\n",
    "        half = vec.shape[0]//2\n",
    "        x = vec[:half]; y = vec[half:half+min(len(vec)-half,half)]\n",
    "        try:\n",
    "            s = ncc.predict(x.reshape(-1,1), y.reshape(-1,1))\n",
    "            scores.append(float(s))\n",
    "        except Exception:\n",
    "            scores.append(0.0)\n",
    "    score_norm = (np.array(scores) - np.min(scores)) / (np.max(scores)-np.min(scores)+1e-12)\n",
    "    df_out = df_pairs.copy()\n",
    "    df_out[\"ncc_score\"] = score_norm.tolist()\n",
    "    return df_out\n",
    "\n",
    "# -------------------- Run baselines and evaluate --------------------\n",
    "results_summary = {}\n",
    "\n",
    "print(\"Running baselines â this may take a while depending on installed libs and dataset size.\")\n",
    "\n",
    "# PC baseline\n",
    "try:\n",
    "    df_pc = baseline_pc(pair_X, pair_keys)\n",
    "    res_pc = evaluate_scores(df_pc, \"pc_score\", gt_edges, OUT_DIR / \"pc_eval\")\n",
    "    results_summary[\"pc\"] = res_pc\n",
    "    print(\"PC baseline done.\")\n",
    "except Exception as e:\n",
    "    results_summary[\"pc_error\"] = str(e)\n",
    "    print(\"PC baseline error:\", e)\n",
    "\n",
    "# GES baseline\n",
    "try:\n",
    "    df_ges = baseline_ges(pair_X)\n",
    "    res_ges = evaluate_scores(df_ges, \"ges_score\", gt_edges, OUT_DIR / \"ges_eval\")\n",
    "    results_summary[\"ges\"] = res_ges\n",
    "    print(\"GES baseline done.\")\n",
    "except Exception as e:\n",
    "    results_summary[\"ges_error\"] = str(e)\n",
    "    print(\"GES baseline error:\", e)\n",
    "\n",
    "# NOTEARS baseline\n",
    "try:\n",
    "    df_notears = baseline_notears(None)\n",
    "    res_notears = evaluate_scores(df_notears, \"notears_score\", gt_edges, OUT_DIR / \"notears_eval\")\n",
    "    results_summary[\"notears\"] = res_notears\n",
    "    print(\"NOTEARS baseline done.\")\n",
    "except Exception as e:\n",
    "    results_summary[\"notears_error\"] = str(e)\n",
    "    print(\"NOTEARS baseline error:\", e)\n",
    "\n",
    "# LiNGAM baseline\n",
    "try:\n",
    "    df_lingam = baseline_lingam(pair_X)\n",
    "    res_lingam = evaluate_scores(df_lingam, \"lingam_score\", gt_edges, OUT_DIR / \"lingam_eval\")\n",
    "    results_summary[\"lingam\"] = res_lingam\n",
    "    print(\"LiNGAM baseline done.\")\n",
    "except Exception as e:\n",
    "    results_summary[\"lingam_error\"] = str(e)\n",
    "    print(\"LiNGAM baseline error:\", e)\n",
    "\n",
    "# NCC baseline (cdt)\n",
    "try:\n",
    "    df_ncc = baseline_ncc(df_pairs, pair_X)\n",
    "    res_ncc = evaluate_scores(df_ncc, \"ncc_score\", gt_edges, OUT_DIR / \"ncc_eval\")\n",
    "    results_summary[\"ncc\"] = res_ncc\n",
    "    print(\"NCC baseline done.\")\n",
    "except Exception as e:\n",
    "    results_summary[\"ncc_error\"] = str(e)\n",
    "    print(\"NCC baseline error:\", e)\n",
    "\n",
    "# CausalBERT baseline: attempt only if training data exists (TrainingSetCPC in Dsynth)\n",
    "try:\n",
    "    # find a training set file (TrainingSetCPC.jsonl) in d_corpus directory or out/Dsynth\n",
    "    train_cpc = DCORPUS_DIR / \"TrainingSetCPC.jsonl\"\n",
    "    if train_cpc.exists() and HAS_TRANSFORMERS:\n",
    "        train_records = load_jsonl(train_cpc)\n",
    "        train_df = build_pair_df_from_records(train_records, entities_map, require_unique_pairs=True)\n",
    "        # create a small validation split\n",
    "        tr, val = train_test_split(train_df, test_size=0.1, random_state=42)\n",
    "        model_out = train_causalbert_classifier(tr, val, model_name_or_path=\"distilbert-base-uncased\", out_dir=OUT_DIR/\"causalbert_model\", epochs=1, batch_size=8)\n",
    "        df_cb = predict_causalbert_scores(model_out, df_pairs)\n",
    "        res_cb = evaluate_scores(df_cb, \"causalbert_score\", gt_edges, OUT_DIR / \"causalbert_eval\")\n",
    "        results_summary[\"causalbert\"] = res_cb\n",
    "        print(\"CausalBERT baseline done.\")\n",
    "    else:\n",
    "        results_summary[\"causalbert_note\"] = \"TrainingSetCPC.jsonl not found or transformers not available; skipping CausalBERT.\"\n",
    "        print(\"Skipping CausalBERT (no train data or transformers missing).\")\n",
    "except Exception as e:\n",
    "    results_summary[\"causalbert_error\"] = str(e)\n",
    "    print(\"CausalBERT error:\", e)\n",
    "\n",
    "# LLM zero-shot baseline (Gemini) â only if configured\n",
    "try:\n",
    "    if HAS_GEMINI:\n",
    "        df_llm = llm_score_pairs_gemini(df_pairs, model_name=\"gemini-2.5-flash-lite\", sleep_between_calls=0.0)\n",
    "        res_llm = evaluate_scores(df_llm, \"llm_gemini_score\", gt_edges, OUT_DIR / \"llm_gemini_eval\")\n",
    "        results_summary[\"llm_gemini\"] = res_llm\n",
    "        print(\"LLM Gemini baseline done.\")\n",
    "    else:\n",
    "        results_summary[\"llm_gemini_note\"] = \"Gemini SDK not installed/configured; skipping.\"\n",
    "        print(\"Skipping Gemini LLM baseline.\")\n",
    "except Exception as e:\n",
    "    results_summary[\"llm_gemini_error\"] = str(e)\n",
    "    print(\"Gemini baseline error:\", e)\n",
    "\n",
    "# Save combined summary\n",
    "(OUT_DIR / \"baseline_summary.json\").write_text(json.dumps(results_summary, indent=2))\n",
    "print(\"Baseline evaluation finished. Results saved to:\", OUT_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
